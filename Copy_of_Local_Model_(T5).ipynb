{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Original Implementation by Gyubok Lee -->\n",
        "<!-- Refined by Seongsu Bae on 2024-01-14 -->\n",
        "<!-- Note: This Jupyter notebook is specifically designed for the EHRSQL project. It features custom modifications and enhancements to cater to the unique dataset and experiment objectives -->\n",
        "\n",
        "# Local Model Sample Code (T5) for EHRSQL: Reliable Text-to-SQL Modeling on Electronic Health Records\n",
        "\n",
        "<p align=\"left\" float=\"left\">\n",
        "  <img src=\"https://github.com/glee4810/ehrsql-2024/raw/master/image/logo.png\" height=\"100\" />\n",
        "</p>\n",
        "\n",
        "Welcome to the T5-based Local-Model Baseline Code for the EHRSQL task, a component of the Clinical NLP 2024 Workshop. This Jupyter notebook serves as a comprehensive guide to developing a robust Text-to-SQL model for Electronic Health Records (EHRs).\n",
        "\n",
        "## Steps in This Jupyter Notebook\n",
        "- [x] Step 1: Clone the GitHub Repository and Install Dependencies\n",
        "- [x] Step 2: Import Global Packages and Define File Paths\n",
        "- [x] Step 3: Load Data and Prepare Datasets\n",
        "- [x] Step 4: Construct a Text-to-SQL Baseline Model\n",
        "- [x] Step 5: Initial Model Evaluation on All Queries\n",
        "- [x] Step 6: Model Evaluation Considering Unanswerable Questions\n",
        "- [x] Step 7: Test data inference\n",
        "- [x] Step 8: Submission\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Begin your journey with the EHRSQL task by following these structured steps (from Step 1 to Step 8). Each section is designed to guide you smoothly through the process, from setup to submission. We're eager to see the innovative solutions you'll bring to the field of Text-to-SQL modeling for electronic health records."
      ],
      "metadata": {
        "id": "nFluu0QgVZsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone the GitHub Repository and Install Dependencies"
      ],
      "metadata": {
        "id": "WuGjZ24xTJjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you begin, make sure you're in the correct directory. If you need to reset the repository directory, remove the existing directory by uncommenting and executing the following lines:"
      ],
      "metadata": {
        "id": "KJAip9BJCRDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf ehrsql-2024"
      ],
      "metadata": {
        "id": "uhH44DzGXx98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1266f6c0-cba1-490d-dd99-104b71d2c8d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, clone the repository and install the required Python packages:"
      ],
      "metadata": {
        "id": "QyxAMm_ksM7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone -q https://github.com/glee4810/ehrsql-2024.git\n",
        "%cd ehrsql-2024\n",
        "\n",
        "# Installing dependencies\n",
        "!pip install -q transformers\n",
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyFGlZ2wUBn2",
        "outputId": "ce07fdad-cd21-43ca-9a21-e5ac895c6582"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `%load_ext` magic command to automatically reload modules before executing a new line:"
      ],
      "metadata": {
        "id": "pwyXT96YsPJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rYYVQTvWZApy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import Global Packages and Define File Paths\n",
        "\n",
        "Now that the repository and dependencies are set up, let's import the necessary global packages and define file paths for our datasets."
      ],
      "metadata": {
        "id": "J9v6u67eUXxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "WY3CWQvLTf-s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directory Paths:\n",
        "- `BASE_DATA_DIR`: The primary directory for all dataset files, ensuring centralized and organized data storage.\n",
        "- `RESULT_DIR`: Path to store results for submission.\n",
        "\n",
        "\n",
        "Dataset File Paths:\n",
        "- `TABLES_PATH`: Contains the structure of database tables (JSON format).\n",
        "- `TRAIN_DATA_PATH`: Natural language questions for training (JSON format).\n",
        "- `TRAIN_LABEL_PATH`: Corresponding SQL queries for training labels (JSON format).\n",
        "- `VALID_DATA_PATH`: Validation dataset with natural language questions (JSON format)."
      ],
      "metadata": {
        "id": "e0xykR31N4zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory paths for database, results and scoring program\n",
        "DB_ID = 'mimic_iv'\n",
        "BASE_DATA_DIR = 'data/mimic_iv'\n",
        "RESULT_DIR = 'sample_result_submission/'\n",
        "SCORE_PROGRAM_DIR = 'scoring_program/'\n",
        "\n",
        "# File paths for the dataset and labels\n",
        "TABLES_PATH = os.path.join('data', DB_ID, 'tables.json')               # JSON containing database schema\n",
        "TRAIN_DATA_PATH = os.path.join(BASE_DATA_DIR, 'train', 'data.json')    # JSON file with natural language questions for training data\n",
        "TRAIN_LABEL_PATH = os.path.join(BASE_DATA_DIR, 'train', 'label.json')  # JSON file with corresponding SQL queries for training data\n",
        "VALID_DATA_PATH = os.path.join(BASE_DATA_DIR, 'valid', 'data.json')    # JSON file for validation data\n",
        "DB_PATH = os.path.join('data', DB_ID, f'{DB_ID}.sqlite')               # Database path"
      ],
      "metadata": {
        "id": "JU6Ofa81UZ3v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Data and Prepare Datasets\n",
        "\n",
        "Now that we have our environment and paths set up, the next step is to load the data and prepare it for our model. This involves preprocessing the MIMIC-IV database, reading the data from JSON files, splitting it into training and validation sets, and then initializing our dataset object."
      ],
      "metadata": {
        "id": "P4_7-GnpUc2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Preprocess MIMIC-IV Database Demo"
      ],
      "metadata": {
        "id": "DIar8UFxYCse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://physionet.org/static/published-projects/mimic-iv-demo/mimic-iv-clinical-database-demo-2.2.zip\n",
        "!unzip mimic-iv-clinical-database-demo-2.2\n",
        "!gunzip -r mimic-iv-clinical-database-demo-2.2"
      ],
      "metadata": {
        "id": "CXbRLFgGYD0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f3a69c-ab37-4c60-bf43-fae875e274a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-30 11:29:19--  https://physionet.org/static/published-projects/mimic-iv-demo/mimic-iv-clinical-database-demo-2.2.zip\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16189661 (15M) [application/zip]\n",
            "Saving to: ‘mimic-iv-clinical-database-demo-2.2.zip’\n",
            "\n",
            "mimic-iv-clinical-d 100%[===================>]  15.44M   463KB/s    in 33s     \n",
            "\n",
            "2025-06-30 11:29:52 (480 KB/s) - ‘mimic-iv-clinical-database-demo-2.2.zip’ saved [16189661/16189661]\n",
            "\n",
            "Archive:  mimic-iv-clinical-database-demo-2.2.zip\n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/LICENSE.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/README.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/SHA256SUMS.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/demo_subject_id.csv  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/admissions.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_hcpcs.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_icd_diagnoses.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_icd_procedures.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/d_labitems.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/diagnoses_icd.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/drgcodes.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/emar.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/emar_detail.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/hcpcsevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/labevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/microbiologyevents.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/omr.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/patients.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/pharmacy.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/poe.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/poe_detail.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/prescriptions.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/procedures_icd.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/provider.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/services.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/transfers.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/caregiver.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/chartevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/d_items.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/datetimeevents.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/icu/icustays.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/ingredientevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/inputevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/outputevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/procedureevents.csv.gz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd preprocess\n",
        "!bash preprocess.sh\n",
        "%cd .."
      ],
      "metadata": {
        "id": "JnprCPZhYG1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20073d0-7af1-4509-b1a5-c842491db8b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024/preprocess\n",
            "timeshift is True\n",
            "start_year: 2100\n",
            "time_span: 0\n",
            "current_time: 2100-12-31 23:59:00\n",
            "Processing patients, admissions, icustays, transfers\n",
            "Cannot take a larger sample than population when 'replace=False\n",
            "Use all available patients instead.\n",
            "num_cur_patient: 4\n",
            "num_non_cur_patient: 90\n",
            "num_patient: 94\n",
            "patients, admissions, icustays, transfers processed (took 0.1326 secs)\n",
            "Processing dictionary tables (d_icd_diagnoses, d_icd_procedures, d_labitems, d_items)\n",
            "d_icd_diagnoses, d_icd_procedures, d_labitems, d_items processed (took 1.5603 secs)\n",
            "Processing diagnoses_icd table\n",
            "diagnoses_icd processed (took 0.0974 secs)\n",
            "Processing procedures_icd table\n",
            "procedures_icd processed (took 0.0389 secs)\n",
            "Processing labevents table\n",
            "labevents processed (took 1.4311 secs)\n",
            "Processing prescriptions table\n",
            "prescriptions processed (took 0.4612 secs)\n",
            "Processing COST table\n",
            "cost processed (took 0.3343 secs)\n",
            "Processing chartevents table\n",
            "chartevents processed (took 2.5671 secs)\n",
            "Processing inputevents table\n",
            "inputevents processed (took 0.456 secs)\n",
            "Processing outputevents table\n",
            "outputevents processed (took 0.2467 secs)\n",
            "Processing microbiologyevents table\n",
            "microbiologyevents processed (took 0.0614 secs)\n",
            "0               patients\n",
            "1             admissions\n",
            "2        d_icd_diagnoses\n",
            "3       d_icd_procedures\n",
            "4             d_labitems\n",
            "5                d_items\n",
            "6          diagnoses_icd\n",
            "7         procedures_icd\n",
            "8              labevents\n",
            "9          prescriptions\n",
            "10                  cost\n",
            "11           chartevents\n",
            "12           inputevents\n",
            "13          outputevents\n",
            "14    microbiologyevents\n",
            "15              icustays\n",
            "16             transfers\n",
            "Name: name, dtype: object\n",
            "Done!\n",
            "\n",
            "/content/ehrsql-2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data from JSON"
      ],
      "metadata": {
        "id": "zAwMC0MOu7N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_io import read_json as read_data\n",
        "from utils.data_io import write_json as write_data\n",
        "\n",
        "# Load train and validation sets\n",
        "train_data = read_data(TRAIN_DATA_PATH)\n",
        "train_label = read_data(TRAIN_LABEL_PATH)\n",
        "valid_data = read_data(VALID_DATA_PATH)\n",
        "\n",
        "# Quick summary of the dataset\n",
        "print(f\"Train data: {len(train_data['data'])} entries, Train labels: {len(train_label)} entries\")\n",
        "print(f\"Valid data: {len(valid_data['data'])} entries\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A64Qj-SIUbEa",
        "outputId": "5ee2c987-b688-40ce-f4ad-7fe63eee7de8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 5124 entries, Train labels: 5124 entries\n",
            "Valid data: 1163 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the Dataset\n",
        "\n",
        "Before proceeding with the model, it is always a good idea to explore the dataset. This includes checking the keys in the dataset, and viewing the first few entries to understand the structure of the data."
      ],
      "metadata": {
        "id": "Un-pQJ11aMW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore keys and data structure\n",
        "print(train_data.keys())\n",
        "print(train_data['version'])\n",
        "print(train_data['data'][0])\n",
        "\n",
        "# Explore the label structure\n",
        "print(train_label.keys())\n",
        "print(train_label[list(train_label.keys())[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLze-yOMUivf",
        "outputId": "82029bda-9471-40da-8a47-cd971a4d472b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['version', 'data'])\n",
            "train_v1.1.0\n",
            "{'id': '86c0624f79d2e1a57bd72381', 'question': 'What are the consumption methods of ampicillin sodium?'}\n",
            "dict_keys(['86c0624f79d2e1a57bd72381', '8410ba33ca60f450bef1f5d8', '657a58e806b8805fa2a4714d', 'db32ddeefc60ef2e085d547a', '192595f3a72877272b046e55', 'def6d375a2be3ced2d907c6d', 'bc72b33b40a0a574955d98e6', 'e28ceb0ac6e10e4e5f14b4dd', 'd162e9cc060eadbc00511ac2', 'a229a64f2bf74f9fc9dfa626', 'dac5c6aaac6b57cdc328694e', '56fd4c77a08d2c69466f3daf', 'b9bcd099d5f42ea75aca129e', 'b64c62eb05aaad4071af83a7', '368dc6fa47ea7885905c48d5', '1f76d064d52e32276438fbaf', '8073dc91a374c05758eb7cd2', '9d3038ee311cade2b5621bce', '9906646cfa86ce749ac4d08e', 'df7a774b0aacbddb0a1facfe', '9298a838a1b1fa2910b4a9eb', '975a9d2f0afd09663ee67165', '3eb6d37c0b82ceb5b2df547e', '612076c066409c1c13b808e5', '3da43478d4e899fc1b0f0fe3', '21e946effbb48dafa5e842d3', '7c25dcee711f95e8760994eb', 'eec30a374f5a614dddb5c128', '01a258cef08c0eb27a9ef878', 'efd5c9c44ecab92af5e496fa', '5d63012ba377b6abd13cc0ec', 'bf8943fddda84358c2b49e35', 'f76e82ade10ee685ac166e82', 'bf0f4f576e73bf0337820ba1', '252547601fd6f7de68d6ad35', '09d05723516e1dd76fa1efe3', '190982f3687093b621a95f14', 'd468712401b6ab1b27a362ee', 'b01254cc6625f82626d18102', 'f806b5540e6d98bc7a994ad3', '4e87cca0b7f4f1c42928e016', '6857374e8a42190064459f79', 'c68906dafb0c5fe36f9c5d48', '1d7daad1762a274e42d1274a', 'e138f038c01ab7ff83cbbb98', 'c616ccb02a7104766a7ca4e7', '614926ee15e952ef06fec83f', 'acf918458c8addc978e6c8d7', '1013430fc9817f02c815005a', '49da3f4c781d729017455057', '924c0d9895d24fb53c79fb4a', '3eb9161ed9a1f7a609811822', 'e83b5e034fb29dbffbbeed14', 'db18ec5bfbe1e3422939cf2b', 'ae87fc8fc5ccf8578f0ec36c', '59e81ba463402dfebb19a04b', '5837deca15847d294628637f', 'fb44777e76712299533eaf79', '61943ff9aadb518fc206c477', 'd199f2338fccc1376de62441', '2ed30506921aece493589863', '24fdc72bfa641df5e25a4dd3', 'a12e0ce3ce5a8ad2bd8f3a5d', '3e18d6bc76b77c4f191e1259', '59612d635a641261872944e4', '45d81fe4cd05b27444d9f58e', '055d52386664ba496c850da1', '0de9102ca9d14d7b275ec8b7', 'c562491538e06939d07d281f', 'fc0310f4a0e6c3791fc800f8', '5b981e188f8028d8f045d245', '0f29c76985468daa67aa9e6d', 'ee08d24fe58b44292d96dfdc', 'e48fc73023f959a4fcf5c5c4', '103610582e111db3b8138c85', '59c00de184347b5897bcc303', 'e7552c3d9e8f53dd5494cd5d', '7bf454dec8755f5d448775d0', 'c9d4464b66be176cf11f8d68', '695b3083856ab31c0cd2853e', 'c1bede41699794dd619feb6b', '0fcf3657ba17464a0f38afe8', 'b857d922261f995e3a1265ac', 'aaca78ea66f02f483ebdf478', 'c40320a8cc992e9cf6c9c807', 'a8fc0b9f87df5a45d66da39e', '825c5c877128209aef4d391e', '53fbf62aeeffb338f67df6cc', 'd53217eec061327cdf9bf36c', '366d08a0b63e3cc04f1a4df1', '55f8f1cd25a1f682cc88512b', 'de726b4a741c447f0cdcb8e5', '3105970deb871dbf0e604cb4', '1413d85d169629ef664b2b96', '9c9100431bbeace3679922e0', '498d2f4e14ef15f20bc02818', 'c3f33ef0036d9efd71c23adc', '239fa629d1e7317b24ec198e', '8d8518ce9ca76a042a0c5bb0', '7b14cdcd4cf8cd3ffdc02db7', '6cc5dc7c9bdf2cc361bd3a79', 'cc4241e21c09d7f7c2b141ff', 'e7e44b96a9f8a6f93d886bbd', 'cf8596ed1cee62a5ad2886d8', '0e012c21a61355d6b84c3090', '8cbc6f9057443ffd3cb11a50', '037d3be256bd398ee1db08ce', '33c5bee6d20b4effb2ff92c1', 'f8afb5281dcdfe12ea07f322', 'd3d61d08b329e1aaf3de1a85', 'afa0e569514d9221f0ed8ad6', '65f6f12656c77dd1d0e81081', '5a676f9bd9eb81f901577ab1', '90c0a4f23c31e61cee1395c2', '7d25ac3b59f8763886afb8a7', '572e3be6f4447f2f3dd8a46e', 'a4d744501a505ad53e491d0c', 'f0782e76ee1d6e988ec5bb08', '486aad9ca1f13f573fabc677', 'e12e998b1f9c18fea1f85d8f', '96550da61d7335c3ccc3d5d0', '43377e1ef48d695d15424da9', 'd7d112f41aba75a33dcbeb67', 'c26556c5555cff100d6a8a02', '5407c72b5374049d5ff42574', '9e7913d9465b0471d710f65b', '5519ee451e8ab94af344b52d', 'fbe7d2b820e2ed531e0311d7', 'e3050cd2b1f00826b18a4be8', 'ffefdb9195190d8fcb86fa14', 'ba956e22bb92d02f3abbcb3c', 'e6fc71341c7764ba95e7f656', 'e7693ad9894979dd2cf53541', 'a14c0a5446f2f1b57b2a4c07', '218edde218dc6a20ef8e8fad', 'd8df22b2ce5cbb8d4e6d6f4d', '40ce8982a0a966c5bbb74462', '44a6d21d8264b4fa98a0113f', '9273f8ff183822a0ce4f95be', '45cd303621fb1f3007600184', '95a2c61973863427b73ef937', '585b1a785327dcf93085897b', '6a6845f8f10630a1084755dd', '2fe3354da7c1d59bea4dda70', '82b62524391ca6823ef4cd75', '43d295b14df7663a4b921316', 'fc46ccfbdac692e517e9d7fe', 'c0dcb9d8aed598dc3c1ff8fd', '06082342b67bc9539dd5dce6', 'cc583d453844985f8c75964d', '3310a57f349b527861680281', '943c84d543c4adfc73e1771b', '9cdb25ef0c41840e0b599dbb', '4fac3af5df19be6347d3c772', '408218a9af14aa7ec6f3f966', '5abb89ffecbb35ddc1f5b163', '7afd7257fd278efbcb7b33ad', 'e582763c64c4e8a81b029c81', '24273ce507fa41634f03e1bd', '696eddd60cdf06cbb9ee62d7', 'ed6f8d67b33854602df8651f', '99327791c62b40dd242f407a', '0de0194d965055a79103daf2', 'c21cf578f81ff7a390dc8596', '4168e2277f26fb151490a2c0', '4a9c408414e0cb27d0bc9e3b', 'f54bb9ca547f05441bb1ce7d', '41bdccec26b0e33321c1ec3f', '311010fa82081b7438a008c0', 'd4f9d7cf2cdd1caea918a666', '9c4387eddc635a52994b4e04', 'd8839ecf07fe219f65ec8de5', 'e18a2d8bc4701233c6f71e19', 'ead0a72fbee21b877251d88f', '11f17f3d6fad511b3db76b80', '02cf1de606c045cf18e72370', '9c7279514181f0cd64efe035', '18134bb405cad581e0aaef9f', '721e100bb5221ab0b783efb9', 'bf62c5424509b587645d8c69', '5d18dc5b86410f1a0b68d571', '6af5326ec076b32f85b4e657', 'cfb16f496f6c359ae9e6da4e', 'b2d4a908cb2de00418d09277', 'ea75ae7fadc90d510e6c9488', '17086641ec84cd4ab9ebe9be', 'f80d944a40468e69f130d0ca', 'b78c0434ecf85c58970b853d', 'f58bd3fca803b73088423ede', 'fb25b72d8fbcca4ca0b23169', '9def26468b7d6f3093845934', '202d3ee5d7d3e606014abe18', '49a64438974f40760d7b4448', '1c2f1cfa5e513beb87314705', '2cffa622f6560d843482b50d', '2d36357172aa4aae8c662e86', '66e17c14c6b5f8370524c964', '001bd30793469267511dbbbb', 'ac9fc03c65beee9fae66c482', '8a4a4c79371999b9915a2ef3', 'e0d157e7655d68add3bb76d5', '5f4091b20b6ccfd4e72a8f1f', '83d85a4fb249a66c71ea4700', '63d12a773f7455c04714cb1e', '44b000c0c7e63ce369e8fcb0', '7d7aee677bb35ba8d39e2a8e', 'a087cf65a777e7f24185f1a9', '6b992edeff1d490c7c58f9d0', '8521d760a18e114ce1c608b3', 'bb0544fc1cbc2ba271291243', 'f370a107576540264d73906f', '0d68d613cbc5bfb69833795a', 'a6b419a3f82d564950633030', 'dd2de211b42f9be113f51d60', '61d45a73e8a0469f9bf963be', '669a0b2733d0accec1a73720', 'db408655e01275e4bcc8c7bc', '989ff39a5fc2d15ff9d12bef', 'f96633ec8fc87fce8f72854a', 'a96ef9e34778c695552e52c6', 'acb8470937bc4a7d0d9b622d', '28b46c82ec1854678938782d', 'e3732452c0c7cbd80082d35c', 'cbcc848bf46b8605d7a0735d', 'ae00fe5dbb359a903185aab9', 'd83e90e0fe19b6017850565d', '243503fcb552e825a3b62d0c', '35ed250e4f509e49e30cba17', 'ee69065549df2afefab7aae1', '6fd61e60148bb599c1a2a048', '7151c86b2f910d26891150a0', 'ea34c337ef08f5bb39bce43e', '446ee7d9f8e891fa807c4f29', '9e442d16828a578f4b27bb6f', '0e87f2737511d219196c8409', '3c21d00c8e06bab6642fad1c', 'cc8811490b346c0fe68bf66b', 'e7d1fbad4727f90f548eeaae', '3fceb3f3200f3f095b671be0', '51f451ef32c9bcc8c27f43e9', '5c5679626e1a978f60f24793', '1e3f74247a6a94fae1151382', '0de3b7f259a662ea8dea4d2b', 'b51511a676f74b3a0f868b97', '02960e704986efbe2e56a892', '3bd09b282f97fbf5a9f40eaf', '559cabbd94ac4b49afae49bd', 'bae6bdda5b9a9cb808040a25', '5ae7505a2520a19129c81edd', '63b6c9677e2f1cde57d31e73', '771ae0e7dfa569d1298f749c', '853d39a04eeeedbb0a28a7d6', '150dcba6b064df151fc6eaf3', '613a190f2257871bd0c6a395', '5e3559038c113cb814682141', 'a718668474f99aed79794a78', '5f397d9337e3f7c527ae89c4', '0156bbc7fa6f2c54a9587d76', '0dac4285b866c55eacef22d7', 'db1b480d2286ade3469fa410', '690cfb24a4808aace8c6a75a', '350181bd71c310c99e34da39', '7fd1121ddb007a49e5ed2f4c', 'cd5489d01e1749510fc86424', '91a1b7d722fd22c60cb7f9c7', 'd1d3935b2877cebd687efc35', 'ff7c3e66b7fe93c4c036fe1e', 'cd1253c3a3d160eab14d31d4', '3244f169b0839776c6f8d9aa', 'f7175ad460d1ff7aae62b0fa', '663817ca2281ed4ca55f52e3', '0ef02974483ac960722b84f8', '44c07c98fe50b60cd61a2569', 'ea3505754407fd4d8ea5fdd8', '18d6cbfdf913f50a3617e481', '919fd2fec23929480d56959a', '6e592987e710b1b2fcd180e0', '0d4db28074f3b1bafc59af7e', '4ce7e0d7febc6b899fff7a21', 'f1308ea9b8bbc94c5e296e34', '2348bda143e013d91131d2d9', '66415948d667e13324c3969a', 'f04c7d3113bb51fa52b5acf5', 'cf07a721765b700935e376f5', '484f6763a7263dfc6dd3843b', '1c2352529be1c26de9ae73e4', '4f390ab9331393d06d9b9595', '8349ae15ee5f76bb723596fb', '023f3f0db56f39d9b838b1c0', '0427a5eaa446635b1a4b7f18', '22ab23e20a87874b13ca865c', '38b0a6d72077dca2e36faa92', '6f1c6d1e65b0d7b96f895ca2', 'f3ae841b553febe658abd103', 'd6be51fd1c5f29f5d9719bec', '6403ade93013ea7eb291be96', '48b89e86915910878671569f', '04e24b204bd0cfa1f803ee70', '09b0a7c875a861f6dca89576', '0114a64085ec7d751f6e1bfd', 'c395fa8a146f1042784e0d46', '54f536c0e9bc497653648fa1', 'e24e59d7e21364890399468e', '3fa2f28fcf723a8ae5b496cd', '9f9db02efbdc2ea5168b658f', 'c9769b44044478c7148aed85', '5ad0b756f0eced9a61f3f0e2', '15aef1c4f860681d29061482', '71e9ec4174f7ac09f0636302', '1e9722d883ec34d867a344f9', '69662f679dde3d8d7bc6490c', '97d26f029a5f2f8e475529e6', '8a93df214af665f8defd91d1', 'a169e91c54eaa5ebbdb895e6', '5fb41130df29e6ca3349cd41', '98703366748022f38c396dfa', 'f0508cab258d6df36060ea48', '1858b068f17e456b42371330', '887f1892fedc575d080e8217', 'd936f940a2ec69a598302c7c', '0d6abd33276d5170877ee1fa', 'aee372f28e8cc6e1deeb4d36', 'fabcb3ee15b98badd66dcd76', 'ad9324e51fa0e24a795cc9c7', '8f0afd39792dda81827e4464', '74a38dccf5ce3b494dd37197', '97d179e16fffa9fb76504042', '2504708564dec501dc2fdde3', '16836caa5b38e5fa22166c1a', 'abf27942525ea42427bca966', 'cb78a1c0f1fe2f58edc2d283', '77f1caca4c8a38d1fe942703', '953ded6c199c40900648aa89', '95b245de3db0ff301118f6ef', 'f6401e3fea26ee15aed66ec1', '76752df29fef2ffe6127c97b', '8a5ef0e3b44f9d29e1d8e450', '47bcce86f3ab85e1c0edd92a', '0179af361778345171c9542a', '15e5163ccc3e3c1f766d7f6a', '207e6d0a6a9b812afab27ac7', '96762825c5cbfa3426dc79a2', 'd064155c1b69cfe53b508d1e', 'f18a1ffa1752d917bfb094ac', 'edb18fda949ab33cd5cd47c8', '871e1ec7efc82f4a5c9d293c', 'eee4eef5cba60f4be092bcb9', 'af5515bbc62c20e665bfdae3', '2c36fe674f06fe07c1c1b71d', 'be4864408d7e9c4cb2d27c8a', '0dcdf1950d75981036938d0f', 'a7913ace036061bcf8f67934', '1adba3ceaf529ef2a8dda81a', 'e96d3b106469bfd953cd2583', 'df5a3dc1bac62f8679a50e44', 'c1ead7f66a477b8a69f1baea', '2092bc06715d6d43db8d20c2', 'b5aedd087997ec2e10bb6736', '2f795d71a3f4c1f8e411ce55', '12d278afa5aced986bad28bf', 'dba558e5efd6207a1ad84c29', 'b9f6116b0b39e50a2fa629e1', 'ce7b67d7433c0b9c16be0a5f', '70935d34cbc96deade5c1b18', '8e181485cf1adc897c3a3e28', '133bff217be024035d5957e2', '1d73f76e9729625f5d313029', '3fa947a7c4c696baf058e932', 'eb588610d7a73daedf0f76c1', '5f192a749e3dc5e91eff2fd7', 'a8572111c6db24cf56d0391e', '79690c25ac2b2e1a3f74269c', '3e3c16a752c633d8a67ecda2', 'a3bc0d803f5c36757f71d51c', '1d5c343c436c4699ca75db67', '658f14f535401c3647d83d50', '7af1e69b20b9be325402ee3c', '10a09034b24ebc5ea1fcd470', '6a55f374b69cde6051e87af6', '7c37ccb48483a3d417233092', 'dc414e02268ef72244d435fd', '4433eb04729dc3101c0b6e05', 'df6d9f1646fc387c7952ce10', '75dcf661ef83b60c79a0aa34', '909212b3de8ea34ca2c96475', 'a11042428c7092cce5896974', '0d22f4703425e474ebd63580', '4b57287bb27a24b3ea3db358', '2b35fcda321bd6bbe4114dd2', 'a280ab4c51d6d7b334f1d575', '7b673569df3b4b123b597c43', '04d6acb457c7debd55705e51', 'cd68238c19445383f9469b6b', 'adb4dc30adc6acdfe49dc9c0', '507c98230efbbf1d84008059', 'e4c2baa72dfc40ca402c8ebc', '39a0e7eaffab936c1439a5fa', '1ac4bb5a24bb2e2beea14966', 'dcf9ab0261c9713de6f8dab0', 'dc086ae27c1b78b95332d217', '83cc6dc500e1e949c8a26cdc', '72666450524051b2095429f8', '876f65e64154a3d0ee436ad3', '548efe4af132f8b95bf61624', 'db2dac9cf4438079183f8b61', '4d49aa5a44c5a8b00e811bf8', '0822c127d758cb84c86208ab', '790f43812849f0e3f94c3c15', '238589d4d2a414a0aa04c9b5', '9fba75551c882938367916bc', 'c3cb7b770179052c67712e37', '2c4de5ffe5ea946437ba33a6', '60fcfb33b6da12626f9c0ed4', '99c9abca99f18fa8ddc1f20a', '39206b0e94f1d50dfd4f7a97', '0653e85d090882590ea6b4ce', 'd84033aab28898c9a733e209', '338a9d532066c9b092d97b39', '13fab13d5c28d10640de8024', '54714e162bde7b10c34ed1c1', '61f316cdde3e8b077f86a486', '9e13de1d202dab1dcf105976', '9e60028a3774be29f175d420', '53fca8bfc5f88cb4209eec38', 'bae75ab280f0f80ba298c0cb', '3fa74c4fb1defa83dd97682b', 'fe581d0039127b044368f739', '08f5481de0c251a808376406', 'e0cf2f53e348a811ec32082d', '4f998b87cac41752ae6d9248', '0bcf658b419c2cb56787d659', 'c1adc1dd4db93616537a4296', 'c7279aab21fca4862f9c138a', '1e644096c1912f2f70a3c917', 'a01e64e03c8ea6881cad8b6c', 'b210336ce9274694af8855f6', '1603ed597a3810e80a4e2f15', '79028656244bb2aab8bd8d5d', 'afce68a2f7090e5fa3220930', 'de873dcbb588ef6ce9ad305d', 'af7b45da0507ce22b22901c2', 'aae494e615785b0b4e7f5bd8', 'e8f9739dbbd0348fee454966', '1ba68173e9103374da571bcf', '0d0dfd8344c44ef1ba5abcc4', '3a11d55ef59b984180bf191b', '3dd575660bbbf5e93e445cfb', '5df1cd4b427c7adcfb315ff9', '2dd263172f5bf1ae381c6af1', 'fd514da0acdf2220eacb5f1f', '381ee96e607f7191231167cb', '98c5ba7c0885aff19ce951a4', 'fe3277e1cb0eca8a574478bb', '306f0ab7b65335f49a4bfc03', 'dcbeaf8a50d187f685e536c8', 'f5f0f6336f05d930f6059ee3', '749cd7577c772cdc228d8a49', '067face22845095ef5e901a0', '3f1090acd1fbd153ed566e98', 'fc4da0d8a328e76fa47d035f', 'e4946b7c7c8d1c41eb7d77e2', '10379bc71183afe73e396f57', '3f720ea93f94700efe7fe7ee', '6b06f9b397dbfbab8b85f6e1', '6483b1969cfa3eda4e888a7a', '8b1866c740133c63f16df25c', '15a45174676987c6a3c0c4af', 'c32224fbcb946a4db57012a7', 'a65675d809840dc8d6dda8a4', '320d0d42e2bc3e896297a919', 'a3e6f2a97bc4bdaab7616bd2', 'b84f8bef2656a98e1a21f179', 'bfa5c2646e642966bfa98418', '145ae721e90f0d4889236e9b', 'd4729c0ab6ae0748e9626cab', 'a3355859e69721c3baf952d0', '0e962cda70b80f5930bde5ac', 'aedb02499fd35b17dcda7ada', 'f7dd12718e496d0937b3d1be', 'd28d6593912738578589157f', 'c88b6042bd98d9ea98a91f19', '7e545989763b5dd9c6a9df0b', 'b90482cec7b5c892ea5302f4', '9d89c1083e101a847c24df5f', 'bb02020436904947b9602d44', '9811bdd8dd976caed209c6a2', '1cfbdedba5f3d901870e5290', 'd4d40dd78c364c6f666d1a05', '339bd7b7cb9460146cc1f5a0', '9b56d431c0b4eac3cf5171d7', '346ee07f02d16abcf7f62e9e', '3bf09c03de716a687fc51856', '2c9a172538d37c27f588e4f8', 'b69ed3edc52cb224ecb174eb', '09552895d2ca5e482d2b314f', 'b9810aef8d75d1d2a9a31183', '1aaa39bc1ab0805e5a3b83be', '94ea79f626ba94bd76d643b1', '71319107f961de47a8a7b439', '75b0b6062a202e39dc311504', '3dfb9565afee9c41fd63cc07', '7b2e4a56a587f857df255484', '52d67bef474996c117256e92', 'a3279eb9747f960bcb7b62b6', '85fc1e7aa9384773068ded3c', 'fc72497b8c3f4de11b1c418f', '67a35d73e846d6a5995d2dd4', 'f93e415636fa3dd73984e7dc', '55c7172525f47f43ab6b752a', 'e2b4b7e5509dd99e1a88449e', '2985f06b4e11ccad87836564', '016d92926546ac6ede02409b', 'f53ea28051ef658c6e955c6f', 'beb64497e8a5dd3747e96f78', '74504b66834c2700e6349766', '426f5871dfa620cca1f14a84', '53645af951b7d3f45781e59f', '4b2e4f08510d69ad89b581ce', 'f888fddd502f84dfdc3b3bcb', 'c7fe6ea31f9f71af4dcc0072', '7346582042d3b9bcee31329c', 'b09c1296a97d4f7a4488f11f', 'af48025f4da1ed8f5c1616e3', '563951219388e9d8f1ba0f30', '17ff517f4cb7bc5330bbc4dd', '9b5ab2bf426064b58719cc29', '131f8932f899a611506ecd2b', '3db50784b5c5fd5267669673', '1ae02fd40242a1f6626facb2', 'c89cf055a5d102b539366869', '6eab05aa70724d26ebe7e7c1', '2e7f18557b9d9530eddacca0', '62547959e3baf6a4703c5fbb', 'be4e133fd657b3c989be8b0b', 'df30afea60a71f1c1b64dfef', 'b8f6fd0f9b950b22019dc5f9', '27f86a5f461f220f2b2ed647', '65f0a54b0c223f74168d1b02', 'e44cd0b41cda6c3cab6b967e', 'dc9b3236056266b458fff17f', '6c26a6c8707782ccd2a0c56c', 'fb95177b2a968ec680128db1', 'b6d57a0c15272dbc69e39fc2', '7809b76d2d7b213240cd949c', 'fab4f3241b1a4140593a2196', '6246ddb668aaa2fe1adb0353', '4202b117d324f6285ecaf255', 'db9fb5b609cf5c9785924c0c', 'd736183a8eb133edc418c730', '6208d84a6a16f8ac2b720298', 'a178876b3ab67646062e1b51', '4b334d0f16aebc57870989a3', '9aaa83b804392690737b00fb', '7b8292b0a8f2a804114ac706', 'c122bbbae5a9d7b44953325a', 'f65f6f053430f63b922aef1d', '66c02202fa82b6035ee4845c', 'bcf8bddfe8dcd3e449454450', '36ed6cc232d6795e6492644d', 'ab750c2c23f2234be8a906a3', '7671f2895af9f8efa4666e20', '0a103802ca827b13141a5a60', '8d8cd6284d24a2bdccc48b42', 'beba565897d39febcb35f999', 'bbe074710272a9a159c13d10', 'dae5f9c47a5e0608624786d7', '8b0171b645230d02485753dc', 'c0ed5f3463fb838c2206713f', '1286e054ab8b363bfd212296', 'aaa971c7a88d9bf7858d0200', '648035b87d03c40993442aeb', 'a7766be547dac94471bb1f74', '95b867d0cf6c28bfdd679151', 'aca1e0e3be80e222d3b95be5', 'b11ba285107d208de9e518f1', '5e75262ac3a25d12e75712dc', '662a8bb09520c819a88e24a6', '9f95244492614327ffaf076b', '09a725954294822d94f728cd', '0e5f94ff7f2b90800950a848', 'ced779d97cae41941721bd34', '388d3f6a45be242b02005c5c', 'f1189d2c589416c9c81ca80e', '99ce32579f34baf63f28f671', '95e4cfa052e3d03fe0ffacbd', '92847b18dd8be297f01979a1', 'ad2612489dcd53ed00312d17', '09c12062e2d66d05c75bba9f', '8236653d88c7fec0c10aeb71', '5eed4e1b791b78ba28273ed6', '1816be0b35b828a815b17b16', 'b555ee213c4e95edc4e8b7e9', 'a49ff217e1eaf845efa42727', '127ee80e549fe86039373e27', '4f42b7f15b57fa921a5c03ea', '67aeef950338b9e353377442', '1f0fce096cb3fb07a3c96ef2', '7d3ded586776af8013c94a0f', '02bd66cb3a751f53d4accb0a', '9dea9102653c7bfb36386393', '9a5ebe2812ee93bc053bbf59', '827992b8de480860fb744924', '3f43e5ace937d4b9a8b18b3f', 'd6b7b3ab6732956bc3e0fc24', 'c2611c6cae651d68d35a90db', 'ce843fac6f9ff9ab4f1d2dc3', '531895a8f6c3cd6a5748843b', '06ba722e2ac0589ffacd1249', '250459eeaf1e43b5affdfa0e', '3890e55b1b0c07ff2b11bb35', 'b5ce6c822904c206071d56a5', 'dd2f29754291be893cdcffa8', '215bb31f610d65f9b86033ff', 'fe615a9fbe3f8b13bb56bbdf', 'd939b033b5e6b326580d0570', 'd2d6e834bd7830831783fa05', 'fd430b3bc6f281ccc988453c', '1cf1e58d245ff59b4d7adc31', '3751ff2eb0be4c22f7a8f752', '5301d3f2ee9055f024af59a4', '2ec6cb1efc895f9201b5cf60', 'e152d27a95ebcc62820b1622', '6d770f5dad11c867295ac4f0', '7ae435e691f248d18ab7bec3', 'abe78de7464f93993da9c600', '45d38cc2d6126200d9c5ec99', '137633ed86ab2d0d0059f5c2', 'b947843285099f2f901cf7de', 'f95edd83ff3d509561310e88', '3d45d365e05eb1ff7b926005', '23186572a878a351ae7acf5b', '620fed67edcc618c82c9bb68', 'd2edfd01c7ab2bfa13268728', '935352db3b3a1d247e88bdc4', '7d2d2036da24495b7017dd89', '9a574ab97db06ee700de7520', '38e7715444818223680cc90f', '97d549d940853218be2a6803', '816890403b923f91deda0dda', '733c21a9f57a3bc179010c01', 'b53daa3c6e0af875928b6bd7', 'b6d7a34bc707d9209a3f1b63', '3f52f0b4c069263ecd9729b0', 'a035bf3a134c3a5f16e7e841', '3717572f6b674f00be856aec', 'a3dd56dec5262895f50e89b7', '71621e85a074b2ac8ffc6ace', '646dc3c2d9906fbf675e6443', '48d5f819ed7042b8dca4b7e5', '1d085776a9f4303e625f4125', '8f05ca0c74199be8f6803a5c', '170d16d87b8d77ec966d5f56', '34f825ce946e62cf44c7f3f5', 'e9de88c1ca4e544ff64bd3f9', '21f3520f8db52d400b139521', 'da332c7d00584e07d7258bc1', '2d80cb1e489c0421c68be6f2', 'c4afaf3f596cdc2be83cac17', '2398b4f90c62615b764ca247', 'b3d362f74a925702dfbb0a1d', '3fbce8b880d773477b429d71', '377abeef64a076e8f592c701', 'b7b00a485da3ac7c2a9f4f8e', '6f95b08ff006a4983b0050f6', '949e6e0fe8bdf465a1964e73', '64a1ee1c1e25b6f646865939', '42fb2b34ffcff69466b09384', '837051daccd7778c8114f640', '0d3343e3e64231d00abab91e', '7817472ef455fc770676dced', '1f2e37aaa091d50e833afad1', '180fff17c7418b127d038bf7', '1d8e1854e955b721c482a91d', '468732462fc76ffb0eabb559', 'ffb225e9649d2d2a042af243', '99e2661e12b6c6e852955ea5', '0664f9448edc539d0cb228a4', '30912953ec6a9977cec930db', '1770a690d77ad9ec94532a67', 'db0814178ef902c3c2b96f95', 'bd0c2e34f79eadadf992f4e2', '8b3bbb2614914b69a0d35d7f', 'ff61f56376566ef1959962de', 'e44f5a7695147c0b38ec316e', '3f384b70bd3be24de7ec5ac2', '18d972f8815b6dbf2e9141c3', '858671065bb8f7d96bf37f64', 'c550bac1aacd2bc72e7e12ab', 'f12b990bb88ff1470ae0fbd2', '0221f690fdea162c568ad8dc', '5f14e8eaef40b6633ce2e6dc', 'dbadc610a502fc0a6c69d44e', 'af8069263b44e7b3d7b8dee2', '4775d3a9d0fb326081985b5e', '132963e711d7f2dfe87f94dc', 'a124aa7b3370848af7ee0c6b', 'f5b7b1f39d3f36c2baf21b63', '8499e24e138f45443a93fa6d', '5a9d2f417f6b862c0b7366e8', '8325c8b0200f0d5f16e96fd7', 'd289ae08b9d6d02468d8c8d2', '8f4606909a78a1bbf2992c5c', '1707f8cb73d2f9a0fc881db5', '51ab705e6d5e1025e101e735', 'e60e3b0dd9bb998ce08e850c', '807c6c3264c76b6faa008696', 'db2e74ae7eb32d3ddbdbe8b2', '6bade51b85498f959d6a659c', '35b0b505d474e73b841b45f6', '4613c69ff92c982ad6b0c73e', 'c1cbfb46dafe04deb682724d', '258a0365b34cfcb6501ad3c2', 'f8bfabf3d67d5c270425864f', '506c80f153411922f7967305', 'f08251f8b3dd5a479060e87b', 'bf14cf17da2349955ab8ea66', '110b301bfc80d9c150556b92', '0f2f3ef0fa1e36d951c5a42f', 'af98aa24749ee692f69ef110', '02c15c7a4faad2a32636fac7', '7f9576332062c59f8d3332f3', '61b15d7e2318959ccf6194ba', 'd792cf5775c1f4e850ffcde0', '9f59f271601c4130d2301520', 'edcb877560f680ecc90bffc6', '98d4523a1fa9d300734adcb5', '474e88f3f2489ae5e866536c', '57ee9b35377fe295adfbf9c1', 'fdc2cf2c322ae8d1a991cb88', 'e7626ed5099c3df4e2766996', '55005268f132ecb83abd1166', '72046d186a8821cf81d3fec7', '998714278a267519fc47473b', '0ae32bee1adc6a16d66b16de', 'ec92f2209fc00778cd5a3157', 'bd64eba2a9801db69c14dd75', '407f290d6f4319cdd21a777e', '15b58da2d88da3aa6b767f4e', 'de257ec1deb940f9cc31497a', '6d4fb4147666cb3f5be2c8be', 'a39d417e2b49ba956a7d03a7', '9f7b99f3d5e3095f6d354747', 'c1b3f37142e9c9cf9ba75b12', 'ab353a41c3fc36453bfc931c', '1dd7881fb93e0f171b1c67dc', '0831dece04ef846871b1b934', 'c7f69643d20645a5bd715035', '042ab61601f982ee4d6436fd', '138c2d22c5c0e542ad8688f0', 'aaf18ebab994cddb6afcd715', 'cce128d8f29c8e7564cc8cc8', '38b98518dde0e0d276fdf109', '1ca13ce347fd46ac69499979', 'd49a169b25722c624294da5c', '56ed63e758861043fc857932', '6e552f2daf5bcd6d9a143315', '612f8fa49f7f4fdc5d2bc4b6', '9541827f1eee21fcc491d39d', '6b2bc626482c4ebd317ba6ea', '9ecd148b83207e3fbed2a937', '91db324bae8dcd9a03f5f6ba', '625878ba2c323f56d784df19', '16ca0a5e17d4cb11df70a0d0', 'a0ebb505e3207ec9be553166', '73d40a25005323dbe30f475f', 'b06238b6f95478036e95125a', 'bebeb2104d4c95aa591562d9', '562f824477376311916b88db', '86a5036ec7d536605431efaf', 'd96399e5245e5a0e11dcf0ff', '65ed4479d7d3a2021cd1f024', '6e32e4314cb1b08ef73c4739', 'f1501b008c57806e4fdc437f', '04d135a8d8db7bcb4130bb9b', '110ca8ef52a592fe8201ca1c', 'bc7ad8b3ef9492deca744662', 'b0e8ceb89dac04c7f918d0aa', '9879a8df02f5078e4cc9405e', '6cd24d0a30123968e0158324', 'ce7977eba118e89d42bc63b2', '60460642bc6fa663ac944b18', 'bbd2daaab53a49a1140c416c', '18f859e690e5c53434768ab0', '1f1579d6f5886ce1d80398a0', '8f3e188a5ef2fa6208206b5f', '17fee8730ce67c5cb81363da', 'c469f81f092e3b28dadc05f4', '2616e051ac4579e504b2e48d', '12fb8402b00499381bd3ff8c', '73482639c89e793869246809', '694ecac71896531f9afc039a', 'd8493e7bf9c18bcd8edb3a40', 'ea8b16320ebc9e5ee3d92c14', 'fe47357d4996af8b8acb6162', '83ee51e6e7fdc992ab579780', '4334a09dd6d34538cc7445dc', '627069dc134dd25c3ddbbb5a', 'fb7a0f8c9dc16e058b2fa6fb', '89383745e9cd66ac4837c91f', '9e84a6e731e2b335a972b488', '0b9e619bdb576876f002d49a', '065b726dbf86eb804accd168', '54ab42240e681be312ba36be', 'bf9ce789f4d2ca8fc80ad3e1', 'c68f338d371ce9d209a15844', '24f447b683e61e944f998093', '398d1c05773ae55b7220d406', '819c7fee312e5058c9f3296f', '571c7531441ce4b75b1fe333', '6f8ec1a440771aa4151d974e', '22e0dcfd0402820cca140ef2', '0266d6e5d007484e57bf12d6', 'a2c0369e9e1db224ff7cb590', 'c9d8cdde8cb8a16012cdc065', 'a3453842fa6d5f908f2e8c6e', '7da9c0a5790b317cead06455', 'e6c07526b6246ff9377949ba', 'd2eeacdc392b4745759a9da7', '3fcd3dd1926914800ea40cbb', 'a40106b94aad93108e39fdbe', 'bc8eaff8a367f984fb5ce7ab', '1c833319621b08fd5e14e8ff', '77bf5aa2f4ab92df9d557a77', '764c1ad18155aabf053779ab', 'facfa7d227ce410e9a85def3', '059ed55281d42669ad25d514', 'e2cf012f4e5832fab8f5409b', '6a91b9dd415016e5b1793284', '0cd11d35e8ac3515e3c55d6c', '06b1eef22357320dc0f8a64a', '2d745a50f391efc3dab3ccd8', 'c8b66e1569afc7477b2048fb', '3ce0aee35413ee29a66136d0', 'e741a395203aabb321b46310', 'a76ac4f3407058b120923fca', 'f782fdf63ed4c6c75950ea24', 'd86c1530c01a8065fe956df5', '77b6bd619a1302c0e9f16e66', '2040aaebd3c0a403ffa1269c', '062575cdb38e709723edbb54', '9b71dfdbadbc316c5802b20d', 'f4efae356977c3e6db1d472e', '1e1a1711a9e429a5c0a74eec', '4bcd1b55582a8d4b902af134', '77056748c01969f4cedd4f49', '5e6f873f02b4c4a0d2ee764a', 'adead92d438c2cc8419cbb1a', 'c3771288ef450c465644693b', '7c3ea800b2b64cb1b3cf89a4', '96c87d6620403ab5197e010c', '0d923876f67a35e78f8044b8', 'c9f31ddb9aad553f281fb072', '9d58a5b47d175751dafd7e2b', '01bc93ed00df686c5593006f', '45fcb3df912430805e7d3f94', '8dc67c242df7f0e88cce307e', '41b9a346811b51fc23501b6f', '72692c9fe3d361f082e66556', '9ae1e99a336fdea068c22d52', '169bc0cd29c8abe63a931a22', 'd1018384915acc94c4043e76', 'ce3af199fd7438f9504a0ed5', '1b34ed1fb8e15ce853b7f472', '03d470fc8e41f5dd8568f771', 'c871c7a5d78c361289609381', 'f8d0aedd069c1450d7d6264f', '228014642a9c756b378d10cc', '708d239b2f7785ac668db27a', '1f7e6a11b09b66d4eb7904e1', '911bb06c9471e1c057977c81', '1bd7abf7a8f3aefc71dd2357', '3c7e00141c354983c6fb8742', '4d0bc94cd3038c80ab777027', '1cd31dccc70c46d3c3d8d825', '4a31a2d75cf6e073cdeef706', '462cd9e5980b86409d6557d8', 'fdd1695a1c8a50679d56e863', '1a8c4898fa6341d62be1f722', '5255f208c2e8f59e3a5737fd', '1d509edaa223f304f5ee3b9f', '7d02af05751b72aaed0916cd', '5ebecd683c34753383eaaa76', '535fa7171aca46e1fa19b72d', '7b1b135317d758d40c445a0d', '27f16675ba7f39ec5b46e3bf', 'eae749337c708ec5697cf97e', 'cb1a4e3e68a3305cbed774f1', '0a8c46b684e72300d29c18aa', 'ff7b7029d2eb43d96f2ee688', '5b550bcb1829cb627ed0e4b7', 'c7ae2e00343bbb04614217b6', 'f224a6e013d318ebe61083f8', '2dc83d6d0ed121d2f9b4c9ca', 'cb480ff3c89f74e82be45053', 'a3a2597423bb12f178e4e5b7', '283bf444d3fe0d8412a24dc1', '88feed4e79da04e646ebc129', '383586ac765d783e5374a6c0', '0406ba9fa1c3ada7f76965a3', 'cbf01f06a75320ed354d25af', '8f1e4140fd54d60a4a21a46e', '4d8620a9b634b4449be0b4bd', '75f06d4831e589b2c6c537f0', 'da7b960f34b7f3185ea6d045', '5d5d324fca23706de226e43a', '2ddc53c4a796889b9c40ca78', '7299ff6d3a692b4da823bc87', 'ef005db9fac61254bdbabbe7', '09315d12007c47ae3fb400b6', '1fc3739dc0cf84ab7935fd38', '515fbb81432c9872301c377a', '45055dee9d62c2fec5046a84', 'b9dd894208060adb71afcbfc', 'a13c273dcddfa537845c91d0', 'd3ba4b68ea980852ba7f2f4a', '72f7cf565eac6853d4a5f4bc', 'f41dd60cef49db205a9a109e', 'bccd2741d2ab3570194f6bc7', '5542edc6eab94af30e250d96', '6bac631eb4407c64590d6679', '5d890144fe08088c541a7324', 'cdc697ea9fbefe7b34b817f1', '40c2eb3691b1c2483780d090', 'c4471eff3bf652c6fbb2e1bc', 'ba8c72ac9d84398bbde60168', '4c5b9d325f155a995261d1ee', '795eea96b2fc2255386f257a', '8f32b474deef58836081357f', '52959cb2e22890d781e8c6de', 'e85f9d1230b8c068895845ee', 'e9c90f808da51ad2e6517c27', '8b66fa07efb65f5c04096927', '9f89c16fdd0c28c056b815dc', '975f52f31d46067b703966a7', 'fe707f1415b3c5b889170f9f', '28b035f667b552adb72ed601', '4ef539346017d3f823c494a9', 'afd0edf3d315e4e3527d20e6', '8474dc2ee07777189c3204a6', '615451f929c6685caceb50d7', '67568f49d11fd0496fbb6673', 'e059ea4efcd2c6acce83030c', 'b3af8dad7a842e66a82fcefd', 'a5f82a2a25e12b8fa9f45188', 'af4a5dcb191d526cfe72e5e8', '4c4699c09aaed1411610005f', '6b45715eee2c6a3e15b33c84', 'f7c5ad73111031a507a6cd1e', '6fde254686227404794b2fc5', 'fef5c5c5e87a50fe992eb5e1', '1dd624d2269c420f3f8f4221', 'cff0399ac5f3e6f92802d46d', '3d1cd7fac995410fcbe1ac6e', '300b730b2071304399d37187', 'd1869793457264a58951d5a1', '07c3a7bd1ad4a0b1ff99dc6e', '58fc46bd97a36a8cd0da0a51', 'e82906460d369c59dd88596e', '006515f6c55f97197c806551', '27f935b1150b9d1465aca671', '6ae1470d6aa9a8989ce9feae', '4f4b54dda8079b6a474f7dbf', '1a9871c5fd02d558c330cbf8', '7549b94355cb877daceefd76', '020e2d80e18299ce0507fa90', 'b7cc95bac64259f6622ed1a6', 'eae17a2abae5380d33e5a16e', '805ef9586b322f146a69bc90', 'ae007a9e7bac3b258a198e4d', '4cb57312c692ef484eda70f2', '878bc58329a469fba6dce96f', 'd46df647d340ad44a40ac35c', '30211c2c43373c88ce98e15e', '28c2e5328bdffc0cd759ab0f', '4c768381b27bc7c4c77797b7', '6b86da30902fd18b6c3ce8fc', '0bdc5386e647b2eac6a93285', '89f60dd5338086b4ba4d500a', '5b01de29acc6c2fd58dc2d4d', '8ef307e735bc81566e95ef4d', '7e4fdf23c8cdbb2a00ac424f', '5cc50c300a3a469b841e4c03', '231da8d4c98bd9dbb15ab2b7', 'b5b556bd732ad0c5181e637e', '7558823d7e5287333e3e4844', 'eeee87a5c6e360efda22b0ae', '264b6be13eb00dcf23783033', '920b213eb78b65283a31c617', '1ea38b4d27812656f9f11213', '3e45428b37de1c2bb0c7aca8', 'f5ca4472ad5d322e094d14a9', 'a6b93479849a9df2a20349ea', '2615e31cc57389eaef9b60c2', '6392169bac12c24e6baf728c', 'cd65bce5b40390f06e3f1de2', '4cabeaca5a928bf8d834306f', '330e171b953b9a8aba0f243e', '41458d13b9e2254f4f437edf', 'efcfc20b6e9563abd729f917', '70bfaa91295002b7f6bd96a7', 'd3df07a9c31a2401cb746fdc', '74b8798e6983766e5803a4dd', 'b974e69687e62e745f07bfc0', 'fde9f5d77c8484063c8dcbc7', '8900221a23ce9db783827c31', 'ddec069510b33d402e5a0170', 'bd8d396b0fea8409695aebce', '6206774d35ffcf574a284cb2', '0cb92dfe9a68f1281cc94b27', '1b8fa8c17b4953cb8ae5696f', 'b8e9b90e80a785175600b2ff', 'c3b9775f6f9f3f0a14d7ec29', '312eb217dff66ce52d145060', '81852273a5351d699a554177', '77eb3ba985eb3df7b7b03d98', 'f51f73add40fa25cc0d3936a', '3bf9272fcc3117ccfaed52f1', '42d77c1fd11fc0abbd3449b8', 'e95fcfa72f1c014d79280732', 'd2664490e75476fb8fcc2c63', '6d74cbf5c9fe6defe17b715e', '09469e7ae520d7c2a28ad15f', '3fad0b33ee39bfb6e59660eb', '9bcb25bfb75bf11f00162db1', '1550fe2c0834cad1b2dbef07', '8bbc16e7b33ddf49226c0c8e', 'c8c5c2ee11a8da094f25c3bc', 'fb466f1f12c24c1faea2fb13', 'a2556a4a997d1f09c6a72589', '733f66f03dc1de20e998d218', 'd624abedfa96e75fb614fc58', 'e5b93830a2376294094a1f1b', 'af6abe939c498f156e856916', '6e94c2a9ff1a11c41777ecf8', '6260379332c5d91d2221013d', '54234a211c3fb7360ae4e161', 'd24509cc1ab0dd341bb53f33', '8e22c703d632798f42282434', '3cfe1a9f322b92f0841576db', '339d3163e8bea1c8f13aabf3', '05a9aa5bb494b962444ac354', '21ee43d3aa608dce16db8951', '61f764dd9a145b1cc50e9c25', 'df5256f4811843aaeca939a2', '48bc5f792f4ed6f03d3cb9e5', 'cf32c8a66e9b2e46a4a073dd', 'a0e105397fe459f9ad540eef', '2ada7dac8b465ec817534276', '6247e4ff884d2882517e9fa9', '2fa869cf56451cb9220ecb8a', 'd50ac96f2f625bb2840762bf', 'cc7cd55d5065328b8c5164e1', 'a46388d3c77f04af56eb9f4a', '9d99fa18449a20ae42392b52', 'f34ae2771a3ae71a42d66a89', 'c4eba636bd543d4b237a1e3c', 'b60a37507f5ac0a7a99bb5b2', '7993e77f8701f72acc7a2d5b', 'ec87b2a66e1ee117d0c97694', 'd1fc20ee02b9ce89df2bb4e6', '081ba7feccd490013f102984', '6460cd5a26ffc1b6bcc56a55', 'ea10182ca02a264d05d0a0c6', '14540374a9d0b9528a6d94fe', '5af27171b0a97add7aee4ea6', '91bfc5a70401d51bfca3e0d1', '1d5758a11b098e86ecfcc86d', '81f790401d1b25c6eebdd607', '447267ea557ee396e8eade57', 'c0fcaebf5fe4de9b0da7c35c', '659e84dd2728a7624246c318', '1479c9147e64755116efc852', '01389011a3cea028b226b95b', 'e449057b794c66a951ffc20d', 'bfda4e34737d0530a461ae0a', 'e5c3587bfbb2d97b71b9e953', '63677b75a5d720c6cc3d41f2', 'd653fc27e70a4eedd39bd936', '814f6690d0bc9410fa12b9f4', '721bfea157a6426f9d055a41', '2fa8b86ac44e632ee829dec6', '1183bcefba1a2e8f38f90e8e', 'c5924167cb9c4a6790f631c5', '20c1cb7239a17a4dbbe96296', '4f40841ba5cc7ce273305a27', 'a3ca87a1ecbcd3145068f456', 'feaaef960a419d81d79e5cfb', '07bde541ff2932869ecb4912', '15e6224c6a4f4b69e45e2059', 'ecf8d3921fe7ec039f51e46e', '2ca14c9e3ae55c6d467fa8c1', '333df3a7ec5a12c84b0e951e', '328c8f2538243e8dd6f5da24', '987c9d2214cdf8dd1eff384d', '6c892975c433bd0b8960e8d5', '98718dac8212efcff4207af5', '79af64ce3260e4d25b227939', '33b970d4dd11fbe67b989d1c', '7aeb94856d35a70807387853', 'a5681c4eead8c8b2e1968ab1', 'ed4bfebb071d64a0de120838', '77238633972ba57331af47e1', '8dea7b9b04a6934cbc300217', '7ea5b7b4bc12cad8a4e74fdc', '5a5f7cbc98a80e1a4f6e3b31', '0e38c574dc705f0c26a2aa69', '62e57b2d710776dc9693105a', '86e644ff0d66b3aee390fc72', '93fdc53c054b08a886a68474', 'e88b565b3eebfa84d07aba21', '1d1103ae4c20715e6f0ae678', '99768e192fa0360d8a7cae90', '523f9419c20f37e75f17f229', 'bc7d9cca70c0c64f7dd707af', 'f86dbfb605a8cf22c7785807', '53c2c01705d8513ebac151eb', '40e1b2eb72eb67d84b772be6', '63dc3947dde2cd40f4b0c364', '08e4e46ffbf10a71b11cc538', 'dea9a4a3b6415cd9f853cbe4', '7de6019246eb50aa7a443936', 'ccf873476d02f981c461b5c0', 'c9f7a8db98a61fe956ee074c', '6ba230c3cb949791fde3229f', 'fa56e6f995ce65468f6bac6a', 'def1690cfa1cd58ae29ab510', 'c07fa4ddf84fc8c4cfd717ab', '83c534985f90fb45936d3f90', '5e120295af4004e7fa588d2f', 'c56635619ccd4b7ce64652e4', '5c86eada276c78a8735e0dfb', '1d5c66901760c1bfc6eb5361', '583645b19b83246b4e37528d', '31fc326ca001513cb405a126', 'f14d33079f86bdf9032e4b84', 'b3c8c99b83e01986b79456be', 'cbe87d3055a29ed5e694a4df', '0f5988ac990c3b052bc99527', '5a217759e9fc00e289c1d8c9', 'e17c8e6fc29a5b5e084734c4', '86f9f9f4d49dd3a3f7c9fedf', '902c95e30f8c9752224d22f9', '306cfa6b9fa0c1c51c7dcd49', 'ac2e5b4fdd7c9a6ea505a929', 'aa513e26eaa857febb6f4db0', '0b19e40d278a97e915037e52', '97618f1a942f1a7582d5b1a9', '8716193b576f9f33068e792d', 'e253c035e9ea72b0f867ad77', 'cd7ec076d6dd032a842781fe', '299ef20e44a70d1ce5af952a', 'f8e70aaaef039854b3b29401', 'e2be072741fd9d09da7ab8b3', 'b6cb5bc47c02678729d05510', '3eebaf8381530fd2b515bfc8', '4287b3790b3f4f5109f1ee57', '5190a9c7556f440558510c86', '566bbc92e52ac6c9cd03050c', '7f130db92be0aad49a7104a6', '8f125e3b053c0f80a6182cc5', '049fb43f09ae244560ee52a7', '54afc6318164ae9f335372fe', '3e2742de9d17a14d3e82aa41', 'cb5360f692863a0eab68182e', '91d0d988d9caf739b370a0af', '297288464d61d257567d25a2', 'a7deec7678c37db84888ba96', '6f420047cefd3ec90873fd93', 'a8704a105b87163e999ca81d', '37949c207b150e40794621cb', '00854efb1da3fe176150292d', 'b0dd61356a38fe4d8c8eda84', '6b1ddc68db0377487658c10b', '233c13143fc7c9d92e63dbb4', '760fc9ca5ebd74a67d09783d', 'f4cfc4a663fd49aeace78486', '055f3e16faecc90b5ba954f2', '44091b4ad36dad1ed6a3d8b1', '25c653da4cccc0b0dec24e49', '5a5b63cc59222e36f5a0e0ea', '522b43ceabd524cfde7e3316', '903e1faa90ee9926eebe6781', 'a9d61cc491cc934c6edf1a8c', '447ce94b8c1311a33e0848fc', '5bfa45301dea4f2fbecbb26b', '6088d9d109938b6b36160f41', '195ea0933db24ed2ac3c0a71', 'e1e75ab26d91e343b7b0ea17', 'e93f9ba8d8777339be3240be', '392945487423b16d5daec3fe', 'fceaf877c094825a80b15f57', '264556fad0e8f61d4b7fe7e9', 'd4183c39d460be6d47009fdd', 'd5968ba9a98b70f548218263', 'f375194eb5908ee511e720c4', '1ed10993a5584026aae83537', '88b0fb242af55f296a52b5d8', '3438f141d7038a0bf312f74b', 'f0fa794eb149befc0d010275', '146e130f4ab60443b1facefb', '4449c0b54dc6e4a7af5dc9d8', '2c0f498a16183e884d741e15', 'ceb8581ad32d0000864d6c0b', '837818ce3b6b8d41acc4c4ea', 'f8c155d806d238a7b40fccc9', '3f49eeea52db301754082dc6', 'dbb471287262410819ef2986', 'd8f365a561e69cca2b2fea83', '6a368f5c49fd5add94776985', '8b02463508e571bad82c1b76', '44962ace42f808407fa6647a', '45cf63c5e6579e640cddd3b1', '2dfbec4e54ac5d6edf34216d', 'ed7775067dbd67782c081e36', '3a071ace73b6a8ed27c95001', '728bd4f1812fb837f2f3ff6b', 'eb6a1301664df928ab91d795', 'e280cc138d720a1fb7cde282', '704f14d72d85257a378afe42', 'c0a87bdad4a3ac34d3210642', '11f8c5631939928ad4f53641', '47ca8eab856cae1f24914f04', '3aa3f14b20280118b146135d', 'e63b87cee280daecb46a2af6', '1d69c2e9a177101cfd62efed', '6cb0d732bdcaaf606d0b499a', '2b73e239d32f4e598b39620c', 'aea39d595c762f58e94e6bc6', 'c0abdf612c0f0fba7baee7ec', 'e1dd13daac1ecaf666f55bc2', '95bf452438092fdf90c9955f', '226565b9dfa316da14138b50', '0577ee51b3ad3c9fcf8fbbae', 'c70358d01148240eb97f8568', 'c72069fe9515604ba1be94c3', '92360fdf128eef86912196c6', 'bfd7a42fc2f55f570373a0ef', '8b5709aba37b6339722a0855', '726a0de52d59010c160bbe92', '9259d15f15a7db0e59aaff9d', '9645c89ce0e75ea8d9ab156a', 'fbb777a428c35d8695cc62d5', '4fbd8deeeee7c2df137faa1a', '8647d1bf21a4ae9c764a0b98', '6d8c0ea325ed343de1ad7c30', '06c9202911fa52427beba085', 'ecd2a10f46954975185155af', '0f415abf215849df3c74d8fb', 'bbd3ab3b5e2878e0c7d8dc79', 'a291e9eb06fbda894cbb7a33', '133e29afd664c35e8accca09', '7b04b1222708b5e1f1411219', 'c72ddd4c729a31793b216593', '9536521393863e42357a143b', 'a8f5c987ca37c40bc1eac5cc', 'bef2c1e139eac11ba6f699ee', '4e9096d82b904f68fcb8006c', 'ecfdce415b13a6552ae21b5a', '304ffa7e26d4e39086d0933b', 'cf6c8c0873569e3fe49b7317', '11bbd36c75760dc9c37a98e7', '88a7f40a049ecb037fdb2016', 'b17a81cf82fe8e6f3d0705eb', '586ca890e966f98f077187c9', '3f66ff390a54bf2f82dedd51', 'f9c16377338fec42f126a765', 'fb3d9d6acc0abd876c53799f', '37bfc037c806a2407d309d50', '4f945a0ea52625d2facbf443', 'd4efc7e55f28c5602d3467ae', '13540fd048d7adb5f077165f', '2202303447142eaeb02bfd69', 'a8bfb5881309bbc205af6f0e', '01c02f4b897bb8192e16bd1d', 'a6fc04dbbe1e0ba75ba30f18', '2ddc5aa70252d046606081e2', '967175d0df47b1226680f9bc', '9de280a78a2a5c2a9872c3b4', '4711ca09480e8240ce0059df', 'c0b58eb14940edd013085528', 'e27430eb77cfd3fc0183209f', '3b1ed5c49626132195b70ec8', '9247b77bedc088fb1beb2f9c', 'a7419fe163e1296529d925bc', '90029829a3c76198a7de717b', '6c0364360a42833597617b98', '6a7adc80e43e20c9c20e21aa', '77ae0d9711456146d89f58ea', 'bd799ac5e9eb3fc8ae226402', '802527c0be8a9149dbd4a8eb', 'f4ea3a1a0ad748d9673ee4c3', '3f37877d41058e4ed337aadb', 'bdb2fa4bcffae40f48f57a25', '11e5506de71d3706a53ac1ab', 'c84dfff5f8753a12aab6815f', '935b75442d1b950e70d20b8f', 'ff717f132bef7b20380c93f7', 'bf1ccb5ac4a847d66be6bc96', '7cbf3d09dcab163910469c88', 'e157dcdbd534ede0dfd40a1f', 'be83182a8a89eceb013c4764', '1697a8cad9b6a471e01ec05a', 'cc8133f15a89f38b3c28c9e9', '65b2855ba05f13d02f85adcd', '399156b9ba93c105aec739fd', '32d7327a3beff353c0d3b98e', 'c3ec4bb31cef4c9d976a8b02', '0a0992495803104da30af972', '0702bc77d929f78085010bb0', '2561607a3178d1491081ba75', '5969b3f1a95b57d848d81e86', 'bc55adec6e2f148eae8ab156', '4d42e61430e34d4e1be887dc', '90c223d20a0599528657b6d3', 'aa5ad9ebeb0fafd7b1afae6f', '6866d0c0c9db304d897bd1b8', '5bdb71007a2f5b2c33e4bd71', 'b562038e8a76b7d15b8694eb', 'f0f7a54c7ede3f83d04bd4df', '84864ac527ad8527348ec48a', '2a882b413da76b5d3b4d828a', '4afe78a50dbf480375c2d614', '9c7b53fbe9d379b7315c6ec8', 'cf40d706cfc1f0846399ec24', '7e6b0e29fe9f32760b7fcfc5', 'bfd437d57f4e32153e438f0c', 'd594afe3713d185962186bc5', 'e9a36293a5d2d223562338c9', 'ad18efa8d9a3881fbc51b4ea', '196b4c9d5405c65e47b0c14d', 'f8a06b403db41f5348bf90f8', '0f1dd768a428334842bfec50', '7cefa5cf7a599ae5c96e8eb5', '0cf19476dc727db127ab20bf', 'f6014eac249a07ee280d9634', '7866a9173d7aff1bce72d3a6', 'a62df61b51406f3e15d17418', '0f0a1891025fdcedc7e8ea0d', '3c053c9b8b903c510ca0c818', 'c62c1e4f5598bb12f5d680d7', '05c1bc3943f37d24fbc4a227', 'c8111e2baf3638b5ee8951da', '7bd7e129fb3ef8370555bf1b', '98f2f619a8c325c797be99a3', '32955b67aaf8c2bd57e9ef2b', '3e53f449eb365ab960c6aa59', '503c5dc62ab633d813594e59', 'cb2de03e599b89ef00694c72', '7c1e5985e0e94a843e2c335a', '962c0dd05a16f3d046055b17', '1f40a273d375689f569acb2e', '6033e2bfc3a0657f188b7149', '52f3a2c6b4d044c06fd15131', '16a44e61297946c6928ab617', 'bbe597ef5bc885d0751caef3', 'f1cc5fc4c2d7e41e0b9536dd', 'fd81b513857342c1199e0cf2', '69d6df3a555ac16f922234f9', '9460f94a4daa58493e8ebbed', '9fec7adf6776835d66f06d90', '259109556cec2005a9ea3db8', 'c26a679f2556db96814fe4aa', '1ab67d97d6f153a086427f61', 'd3693b3ee981749f8a199c7b', '7597553ab7e09923b877dd3e', '287474d13b646c19858f98f7', 'e73df961ffb6ab9df8d8eeab', '24bf28822b415fe4f9bd906c', '5d3b63e510deecde492912dc', 'a903f7427fcbfe8c1598e7c7', 'a064cc53a6478ab0d31cb958', '51b0ff1fc9bfcd9831928425', '224fe50640fe06e9fd64e1cd', '59ecedfe8f2703a51503c566', 'd1054cc1b2ffa4b3b7000b34', '9b0199c77936ada6960d0213', '50179ff508b40f8259d4eb6e', '64d22396919485e14c973f06', '4ba1843465e5f775b2a892a8', '79cd6dad6ad9f5ff2c2684e6', 'db710bbbad258467ce5d73b8', '39881273c6b26ba01d54e3ee', '3bf2d40135249f916f915ace', '55fe6d305b76e501677eed35', '6a7c1eb2cf2a97c8f56e8695', '0abf006890a1a4993c0e275b', '26a928038c08abff85fc25c5', '23e582ea53646d1236eee37e', '27f061fabd9f7d2e99e832c3', '92672fa0de871a17570f6c7b', '2c69aa2c7d2c6989277b55bb', '7d276bb7858da3e756c5b278', 'fabc39d4768ddcfc1eaea089', 'df115de912364769eda352c1', '2c618c0f46c3debf9a6fcad3', 'e5feed6651e93e164fbd7c11', '880b5cd212d4e5ed720e455e', 'ea46c6446f611ab80789ec15', 'd0e1bf41e5fd8ca04ae79ba4', '18b181c1e5e0cb0999cf255c', '42ab873a23dd37a3c747c4a1', '15a0bb3f4f2f12a28f041dd2', 'd9a1e858931b19e914db92c6', '4c0ba2326075b47121880872', '053a84a3939291b5875a4bb2', 'c4b9d1ad637c92074a327167', 'b5d0db7b72d315ea5e4647b0', 'a693683961d00b054d159be0', 'f4a479361b2f03676b79359d', '50d49912da164775f9dc831f', '12f5279f948c5fccb5f94517', '1b93bd516c9f2988ad2965d8', 'd1177dfd4cf0c6b2da2111a1', 'e0581975db0c811fc20544d6', '32041f1a421a46a1ede56482', '299e7e4682125161d8892193', 'f750f0fa41e0b4e4dbe37ba3', 'fc990cb9419776227c9994e7', '6daaebd1833641ba81afc130', '6fede59c21de596953ecde6a', '5bd9ccae8a4d90eca4b4002c', '99266f3b67eb6112916a4b55', 'd72835768250c3efcfb0ef0f', '6d09ba5be77b8bf9cc8b08a8', '97b55cd17bce748e8c767456', 'dc77bd8543dca1e8f57847aa', '898a1010e152158643c29ae2', '1209cc6f2d89e79f32b5b025', 'd0ae32ba9d0feee58d99a6bc', 'ef9e46557f7fe863d42a695e', 'c4b38e4af79858745e77342a', '4aeee894b32b67b1daf7f21d', 'c90f896b24cab48d06c88f3d', 'a544c5a0f893e479f14079f0', 'acc452348f26357e7eee2d70', 'b49883cb372deacf8d0d0392', '2ad3296a49ba1754c226eef3', 'bf3cde9944a2d256d7dea6dd', '221b036ed4f338f8d4bd1c8a', '2977de037421f92addee92ab', 'a02303e787c9c6d217b02035', '8511198e010ebb4b33fcc4e3', '5deee54b966c7e4660cedfb8', 'ffa10298ec3846d375cbd553', '6f1219fa346b449ef48710c1', 'e98f22d20d446f796e001b97', 'b0e746871a7c5eea41ef06b4', '1d4b0f83e48e3a972b624537', '3203c674e0262061c0e9ecc5', '42cb30e92eb50866f96a3d15', 'e328aff459ba450aa7b31950', 'ddcee3c0f498777f0ac3fe7c', 'd8f75bffa5cc49d6e7389a89', '67ea2ec7c02ee83ea4a04d59', '75054e4a84c29aca4b3607df', '654bb26fa8a99fc375bca767', '0ebcf64e6e88ffe234e3a991', '010b98b4248d540f98a42319', '3f82eece23e0481c1ab26586', '347b35d5873783b49e222bc6', '9e244cb537e766b890782d9a', '4f0a03f732e95fdcb15376f7', '01f974128b8f1c4383263191', '95523c3c68ef7d68aa2cd797', '2bdbdd95fe3cb63a5fe57218', 'b6ef3b8f901f6515811991a6', '97d4f5fa5be6b24ab07da93f', '82c36b2b9cc4fe915955f4ec', '39d219c7d6cf5c42a50daf25', '764bf48effd7c27c0d7ddc70', 'f7778f20f71116c2c62f29b8', '74f00dc121afbe12df42ad01', 'f9b43f1daa9180b4970abafe', 'fe6a7a8b896a7b2e6cd69e64', '45fe917c7821d64a778aee8e', '1bd83a6f25d3ac9d966ec9e9', 'a00135dbda426f37103c4031', '76c3866059784b87210a1f13', '8730272c87597016340a1b9a', 'baba1d99e845eb5d22b1c46a', '3d9d7abd6d9d5b5188725536', 'e2ce9bb566451b1c9b9ba7ee', '7e84feafb736e70b619b4009', '4c0c525de0bed58277a23a11', '66c9f492519459a4e0775016', '8c021f1784d97cc1eb00efeb', 'bbd83d8b93e5221cf79488b1', '742320113523a87f95b0f270', '290e46c4e70581545b39621a', '76898a2087c25f36caa4339c', '493b74ce7611de520a722436', 'fa77bf576a4300f065e04807', 'a370a79ac614fe8fa9d3408a', 'c8f9a04c499ddf84d314c397', '136857d990a96067b0872cae', '722720600298a5f82bca4716', '2da4a2b003a50f04b2d7623f', 'b6084da68e989df297fd4021', '89aa1f3b263599aa7da317e8', '41edf4dce9244c624133d08a', 'c5f0f757c748ca958da5182f', '07c43928bf97ed8bc8540e78', '53ac27ef5178d9758e371569', 'fb100dfee04065d29677af93', '43ac9cba569c151427df4304', '5cf80e270db47987d26f8d2c', 'ed72f24083966a774f22b122', 'b8c83d640d2fe3594c7c2cb3', '0e480dd5efb5afb7821bf264', 'bc084c489813e1e8df25c4c3', '41a9d1565306cee37678be20', 'a431657836c3ed7ccacaf64a', '73cbfeea05bf53b8f480cd6a', '298e26144b0f329a5a0615a2', '3f5ac405fb5c105f76ea0b91', '5732b3a1da02702d943f84d4', '1e43adf0cab50573f8e61e90', '3b5a20289fcb449af1962529', '1aa68945724425b2f49cb5f1', 'e1b2ba03357e942fcffc9832', '91405986ac7029c89c4e111c', '04aa90b4226c2ae74327b579', '093bd4e875cc23f9739cdd09', '3aab4c6e3c824c26d1f50ebe', '323d3cb95ad2c7d62dfd8cb3', 'b9fee2e62bcc843043e0a954', '74cb952e6290049d94447a5f', '9ab4162dbb0abdcc190c4d21', 'd6ed2ef486b7d554f4160ba6', '3de9617a7e8dcc80de879fc5', 'e369e10b6bd8a83d98f15e53', '6b59462d8c8e0692f930ee62', '7c2d471282f8777074560c57', '6084f134b156953797d6aff8', '9650f7dfbf4442af6df9fb82', '8155288647172c49b5a66196', '574263846551eca2f19ac645', 'c8c508b6537bf061dae5066a', '257b96b1dd73002157d478e9', 'cb26755fc90d31c8a991b39a', '163e20b7886f513a8897df5b', '8de8d255ebcc53e5933862db', '2694b78056d19869dc331d60', '409925c52ea74d305cc42742', '355c64d2875efbf6a8cd7683', '00bbbffdff5ee0427911211a', '78f0e0fcc6e1ea0b7d221630', 'adfe9182219ecbbfa21f841f', '737c9f23dfb633b9095279c8', '486691bb6da24ab4f1918724', '693d2161daa94f0ac19a5ff2', 'f42f69255942463a3df596bb', '5ccf5c391f79452b6224e1f6', 'ad2310914d9164e853dba7ed', 'a86aa0f3bbf78e814aab9af4', 'c07d03f18cb3b7eb6a97c463', '1ec2b4e6ddcdc9a62d1209df', '19aa80f1a14f42697fdcba60', '003276cc7c1bc688813d5aca', '1b7a372bc73c1b3e5e13c41d', '2ecf6ed7b588701c5b61916c', '65209ec4d53fcc5e5cd03c87', 'accce2ad12559dd458516192', '1d938ae21a7a7d593616d380', '3ac674efda7af01b7217b1a5', 'ecaacdc4fbb0dd2635df78f1', '9b96ce996e808fd4f87d1eee', 'ddf32de215f19f42c2a8ddf6', 'b6b5cdff0364757e59ebb7a4', 'a762ae81d4a2a3d7d99c19e7', '5cf893b312b240832f404b18', 'd3c7771380374c5d73ffd28f', '2e16f3d29c3aeed69b6e3b78', '5c292b2eff5ea33b4c5658b2', 'e8441aac72dc1ce7428bd942', '42ed29ca7381139bed4af657', '3cf174e9abff40de817ec43c', '801278f003c473902d05fa06', '0f42767e5be8f1f3825dbebf', '02759807d268a649ffbc56e0', '1a35a4ed34f622e32e8c72ee', '8575bf6a21bdfbbe6b80a4ab', '9f046b17ea9354be7cebea95', '11cc0c3c5ddde55f2933b0a4', '2e5708405e832d182494a66b', '99fccf1659e27afc7dd17ad2', '2cf0ff14f070a284cf574db2', 'aa2c37cca4ef58130e2faadd', 'f93cc51e5d7120ee4b957451', 'd5306618a151094326d339bc', '69670441a1821ea09ab84daa', '2f5d42ba584507b3ec8786a4', '7fb6c6e5361721f050111d9f', 'e7b0a2fb743b8d418360896e', '8022e43f6d6b61363a0e1da2', '22a17e0cd02cf807c470a259', 'eb2f419e7f09df1b43df8f92', 'bb2aaeceb6f9b4fb421cf918', '5cccb67414afa9206d2624db', 'cdf6333e8b6736879a871a9a', '3ac2379c5a6246bfa08fe92d', '25036a06119f918d2956f2e6', '79356e6c9fbb5a33aa5bf030', 'c916df49979cb247be8c50a6', '19dd65ead0ee8862ebf01011', 'b14e62dc0fdb8c7bba510c8a', '76de61af821cbfa636cc92fe', 'a1a26b44387af2430b609395', '5330e3cf45faedb3477005e6', 'd7a8e332af537a76ab296df1', '0a43e2fe814473ab9035db70', '9c3f5b2ff13b604dcdc88353', '15f5e817e7a5d3115e1563e0', '811775f5b19375275b6b4825', 'a39e1668093aab21fc2f126e', 'ee04db0976616af28ba6a8a5', '54258b49d9028f2fcc83e6d8', 'cac51b303e4b48200febb2a0', 'f65af6870b5d460f82233782', '9068933037510c1817c920bd', '97972bbea1fe2404f8de1b69', '7a904ffff26972cedcca0166', '09b1b086d491d385b6744dd6', '8bfd5025332346ae9908634c', 'babb2410ee949a2d7a609b15', 'c321346f08463a3979f09efe', '3e3f93fb3a2e4577befd898b', '22386e52d5ee964fb29ac28b', '6fc987dbdba9f552b5be7f44', '62ce1e3f90c3aa7b3c7ffd03', '94401d1b08ae71f5ad65ac7b', 'f2265be3b7f96b9827e002f2', '5c8ae752cc0cbe2cb6d28a89', '6012b1badcebf4d12139de0e', '612351f75cf9c16873706c46', '577572963a504b16ab2aced7', 'ffbd9d197177ca7b317f66cb', '1d930d1bc64cf3b52d4cfe25', '388eba2ee935cfefacdbbcf6', '98340bd550d51478d6ada232', '692d3013b67039704bfb1551', '3eee431c56b7e26f4a97d69f', 'ec4e31f512d6319b08a78d92', '68abea0b746f09a1730c8a20', '5768d20678cf5c0dad75054a', '9074ac00135a21bec34e6199', 'cba569373f71ae7e9628bf97', 'b3c91b713aa0b269e1c13630', 'd8cfaf1fb8e89c395bcfc473', 'a1faad0653a8f9dc687564e5', '1153c548a9a77ae4687c8846', '0d22269bdd7bfa8481b101b5', '33c954c2cec837a4ccd734f7', 'bf0f46e8fb7361b565f0acd6', 'ae4b7b569f1122fb6951ca6f', '304008138415ff886f9fa539', '27c5230565a9e53ebebd7913', '6b93b67bb974684b413b3c6a', '4cb5de3e5bd12beac4b15b14', '3f3da5d3397a4a8fe3d6fa12', '0d012e621517a4059d3caf10', '7b5324a4c69137200e0d74e2', '848a65292fc28285ffa82551', '26b5659defc710e97b8055d7', '24ad21be2a942f6c761d77d7', 'db84c0e7a45cffa783b0950f', 'd683e1297440d54816fb0549', 'b2d904b2d1f152b67f7b2b51', '0f47e5f69b9a81be1ceeb52c', '934088633430fb5451e8191e', 'db0b8e8e0ddcba04c82bb7f0', '8444ba22b9c952cf50e50901', '479ae3deb06c95266bad80c8', '22e1a21fc783d4bd45120187', '8e476e63901b7be2cdb602f9', '8b4571147c610648de61a6ab', '26ea9369abea20ebb7ca20ae', 'bad5c823a031437e5a7ff621', '80583d948d18de33fb6987b2', '5a7a92c1e36cc66dc5a226ab', 'b6ebd9e060d890c353600a6a', '8a73eab771e03264c24fffde', '49d1bd3a4560ab072f7825a7', '7e0d52249e45d956b457e7f7', 'caaf86100f832f6892b85b8f', 'bbd60fbc1489752c6364f8bf', '84f5dabf19eb4e0fd354fbef', '60eba7103445142138d17aea', '3fad6d968be4660d18e4a33a', 'cdd34197e0de15595e116b81', '24dea0b7b119c44087400b3d', 'd83c8510ff1184c1d92ff459', '6bffa26dd035a9778fad2e76', '239fb5f5541fdf88fed6bf3c', 'c35347e6b1dda9ed6764a067', '5f932af6bf46cd7718dfafc4', '5c3f52d548353aad5447d804', '666412cc886fa97817ea1d59', '95475af06738ffe0fb4f1c65', 'd048cd029e1afe980ed96d08', '1f1add74c7e3a0f4247c5a78', '5487ee77cca76c582ae0fd80', '2599f881605016f342ed4ad8', '7b2aaf2bdc86d0afb00d3cef', '3cc0342acbb3992a4b0cf40b', 'a112ad7cd8202090ededa192', '65a61f863c5c62e515fe477a', '42b27d5b68477ed32b23938a', 'd33831f0ec31a6a9c49b16ff', '7da203f6a27901736f057b8c', '5933a57b83835c59ed518dbf', 'b0e46f47baaef8c5efa0dcdb', '20b78d286ce05435b56b849f', '253143bdf2322f6137ab6d66', '72be988adaa416d79f2d4060', '181fd571160a6bf269e75dda', '9b39448454fb368c2b7fb229', '42b0089e4e28f35c3bd7f8e5', 'ddc7e149237d42b52700d717', '73c5a29239e229c1e3d8d5f1', 'a5a346eb9f19336f14d5a615', '5e2dc38de1c3863efdd5f7b6', 'fe2ca53dea49bfb8f192692f', 'f97a37d5ea7b54467da5e351', 'd1848715fb9bd76d88e82c49', '8c1904ba5ce5733337e19e75', '588567d3a7f9d7e575cf5435', '3756db86af40c5904040408f', 'fdd3a31fb9173995b776c5b2', '5a89407a39c4cd1be3abc4f2', '0a403bb61217529f94970734', '3b9849548e56c59f768d5447', 'e626a72073cf3197a0efbd87', 'd4bd03642b6b6c5ff9cd88ac', '9f7246b3b545ea28dc8ff5ad', '9f35654e31c2a74dccf4e709', '40e8dd3b84d22a385983c8f7', '6971ce16d647c323dc5a6150', '93736e989193b9f5bc0fbdff', 'f361e5d739050e86c0f5c75f', 'e9dd16ce54ed38fae39646d8', '573ae8f84da94b97d13dd488', '4dffe3f7f7770e47d3e5fdc8', 'fd8bbc85aa480d84c446fef0', 'facfba9ab5edcbd30634f5b1', 'fa4dfaaf2645d182bd7337d2', 'f294c7fe72b5826f97ff068a', 'f6bc08951df014b4c74d7be6', '197b621f36437cbb2e24f71e', '46943daaedc4da5c2540a50c', '4086b5f6f40bd2dfb3952f6d', '336b4ae66fafe9409bbf3780', 'e630dab0aeb52cb103a0b242', '3377c0495e0a4873b8d561c0', '13bf5b0281c0d443bd4ea538', '3c1f961554b4f7004f28ef81', '32e5482d088de481d141565d', 'e7fa38bcee63c4dff174564d', 'eb9fcf1a569a58fe71b1b257', 'a61da9b50a816c216dab4107', 'e7aa4b2720464fe5f689b5f0', '5005d7619cfd562a1af8ba4e', '55f66285eac844245d46c2a6', '23bba64a79ae703a2b84c6e6', 'ec028c849e3b43c508834d3c', '4d08394da0f7341675850575', '2815edbcab8252d5b617ad55', 'd11649ef6f1e014d999ead71', '0a5e5b2f22a73ebf9ddd7a3a', '99ec0658e0c4b37ac1798c46', '0ff24db141cbffff8252d7e6', '75cb3e513ae45223b3f00a57', '8b6ecc1e8d51fdbbd657d6be', 'df128c1c320ab7a3577dbe3e', 'ebd3a49f285aab80f2f09b02', '5da552e4bce7844817e8e4ec', '64dfb6c9030d4565fdcadb6f', '92de51735371a46e81acc845', 'a36cdf4e546071a6ffd31158', '91f98b68f8351708b09a3b5f', '08b21636e8a003182b06159f', '3e872f05856966755e671a77', '45892e6b5af0f6b70b5c1edd', '54b2b03726835ece7168728e', '78bac4549cb2e3ad9fa2a04f', 'ef941c1feaedb7696f5f3fda', 'e65595aa4d0b66d5c6625a99', 'fb08961df2b632f9644c112c', '9e64c0910dc58e2ef996f7c0', 'fd1fe8945ba7f1d84a6e557a', '05bb819666668fc43bad2666', '1c1615f9c154aca940cea316', '14e43b77aa10ac246694f9f5', '29af2e5e1ea84750efeb2ac2', '3280dd533a7cef123247bde5', 'b8e9f61b8a98b3f23dc93f99', 'd6121ad75765bc51dceaf4c9', '05ffeff678368c17b77078d6', 'bca0d0989ef1a590d9a72d9f', '103e589c49e80280c9f04475', '82d8a7640bee5ba7059a425f', 'aed29b51a927aae66b5d4811', 'adcbe9f6b33c50d6f8540cda', '1b86b72d44dcdc58ba833804', 'f859ac724e0f730a950f3efa', 'c509b3b51764a1c88c5721c0', 'f548e5423305443cc9bd89c3', 'b51cf6ccd388a090596b77a3', '2c475b369cef5f55de67b63f', '85c838d478a4f152e0c9879e', '617a17c6fecd772da2fb9fb1', 'f7259128c751b9fb354668d9', '0d0fa264d945b5ef90978c92', '1f55785a38dfb75deb3bfb40', '08777eb92c5be85c5613f0dd', 'a4da025718f83d20130260ea', '671afd8de1d5bdb9e0151ce2', 'bd35ad803e2438c6ada8a6b8', '53ad3791f3c9399dbc8de0c3', '8112593e7e23d761e0584c76', '9997157eb5c508f263b4a2b0', '8aff2d41878a4fe47a7284aa', '3c1cd712d2ed352c132bd2ce', '732c03e81ef4b688df802e29', '0b0a39c4b7112434084d3daa', '73df5b035a5cac7c093f1211', 'a1b0068465d08286b72f7de4', '8f9580ef1cb64c4525680b2f', '5103a06a571d43b9da46cda7', '8174f666b42de86d7c8231a4', '74fa66a731eaa7d33a261eba', 'b2f9b52ce74d61a7d5f2395b', '2985a08b2d895846538fee43', '7d9bd95cb1ec8590bac2746b', '329d0bb92a0e71548c78f544', '70b635d6cbd4d6a5cf0cccfa', '09f8601bdd6e63b61b06c516', '870ff7dd4c46ed086c2c0376', 'e238659bcf9847845f0c8f30', 'be826cd58248f2874aea7651', '4fc4a020a5a905fbea065ca7', '46a12514c3bab25439a23710', 'fec62efd2a043cb3d54efd38', '4f618d2298a9d6c65fb3663a', 'b94c880fccb8435757f8e05b', 'faa2fbd6a8db7bed5790ed25', '4bb969590b7a2c2464c7bb44', 'd557347f082c26133868efb1', 'f9db2f1ae379485d2157c06b', '9d5b103ab75bc4e5ec507f0a', '55351822938c1ebf04f6ef79', 'c49e0c36f1c60e8aa2266956', '94c68a26042492f18d7f5c60', 'a8feb694e864b90b3695fce8', 'cf5d62cfdfa23393641e93c8', '5ec192bf57a5dff7718502ec', 'b2f05f5bfed93860e52c33a1', 'e23231367907b1d48afece71', '5852e743e53e91715cff50d3', '402d46f2e8f68504cd726d4d', '3d09ada3209f58b132f11030', 'b180907473d137cd5300bdf3', '828e19c5d77504383bc65778', 'ccf60f7cf6c692a95a30282b', 'adac729f5e8b6d9ceaf2e454', '715cc33a6ffeecdcb8a10831', 'ab2f0e488953985801236fef', '3ec7578f9e5421f0bb600bba', 'f7f753ce0654fdfa9372170c', '44760a38638babf2a64cc994', '171cf2d1223b4c0cf47224a0', '962f54bae45dac154aceeff8', '2dab95be5e31c24b8faf79af', 'cbf4196ee5e84e090f100adc', '34c3cfba23a6aea2edea8258', '1f9734484a9b32294e2074f6', '8f70e1a5c112b725c727aa5f', '0ef494b07803a61541c81c39', 'a05f05a145b8f405f9806503', '4922b8ae8ec599e46be0d3fd', '17f4467f2df64009e1488314', '94755e6b478aeba5727b4e48', '1fce91ac7d4616dbd3d5e553', '59daa834db9cb79898f3fd0a', 'bb33d9aaae83079fd82f447c', 'cf4c736cc4981a9620e461f1', '967f7af09db9a6588372dd08', 'f1793d9feb28aa3f3a967ac0', '5affe0101c73cff03b406bc4', 'af0aebe56b9ba4ef18fc069e', '8dc8ec5a03ea1ca7d6e6ab61', '34d35219cf5cee5e523e2aee', '8872e8194031b7a1b90a947e', '3885ff6e85e14bbbea0b4eff', '75fa2277ef7469e3671dc5c3', '7e01496c0bdab387e4206cef', '69894e5b9ebb66c422ce494b', '8492930a486ac576898bc56f', 'e1d6b3c8dc1692a66dc9e4ca', '2faac776a2670e5bc963be72', 'eb1a17e4b06769e93f7e9dde', 'dec00286fa27a5ad2733a390', '98a2c71cb7a345e33b540fa5', '656594961d1d8a3fa8621b08', 'bbc4ae682cbe306058b69697', '08d2a4526185ff9acc78cd4a', '49a63036b0be26e9a3840e94', '7bb770bb85dfce808cf2af8f', '9d9795b2d1188111ebac1adb', '49cd1a4d33ebf0b054a31ab6', 'f2b88cd7d540d8f1867f8967', 'eec15a4117409a3f6ef25178', '6f075a2aee3f6ff30875854d', '5ab2547b8cb6265ed909144a', '2e2db3c4f125d84161db9452', '6f8662ab40083c44bec183b5', 'a78fb4bbcf3f2a6873da194c', 'e23751d25ce4eb63dc8c3d37', '9c923e2f1e259366ec2c0f4e', '3a18a1e6c6c51e9ed15ed856', 'dd5c722eb0347ddbfcccd814', '6f986bf79221b52b9dd0440f', '851c9ffac76b05219f791ebf', '29142fe9101ea35d798c84b2', '510737acf7ef19e7074ec198', '662bfa231343947caa022b07', '1cd63eedfcaf1729936509d1', 'd62eb4e8f33da028984990cf', '8dc16ff538447b0e387c7d34', '3eab12ed9af00f0beaf6f7d1', 'a8a0ef78b032393b750a7bd9', 'da5f5e2cbe3bcc2e822a2aa0', 'dd63fa49a61146ca3bf28ee5', '408b91419db2939864b10676', 'ae4c3935738d2e1bd1ee38c2', '8654d6404699c4126b513f90', 'c205b51f6231b94810bd8849', '6d8b67dc5b7691af8bcd4937', '75349759bb3df71a7b6f7649', '1c5f16182f446c154f204081', '03e018e5065829295de0817f', 'c6e9f8b7ab342b4f62878e06', 'e1a987c52eaba2b8697dbc00', 'a4b7670404c595bc4689c577', '425e31a5bea537ada730003e', '3bbc83c195a74b99b51777c9', 'bb7840631855547af8253009', '3a5ab4d7328a4d17c25ac1f9', '78c1ef777fd6564ef1b1164f', '6f9e8ee2deac4ff0313cfd13', '65a768c5a05156a43362b231', '91c2a89a059f3c099a994282', 'fbeef7a4b32462cf2f85c7ab', 'e48b5607cc89f2dc1adfa775', '33d0ec324183f0e65eb1f466', 'a1218eb18f008a05c5c527e8', '23d5a55f9d6248b8d743d970', '4e9b234a6ce9fa0007c2e212', 'bb12c577d54cdbb658f77087', '84bfcde2dd95748732f9e8a4', 'f515f06bef679a5069bf1b69', 'f6ad015f8e12733510bfd83d', '0874a8eb9ae4f8b6bb50a1d4', 'e2b25103644606a2debc3586', '546a49550415320fbb9316ad', '5bf08c9869d070204f3790e2', 'f19baaf7b04bf9e553dd2cbf', '167a500ff70d846339538bb9', '40f3aab550a4fd091b0e4468', 'ecbcf154c6dfea64fea97371', '6ed7efd8318499e011227c1c', '5e93d590379eb00b3a76b6aa', '94b617e6ff37a625db538e00', 'c4fbaf36df80d6e9685e37c1', 'f308aa77cb5c6fd783755cf4', '098b1301820b7d581a339d0f', 'f870fc9332fe7c3778488b46', '21b5d63e1046e143cef88adf', 'ed9a4d3d34a8ae1c9e013631', '975c987c6333e4a188a0a375', '62458787b60bd28c2b337541', 'aef5e5dbf6c5848167e2f641', 'd57dc0bf4122ea92cbe3fbbf', 'dcfe3d31d256b6f0069568e5', '1e60f35bb520bb22a0d6dcf1', 'e47e7e616f3d5838b2aa30eb', '7ec0ab7e9f87fb5c34405276', '0901f19617fd97688d40bbbd', 'f3ecb8116711437750ac3fb5', '0814561e80d18ee7b5e8e214', 'ebdf09b1cf8d52950fe299a1', '024e5c4760ca03ad0215c516', '0ef0e1be7cef42de551d0ac7', 'a2c56aa731442cc35b8f88dc', '475d57ff575806d5690ed031', '37fa4b05690e4fda0cc395bf', 'ba16c2749e29db98a6103a5f', '4483be10999dcd201f1ef4fe', '5ec73b90a9326c7868163c73', 'b4c01b9c3a018f29ade4acf5', 'fbd014c02af79a2d9c53a9d0', '1e7f92fd5a7fad376555b6c5', '67d324104c936264768323f1', '354ec0afe942f8cf2f5c706e', '84a492082c7e8112ea7f1544', 'd2963971f5b061724d770e2c', '3cfbe0e30b718f625d69a2c5', '0424a90b6986dc6ca2da8b3b', '86e5eb5831ba084a42761fa6', '28df687aecadf8f1d696c1f6', 'fc919be1cf3be39f5788b8c3', 'c6af3f026c0e32b6e92878fe', 'ce863b6ee4d6d50f7003ce48', '7418b9331c35714137e940b5', '2bb75165325ab535ac14bae8', '152ff0308ad4afd9693231f2', '0741b96a36302acf8ace5c02', '44fca1429144bd57023476d8', 'f719a14ae6e71d9f9de23e63', '0edf383920d07410f686cb96', 'd0821c0025ab0c979c7f89c2', '195a853f0ef04bb3011b271b', '7a87b3514162ac542fd54a50', 'b30404be1d0cdffef60e38c6', '55106da0f8f7722ca97968ca', '6b5b9ccd032dd84eb4439664', '223c28432258577bfde7c6ee', 'b7f15ad17e5a4047c43d42e6', '6a3568128f729d82972746f2', '6f3c178cf388c0f60f63cd4a', 'bf6f9f9621257cc2c12df1dc', '30e8031670f0d3838d940ec4', '7cee0315da660d7678b612e3', '1c752280e681b6e8e598bdae', '4d0cbd90ae58506f9467785f', '62161016f653e9cf862c97dd', '0f1253fab8016b9da9f6e223', '7c5c504415d7c151349eda86', '6138410041007bba41d241af', 'bbcd893acd5b02637bedbb4d', '4ca27aac7d23ace022562d03', '8694ace52a01f31ca53cc69a', '82497b82db1a47d9940db063', 'a0fe46cb093192a88d6cf061', '381c1509334fff03b367f5e0', '7b4a60c5a197fac6bff1cdf5', '3591d10cf8e7b2175165ea6c', '3744204f6970ebf11f57c0ba', '1153946181f7d7b47dbdc917', '74693de7d313f1576fec3036', '46f0cc9294673a19abea3ead', 'be48ba72929ed97720c91848', '5d7c5f7770c961d7c84c8499', 'adf57bf6800cbd7a1bcce75f', '398270a5b400092bfc10afcb', 'cdeaa55f2c3e7ba95eec9c4a', '718c27e2ef2f6d9f2a3210f8', '1eb6a80e3bcffd099385b474', 'f06966c4eb707fc9298cf8ed', '53b8eec71a9ed17879d3e723', 'e3ef5dc86e154039d7839324', '51cdecbb594a8e0b5f169388', 'f26956b68a52957757b13e45', 'f8d725f820917d71a5301983', 'cbcdc4db6f2c0f87986c08eb', '66f0e9afff14db4b814ca058', 'c327e43875d95df50f74425e', '19d8f43d4364b3abf853cd5a', '02885cc1fb11efec74cb16fd', '61dc7e082e6c06af309663c7', '69b4dbcc3e05876c15ab3314', 'e01675d4835c5611d02521e2', '074c7225bee20e2006c6db58', '54ed73ce298076765282857a', 'd080d1e38919b6a529de708c', '8146ea91c180f5ff5edacc7d', 'eed2ec21308a4facd8e30ec6', '19858e80b7638280abbda010', '754791666185be2763502622', 'cd6cb8495bf452c344f61955', 'b5b6f1a8e33ce9cea9bd0292', 'bd3f5f6c3bbd8425f3cceaf4', 'b6207dcfe0579ae33b721201', 'bdbd2999610d99f0cde120c1', 'd5f33799e7f8110fd11cd073', '315e7c004443575bb2996afc', 'ec01a1e86108eda854c5cd91', '1ed08f1aa0fe257e5b029f58', '2ea2811b8f3a6ed89aa46618', '501d7e20f28d6572b7ea2104', '2ca8e56caf706c6147547a1a', '5c0ef35bdd581b7068ef254e', 'd0c67568fc6aa214a04e3aaa', '4c7e73d8e877dda69f26211c', 'e219db6bec1a6b0c74699c00', '47fa8b1ea8f2a4b9b4e04657', '45e27a5adb524da103b1963d', '857cc6b19c502ce2ba6b66df', '783bda443eb8e764428abb4d', 'e72c9c21aabd74b3648906ef', 'b6ac0c7fa5f88067047b90e0', 'dcc6094fae5bc1bb4de3c989', 'b46dbc1a0b8589b45641e9db', 'e72bc975b9c19bf0df3b5f9f', 'fa71c8774f1846ae6af571b6', 'f9006233824c9919f64e41e9', 'fd369ed514a6f2c485af417b', '0a7229f1e72f42ee2dc14404', 'ce9d557587a02ef7b5b69000', 'c243f4fb931374310bdb207c', '707f754d71d05322bf6f1082', 'd1296c6e0fcaaa1292187c95', '7101ce2540d2798377dc1ae1', 'af707d41fac6dee4c1688787', 'a5e6297c3b4d206acb9998da', 'd3f3a4406592054ad20c2093', 'c04f16fa062bc81f8c917962', '2d4e78fac89671a4c99a7d95', '9ad2b349b566ce28567c5d6b', '9043871db343ad385db09772', '93a6f19b82de2d952049362e', '6388862788004bf9b1e4345a', 'e6ffbc5a3950db37fba4014e', 'bea830fb10c315727fb3899b', '04572e0972a7993db0621881', '6a6f09403ba82cc0aaa73daa', '4830ab94fb0c437406b08947', '44ccda4ff4ceaa8e1e95040c', '39cc7a512a66650e91459e27', 'bfa8588d08b6cab7568a7c34', 'eeac21ba672f8b7b97fbede4', '00fbe516569113decea8de73', '1f89610cbce4f404c0d528e6', '1c7af8d5ad19cc00a657ccc2', 'd0de144bda7a040a2f9dfa07', 'a739dee00e50021190bd7f13', '5cd6bddbc341bdc7d39bab2f', '7c2ab9c849f250ca7ae3054c', '45147c4f6c84a8b896ec69ef', '07f02f8bb9cf48ec09ba120e', '341a4ea74a6802ad1a55e2ff', '85e6a823fac4aece9e3933ba', '449a8617caa34f297b5f7f4a', 'e595c43f7a0338c543bd80cb', '2f22847b30b971f2903664c3', '725d74abd24c1af33ef5d212', 'e56a5abd1ccdf45d55cee224', '6ce32236a45e40ed7a60af77', '2a3c78cd78a7e5f8d977da20', 'c4d75676ab4ff43eaf58b28b', 'fa8dc90654adb35a8f98e8e2', '42e82e626162ecd5abe81360', 'f07f334bbccde1c7406d1f43', '8bce38cc6e677156d2b90712', '4db20b840c3b030a56108b21', '3c11cf08e04cd8e55787eb1f', '810985919f9d2ed07555c4b0', '76247d92b87ae733ddbc1905', 'b6b5724cdad99c96a0d0a001', 'e382d74ae3fcbc0d1ca3a625', 'd4255f4b8d7db34c02b8c1c8', 'c1f271e8baade40b3d9d4596', '71b139cfa31f5f0c28ac7223', 'b43b8df345f082e968c0504d', '2d6e4345dac956dd550150ea', 'ce4f4d6348cd296c4415f38c', '031f4556ea1fe707a94f58bb', '3e4e9c6556f0bae69a76633d', 'f3adc97fcfd46233a705b0b8', 'db74cd1a2f794e17f35ddec4', '0d74b2ee638041bc581f98ec', 'e406dc4e0b4d87d40b90a07f', '20ff0d8a96d5878700a5ea94', '519ec63fd6ee4ba4f86c8048', '9c299b7dcbfbd561bf0f6f6b', '6975f69a4cfb65e6179fba81', '44f2c9be4fc4e3268e1c8ba0', 'cc3323ca987760bede847423', '623f6b6f64fea20e0be94ac5', '0f03144b28c1a640986c7ffc', '94556faa4ba7d0ff0917653d', '92a24aa83e1c66451f13de62', '91afc137c556b8c813b79b2a', '3ef161ccc95ceeb7a1c4f53a', '96cf60d6448c822883274a24', '2c770acc2155effc3c66d286', 'd8f6cf3bc53a60de0a9fc811', '4d5ceeafba15c9090fc8776b', '9c3e936bd95a10b43339da38', '463dff1e23c71f21ca726e31', 'fb87e4c3918b28e10f458a76', '15e2ea64a2fe87620f2135f7', '9c7986d4a90c81c0aaaf986f', '01bb1845215fb7cc77678534', '89f547ad3bff27fb734acf00', 'd2b11a845b1f86d3c1436906', 'd78eee745ce372a0b010f81a', '5067e04f2073e7595e4a57ad', '65faa312dd5804c3f1f638f3', 'f8fd30d0d0f870b4bd2f4abe', '4e8e76dc6a0595e8d2d83aba', '439e2e43115263121a562994', '81882a684bf6449f672dfca5', '713395a9d49099e4643f0ba9', 'd126628b6dfa7ff021c37cc5', '1afcc723ae25dcbcaee4919e', 'a00e9493a4dac3d8a11100c3', 'ba7f88a5002e6408a7156eed', '62984005cb4a2bebf693573b', '044289b85d5894aef9a9825d', '0dbcca2edb8dc4ada9f1ae3a', '017d9aef746962d1c3d9d52e', '523b2264acf6a8ceaf29d220', '799e3b8dccd0212e2b71456d', '80d49c51633413262b935409', 'b02107c6fe9f4494cc14728e', 'c4e7ab7b177fe5ebd0e590fc', 'dd2c47d5a140368a2b1f07a1', 'fecffb251c3f41feb07c69c7', 'b457b0375ed13ba271e11902', '06cb3e044663d50bd84a38f0', '6dbf8d68ebe9d4efd1f714f1', '759aa16667e44e03f4caba14', 'd2c264c9a4496523fd9581ea', 'b5e8c7efd2cc02936f14bf95', '51c4e6f08f5029501e961a4a', '38bb18f4f12bf469e4927756', 'e8e6ee69e045e5606f6c0aa9', '99bcce6bc0fdda73e97057c2', '7a05f054a0d752aa65a229c4', '12a69eaacc6a1663c3d9259f', '25956b8c121a3452cf6a13da', '2bc57e6b3e44d9ecf6f1c242', '0a507e5e6d94656aec03e31d', '5e4bfc749171bceb6b2332d1', '2ad19063a657310f5f20de33', '0e460c97c84c743bb885aefe', '4a5bb0f951af309dfe062485', 'f4312adc1652536556c92455', '592209b6b448207dfea92c06', 'f8a7c82b3eb920c707fa250b', 'f613480747542c410142b4ea', '762749a6a8452aa83554f391', '14a36d4ffabe710c621140cf', '455145565c06c0334318ab67', '7a4312f3777e3813772be85d', 'dc5d5f941a6b2d27b4856352', '0d4e20e0fef8cae36b234d1b', '61f59af2792e3a760c51ddd9', '1129dbf956a1de639c79960c', 'd92a728db326dded231e11ba', 'cc628d6e0b5a259cf31aa0cf', 'c060af6a8bb23ffdee50e730', '56f862020ab17a92aac5b864', 'f4bb5d766bfd7957102de24a', 'e8debe591ef7f4b4639bad49', '6d3a86657cfb5924c8e4dbbb', '23a3bff9e2c821e3f091088a', '0f7b20f0c3c6fb3264a2cc98', '72aa0a8195cef04d785d835c', '40e6d3bcc00d291b26feb3e7', '69d1179ddab59c8ffa8e22d7', 'ffd93124fef0ab4f2c5e1f7d', '51ad9f66e93f33042ccc4669', 'a3d0c04ad119ac98baeec6ac', '0f4c478ccc115578767ec3fb', '917adcbd5e526c5a6f592092', 'f2becb6d3806bef1b31ac86a', 'fa39db2734c74d5812a74112', '249cf2ffc11ec1d31980296c', 'd121006b2aba46e7a9730510', 'e7d455d2f4e0704722248c62', '11a79e0284c0d972831a98a0', '5272430cbc48927e9597669b', 'ed2e1e9eb814e9ee71358ddb', 'fef989a873a0244ffbcecf45', '5f1dc42ba1c4cd7cad30e93d', '4be515e40345fb288dd58aa5', '6f8c9bec861a6567d7a9b284', '41e594b8986edc48616272fc', '3e6c40802e7951b28402583b', '553e1ea6ccc3dcb9caf59f18', 'dd87fb2dfb9bf1eaf69c3a59', '32f8fa73cf7949fc25194b91', '0548ea40a64c517f125a4be7', '537ba5b0d8bba89f02aeaf41', 'f67318674d2ce3452b9792f6', '7234f29b92615d05cfbde52f', '03cc8765cbc06f1cff174a6c', 'a5e8f7d9e725fdd3e6eced18', '2a21e251ed3b120d205aa09a', '084fbed97d37b17fe3de08f7', 'd37cc2f82fab01c5b66069e1', '0f89bd1a01e56d8d8578cd27', 'ffe1a02ee978769dd4f4e53d', 'd768135cc45a97c5f9aa32bc', '85c3807521d93484430abc9e', 'ca6018236b179b413a64059e', '013f12f8af555d68080086d8', 'd17c786dec93d192f68c22dd', '342ee94f22cb4edb3916fb14', '7e3ec87fbaccb0f0ab6de255', '51bf2e035e47da3885e46b70', '395e9529519397ab2b92b3bf', '7c43cec9b8ce603b7b6a81b1', '97197e658fa88a996aa97c83', '08421f07d795de9a81dbc4b1', 'a811c24da8966874201c1f03', '458ec4c0b0b1086e917fb739', '1429055dfad66664c7bf35fe', '8ce0acf858783aaaafbc6c86', 'c873185bf7745af0b9d816fe', '25c1ae6ee1303d4325b02e56', 'b57f674a925a484550b4afa9', '090b965f222b18444e2a1020', '85d696e2a18d54f7bdd92de8', 'd016293ab625d79f2dc0ca33', 'eb857cd3f9ec24928e8c1674', 'b9709f43c5ff64a2dd1b4d47', '76ce0be28b35e8726dc606fa', '4562721f05a7c2b2666b8324', '2aeb48ba6aa5bb661580a085', 'f06393ab8b048f69f34b0dd2', '6ad09c06402234bbbe81de49', '14db1e998fac387f2026f225', 'e365380a427eb3377fda91fe', 'a9c112441a88402a143e7d68', 'd19f3fd4aedf7fd997534d9e', 'ffcd5cfa2ddc5dc30fef4cd5', '8567ab1c50977e5114c864e1', '2733bc74cdbe99ae5365284d', '866f0e3f587b1c8992a48c02', '58dca5f1f34e6a0994b147eb', 'c3fd367fdc390db8d0461dff', '99302cc231fc961e9d68c413', '5e33fcec4342525311fca4cc', 'b5bfc514c70281b00a67544d', '6ecbe5131fa2235952ed05b9', '4ef144ef1e3cc810f42069d1', '4171edfb2349dc1b264cd1dd', 'a4ca19a5c33291f0beacd6c2', '358cc7b4a0a0a45ee24a26fd', '1591c0dee928de6151cbaf4a', '4587dd491b8793e1feba1da6', 'e5194571023c182470d8d9f8', 'f84ac0f635563a2f0fad1c41', '292e05db320f21dac9efa68e', 'e71e7a24a4702232c71f8271', '9191a69ae68cf1a4e5e3ebba', 'c9fe1f1b8ec77f4a772615c7', '1533c631557452d754da7280', '6e40bf924c854c6bb7c3d749', '2a54dcb2e9a6ae1637d88ef8', 'd5e1e8e66d78933ac955b076', 'df0baa783ad628147be24b1a', 'c3b20e163f22e9c64873825c', '1533d0cd76139eb1dd097047', '86f22514f835be171f0fd68c', '000f58d3abb4ad76b2ebc35c', 'e456aafa65dbfb805ba11016', 'b60fe48723590c9d8172f6c7', '163d3f81e0ca38daf1f919a2', '82922424bd771f502216cfe8', 'f74c6d45811f3d87dac9bdc2', 'd2f1256d39dcc2e6a1fea9cc', '1dea4d1c505f3a5797f16236', '74eaa2aea6b2bc5d95b46140', '6c22bec7e47dc38b30e3f2b9', '2e2da95ca5d2a04c74e036f7', 'c7a42a6138402a2496be2e3d', '28bdbd0cf00eb27eaead2cf5', '22458c7e5433bc48eeb5f97c', 'ae5fdb3772ef4280f5cbd7d8', '16db3d465f88c900b68652e7', '8281e9dde4a495faf9a70ae4', '3cb1c84c070748104d4fe00c', 'edf4e6f3df6825947d302e8e', 'd800d11c3e81f4be09d09c2f', '207eceda0156cdc649f4b078', 'e1bb157131c54de5c76b3a0c', 'c464ddc6ede81a650537c328', 'c7b252f65de6eab4598bf4ae', '87a08ba4fb163b2b667c4c13', '17f20674ea38a822c7cb6788', '74800adca8d5382b227f11fc', 'bfff3b930069caa7a3444608', '8d73f28463798e2fa6a31b3a', '4aec6b15c63a023c98af9fbd', '617b9e75f3c58dee20062f3c', '7eb920ea8c935405a34f2187', 'c921eab7b5888cd147156703', '9b4d962443aad38251f870a8', '70419e78d304638558059cf9', 'dd637812c5b2444154d1942b', '9d3fa7a1702389bcc1a4904b', 'c3ad5487d2580375d41c2e06', '2a505caf854db532714351f3', 'f8da84426c2c001652c1ea5f', '60c25b9b360a4037bd94de94', '74d3878c8b5bd8025d7a304d', 'ab3ab99eb3d4c75a7da40497', '1844c94cefe167cfc46bbbc8', 'a4ca81eaa8eb676b5fdfee3b', '2b9a9c55cdacdabc16a4f556', '3ca5f7f58238739a39418242', 'f4668d73e48714b3c81b72ab', '908c6c72c2f860ac928fbaf3', '1f02c929b05a2d1eae19aa43', '45e515311022b0e3085d278f', '618d392ae43e6fe30006328e', 'a0d612dc021f06119cd82641', '3ab088d1de4a0ae537c766a2', 'ef3149b9a35fb04e1492d336', 'ac30cc56e20308d54af2b8cd', 'df4054d39dfcc41a5f36e76b', '8714a2c8bbdfbe82b744586d', '01c441f58a97f89226067a93', '88ef45f61812b1ec67818a35', '81e40ba71ccb07316db2401c', '24d90e86a7032d40c367258d', '187e5274711fbc5acb26d92f', '4fd17cfcc175d92c67e22fdb', '26904ee0e2e1e4ac50b43168', 'c566bb57a34d5a1e6092531a', '24155b9f4c00416b2b4a02d5', '538445bd77fd441ff8085f91', '47f5715cbbaf2be1e8505994', '1990af17fa6d2e02b4b63fe9', '59db7aeb6bea824b6c800d5e', 'c6de512d1247fb7333ad1c80', 'b08e604b0e398d9225a7e1f0', 'bcda489a731952e657ccee47', 'ceb8a5c222865829ffc00ea9', '47d86d0e205097ff162381f7', 'cb4e4e55e551ad021bb55fc0', 'db9a6d17c2bdc3d58e519267', '992e5ae1a94aabac75308495', 'ea58b388c8e0a4f382814580', '4556bf5fa6cf416c4f84dfea', '87539c9734c671cc091d67fc', 'be8cee5520084fc21550d8bb', '643390539a60fbe52d9fc05a', 'a2a83e230687e10b793748e7', '233eeb75a432587011a6b1bc', 'e69db8778c92e5eec552f1eb', '15f218ddc4b0e3bc25f8f534', 'a311fd7b15cb7682fb46dbca', '99db8d08ce7c7dc5e23bb2ab', 'c30028359953f37651a81962', '7766442f90d1794d8c97fdfb', '12f5143349944b924783990d', 'd6f34e43fb6592a8c64d3f94', '0bc993a64b3b18610af5e89f', '3932e19e4ed3b0175cec67c4', 'b8fc22b947af56744b197ad0', '109bdf00fc8e0bc665794600', 'f3fb1b7298f0046e0b6c55ba', '9a8d0a7f72b2f306a779ac82', '21725d6a5831671fc4d0dc87', 'c67d548b3887ca38058fde7e', 'dbe29d2282f5b3aed0d011d3', 'edaebbb4a2886364c2f5455c', 'f046a738ce962ca3221afcbd', '6cdbe56001fefce8414c07e1', 'cfd20a468254386f9a520dca', '034ccc062d441cb484ca8a57', '1fae11bc2be174f27630c683', '7963b2f32402222a44a74bc2', 'b92c083ece2259339c38b5c1', 'c040519bfaa35e04239eecbd', '814787a2d9c20960f6b872b9', '1914be2bfb5f57050076ba8f', '08ae61222ba27e2b2592fc0d', '25a3fc060e58489fa5108651', 'cc6c86acab499b90014c3eac', '3472f6614f855a1f74a08298', '68002865c7084ae451a8b103', 'b472d5763672be20763ee562', '4dbad1cc3c3af06c5664a2ad', 'f531d0fed3a37f3e379fb328', 'a07f951288594d0721e53be7', '70b43bd19ed867f8f2420003', '224e861c8a991fe5103027e4', '78784fbf49277b83517b9dba', 'd4a8c8cbd9db88a331e52ca2', 'af65283ac3452f4ee5fa0142', '5584a484b396e900b09a1ff9', '32176427d268868d414b69a1', '6562f562696c0b8ddfd04a29', 'a2cad7bd6649d8cc2f3b637d', 'fe0a92b8a22e8c88cd9c413a', '8d5bb2ecca85dfad41515eb5', 'efa49770d1b09991933af299', '1f9a407aceb5f8d72e3a565a', 'f599a974b9f48dd1b8bee774', '4f7a1d19e6fadf0e7b619491', 'a342759e5ce55cf378df2630', 'a8f04b428e4feaac42d610de', 'cc1b03b3dc9e12a0e0841326', '97d2fe4c7a06a3344798570f', '91985b654c4167748be8c66b', '061afbb7908a8ff0d6a68a50', 'b5b17c29fa86af65cfe72d48', '59f57cae084573bb29dadab2', 'd8caee9d95e20089a90e7c8c', 'e0699671e9dc302a776e8354', '014255e2a1eb9d957a380379', '35727539614c8de00c1936fa', '9bb095b969e981359c08d126', '6716a47fafd5bf2d15dae0e8', 'bad209f7f1a2e0361719a243', 'f22796c3c0a1bd93d011883d', '37c75c3b997199029b9998b4', '62062f47a37fdbe9d1c27aaa', 'f59622e4ac592f700d2dbc87', '8890920db6fabe97648a1d64', '9a022decba9cb56ac65b6689', 'f2f331a5387ccf3bfd476a39', 'abf1227f05449e3179b9185d', '9c318ab198a0c0e5c19cd4b6', '5b31e1e9fd15d53ccceb7195', '87cc300179a5fe28e3498b5e', '8576dc17a71fd1f052b49898', 'aad14eeea5e885e1009d3b1e', '99ba97a4365a81e47395a5e1', '21a3e839651e25cd7da1dac9', '57e26730a40f2a68869265ef', '5d325bcbd050d7d6eabfcab9', '1f7740e7b17317dd9085a8ce', '8f44537ed71e3c69bfd87f37', '85cf7ff0c55460da32489392', 'db31b23e92a6097f61552803', '3b3ec25a9c5acf7aca6a592b', '9c16ed565a5fe37955e8407d', '11b773ce5f673720f4ff1cd9', '1108d7271243b64d3250ee9e', '804ed378cfb82e9aa6f496dd', 'ca4e42b32f0b7c47922fe65e', 'f0ed8bc2f755ef37eb17af6e', '8e706a5e5f4902a5d9824238', '72a6cc827b8581d7058c56f4', 'b669eb9d598ff80ab9e5f8e6', 'aefb5d2e178ea9fa647cd5fe', '436b1fadeae03c1681161469', '7109e759c570a654d53e3ee4', '89541b5a85b5b5b3125bf003', '4a1dbfdbd15e295406eef0bf', '97acefe23c241af475dc236d', '7499a31689ceddb83308b2d0', 'ae6519f14e5f7700af940f59', 'e9f3ecc3ec11c4b3396e2825', '04195370f600639421b6233c', 'f11bfe4033fc6ace5d5cf382', '83f52912d78ee9b03c4a66a7', 'b88f292ca552b0ea6d9929d1', '6cadd9bbd8f4e8547babc4a4', '84e5d95551d30c43dcfd59af', 'c8359c96bf05ca8e01953b73', '2872894a2d6be289cc0751d3', '05a0dd22ccfcd8bac854d247', '470175d0ccd7f8d9a81e4c14', '2533e11570c9cac4cf3be471', 'eac7992d495c881955ae12b8', '8fe4b6848aa995f8ab0554ae', 'e86ed01755d7638dbad6517f', '543a7a730e5752f6d23804e0', '7344c8361b0e586129656284', 'd4cc44e155d21e53108993c3', '4e2be276b6289a600da28a19', '168c04ce1956c158d1651a93', '5bfa8dfb474aab488d477069', '273f6bc57bc0f792177dfd04', '01270c1f37b90c29598b8e5c', '7f9c0eb6e47a6e07284a459d', 'fba8a54ba42e25b3a395f35b', '4fbd4f9863cff8b2fd42e23b', 'bba4bfd7b72b61f4f0a2b01a', '0eb69f6e47ab63c055e2df90', 'd2d5d1df9320768cf72754db', '1cf9f8c80c784082726a6dde', '24c0ef475388f60e725ccbc1', '4222a76175b0c9d9dbc75006', '37cae934208b2a009d5fa703', '2374026e2104232fe78b6141', 'c8434cc6732c978c99684d40', '81b76631822bb19d0aaa0811', '6699dac0cf704c408038528e', 'f7e72869cfd4d186d37a8a6d', '02784e491e61842ddb4de275', '0063d54603cf0f791a4f2d03', 'c41797e8b4af4e6ab554fdc5', '3bea1d4c8791561006ff719f', '812b9c3cb24eb55cbd0989b6', '6a5d0066989fdc73a130b8c2', '1c0ad5aee8b258ad464b0c2d', 'e7fcf849ac87ce9fbbd3cf84', 'a857fe023621b88d5229e66e', '893c2935450c5d908b4a566a', '8ba70176af381d80ec259c94', '5812f2aa2ec32908144ea996', 'c1b9f618d57148f9613d4e17', '8db3a499f8e4f04b7f55b1a4', 'f9a927c46dab94fac56cd983', 'a9632d75ba6d979b5decdf12', '61a27855d733cbb01f805863', 'c8b3ff2eeceef81045187d16', '5869a0526721f0fc5641901e', '646e109b76831aec3246418b', '2d707b84d2f9dc480c7effa7', '067417d484687c9d57f7dfcd', '7699b4e5c410adc67ecb3537', '9ff096e6083c879d4a6bfeb9', 'ba92f2f766b9d7fdf7e30e5d', '53b45637910db65da16c946b', 'cece63fb84d3cf5a6e97cb83', '0c46bd9e9a1925278db28a40', '13bee07976257e0b38f5e9b3', '3f0035e87fa9e0e54608b6e8', '9a8f62c083931e6b853cf083', '0b0c7f34ee233cef21378070', '8acb279371aec9d2ef64ac77', '0385a3df53040e9eb91837ff', 'dbc236ec214beb6e0a9a5ff0', '3c3c48b480fadfdd63afc64a', '2d9caef46a791339e4a2731b', 'b631a1615445ca9ec8e26a42', '62d9af32c3698f6545567c3e', '2eb0abd516a6a45b4329852b', 'c6db806375506c37524257d8', '57bfa65e25858649a7b7fdb1', '89b3f7739b080ee0246b9f58', 'ea52341a69ca686cb059fc2c', '652d19150532597e8cba1e58', '4769deceed9b3988f20fff62', '22377f7f4ffda156f6c95713', '81aaa658176632cb934fc8b2', '1d64d81dcd56c92b92cf34ad', '888957dc10f4451e27bb31eb', '3b0b9d06060760720fcc6f1d', 'c1f369fb99bd717e87c34253', 'e94967759cb45a5c074573d6', '39f61d8cb6ee0e63eed2c0c1', '7787b854dab1f43b718313bf', '80a3a1b02bca2873dc0308c4', '540b84764bb982f9853d1621', '1ebe06aacc066a61c6d64f52', '46a747d7b9992bd3eae9d736', 'e4e425cc7d58d5e7949bf727', 'dce18218fbb62e3b07c34441', '39a3cf3e83759a824ed64266', '74d964eb743c57b2e97f9876', 'd0bd21030a9fe3f066df09b3', 'a7391e86f5ef2065e3ea2a57', '6e294cbd69afc45c3375e07d', 'a19797fad6ac2c57326769e0', '56ec103efc85ce4ed535ee32', '03d2b60423371ca98d1a99bc', 'ac5dd63a7a7e12dbdb8de9e2', '015be3d8662ca93c5c0bab0b', '402ffae6336ceeb14052f50e', 'a0c6ba5a4eba9f8602ca88de', '13123a9ba850d6caba5a0faa', '72c22160d0226e69dd0c8407', '631f6c7b12fe0e5f5fad366d', 'f8739799c8cf7c00eb97451a', 'b72b79de6cb86da03d64e09c', 'a2f8e369e61f50385ba06afd', '157b31fa4605dab06049c427', '407b4851260c5c0836e1d89e', 'e5de01d16191eb56d2a17817', 'f099406d471ff52b20ae8441', 'a5d91ebb2b0d935b9c493f9f', 'a7bf9a18f2ed133ccc62c5c3', '1e3b44203311b415f4712cc6', 'b789cd80cfb8838ab901d4a4', '8509828abb4a1380dd44f76c', '5b78e15830003c4050414093', '675c3bb58c7f84d6c7abcb76', '00beff4406c2ee10ac9621fe', 'f7afdc32d94d128115a2b257', '00249e27093cdde779012293', 'e7d4c4eea0ceb55fc4a7b51f', 'ced75cfc467f5facf66e9200', '232ebd5bf14d5819bef84afc', '9ccc39b8569c5131efee591e', '2d8f9dd2fbaff9e32a728bc4', '682b7c020d47e07237753b11', '2e778bf667b5fbe90f44ef33', '394a6722595bd4c93789a2b6', '50a2ff309d50e7539213d116', '933c7c79dce6c6b398e200c9', '61f9f600cf87c85106cb2efd', '5b8ab7986b30db4c19fb1088', '64d3df17e06aa81f9ecdc580', '1089bbe66e821577636739ae', 'ec6751ca286066dda72e0c84', '00c6c1102d545178bf7380f3', '047259e83745142834b50838', '68a6646ad90adaa44fe6ddbb', 'e48106054f3e117d2fac314f', '661a2833119e979de4228585', 'c27b7ef096a3a3f132083738', 'e1b0ecc193437991940016e6', '0ceee1a85a040c4d57c27a09', 'b704681115ed8cf6b288919f', 'b8b17acef0f82e15a62e972b', '653ee6598cd92b3382f04431', '46024bc03077cc1765abf676', '644f9d16a15d38b492e0d147', 'bfa5ac0d983d25c1bae0ffdb', 'a5245904049b7aae3a154666', '0d93e83a24f730a575941764', '499e4f8e7f92658595f68d33', '84ba0d560e8d6b40089569b5', '6e39fda592a8e6af9e50df9b', 'ec6cfedc417520a4d86f2365', '303a07985f7ef56f4d234d7e', '090c2ad4771d1fc8adaea4ae', '8fa8ed75a85186090d9db649', '0056cade81e16f20fe9fe322', 'ae413e6191c531e7f585a405', '741e6bfd3ada80120eff4191', 'fe7e8800a8ef335ce9596217', '29183d163063354c6c818147', 'f99e58fee0562c646b3dc682', '5fac6ea9a02d544397cb54fe', '4d79af33c083f4da6c760216', '6a1bd90b69ca958eeb14cef8', '5d5185c385123b16a09f65af', '00b98d0bf4d50497625b257e', '4c5c196bc7d2b79d1ed73ecf', '8df09dad6578de1a0c901527', '0af1a06bcce4aacbc5a936f4', '6256d1fb1cd3aeaba0eb11a8', '837a8f55375dcee9e103dbce', '72a2d6a35e2ba5c873f1a881', '07c7d0b230f28eb2bba883d4', '74d605424dff525f198b0afe', '4f90e141b3068b6b2ff3d1a5', '6ee64a55e047a6157abffad9', 'f2545d14686ea54127cc9c44', 'a6cec8e8e6020c8b18e14f57', '7c14ad97c239a78381bd7174', 'dfa9c58ea0197508d2682000', 'a5661f4d9bc983fe089c2f6d', '04c847911489606e9cc2a6d2', '781463ec4654dbff8c5df153', '21b660c0148b20c1b1c2131d', '2f8b95322025bab1d2c8da4f', 'e15aa00add2d775e41bd5338', 'b6dc114c7f1dd675d8ee88a1', '555c677326428762a09481c7', '2fd61472c7569c2469bef07e', '06aaefb80b31fdff1837ad61', '2ace025c677add406539f6bd', '1495b796ffe9d906c0df1b75', '7b93007f63a2214c1ddc33f7', '6b3c9e4d732df9f3eda20c41', '1452ce7ea3c5edec118c2e61', '1607c40d51d24cbf1164290b', 'a3fbabc4125bd38ac2aed4db', '8189f1610cb803102103466a', '776aa437e8c7772107f91170', '3897e55dfcc80af6c9948c75', '755568f5da1aa36f192dbdd8', 'c6a7a43a376d92df5f420f3d', '224951a256954e9d3b39076e', 'ad7bed12453ee529baf37784', '1768d3075c1fd4b1f229afae', '51825ade8dabf4e61477d4d8', 'f46885deabda4129f8960805', 'f3bebe99a5275c408f17b181', '7ae9d2ebad321231f55eb04c', '5498f998fad51770de8a3567', 'aeeff9dc3dd3312a35c0af6c', '892b40885727ac07a5ca1a88', 'd6dcd3648703a4fe15c42513', '4d64d12fe14c8c3ed4e3f73f', '9a6863fb555783adad183af6', '6dcff6961c5881f37f24c90d', 'a69b592f91b063a29a0fb688', '11974f52e559145ce9f812f2', 'e0bdf1f255574123e3d82ebc', '27b1f84153a5a461120468de', '493ddb9a69efd787e0396f81', 'c85d0450240f7e339aaec76c', '0a966abcccedcc3a0964e05e', '5edb9312f6f7f742fcdce8fc', '6e78d418898692d8783374c7', '2ca6827b5997d6850fe15912', '0ad44ecce7e9c2eea3028673', '60ea85db45d1ad1ad72cf62a', '47a339f3ee10d0098dafc8bd', '7d56993bcf3d2b526fae33a7', '7765d7fe671288bae59a5fa7', '980016183fee2c1f4ae611ae', 'b5f30bce905a467fe3d9be05', '7b241688629b0769f326af90', '2b1f21750fa632e9b0f7a19f', '2a8475d3f201bfe0a949a29a', '7b67c7a9bff55320d436972c', 'b462e1aa1b901782d9358530', 'a4ae3581ae94bfe56b9a4d3e', '2cceb4c8bccd163def8170ce', '241a6bd6f1e129a31b43bea9', 'a492bf5968b017604595cb27', 'd9529dbe9af1c4a2f0911379', '2021b8d65fd7fd080d685ca4', 'b7829190559539b14c91b592', 'b47161883d5f7a57232f66b9', 'a491772e3c26b8dfc1137679', '5780c98a714da7aa7512b363', '333d0beec3e1c8b7b38dc15e', '02964db902a561eae10282a2', 'b04265d8d305b0cccc5d7d67', '3842f39935a34d58b55be97d', '6f8a9ea4d83dea4c52af5a4b', '40073884463d17bc3702a2fc', 'fa4ebfb881b70db087e81779', '7fd810ebd8c88d468eab802e', '297493c491ff8db9a6d2fc45', '988d06c4434babbd7c78a275', '430d5d3db66a6f64ebeb3879', '40f923d3ceb04e98040b7c3e', '4b0dae2bf00cb70ac501a4d7', 'de871565192e846d9c7ca39a', '213a702cca16592f4d19705a', '0186746594c1cf90e38d4ffd', '848f58c164e2f0878c1c9ce1', '5075b95436488f53e5f7976e', 'b3017b420fe13c0d01fb5e63', 'cc8d52ea13df2c173004e53e', 'b56a14e89ad09be086852b0f', 'b3f9074de167c69e1b75d061', '44d5008230190a09f20e3682', 'a8030f14c8d26bf536bbb2e7', '1757227b484201499ac650b9', '43a04bb201473909218db1f2', '2760ec29711e48dd4fbb1d5e', 'b09ed49b64bdf344e14bb1c7', '6232ae4db195276a3e324143', '8131eb8d99a9ae08b543fab4', 'be2ea8ec1974fc0574f2921f', '067ed21678e9244b701465c3', '7c769198cdf2ef06b5f1dab3', '4711376d06c7dea356e7adee', '9b8533703ff8eab23578f84c', '4d21ff0e9b82a46ea21db1c1', 'cd5de61128bf4493b8a116a3', '76d64d32df1f5a7f51202106', 'c87fdda7e48ed877eae86d9a', 'f2d594c951cd6c02275e0a17', 'd59d0db4be4aa6b37d49b1ef', '94c416e60fecdda4973a6173', '0a36ca6e9f221dc69fc7f8de', 'b1ea33dff472a7dc8ff3b3ca', '1e04b4d24fdf02742f3ee567', 'ed782775b12829eac1c6a491', '6ec318a2ef73df94df5bdcae', 'b7b81b39be99bf34446ee242', '7c03fe01f161036f720f6d7e', '4d6effcf91960c4bd023a47c', '34477f844c8389585cdcabca', 'a5af87eb9da16c85cfe6ddb7', 'f97301033f6fab945614f220', '4a22689b12923d592f28be83', '119d4b9159d345fd67da01be', 'fe0907fe6e75c814af68b01f', '8bc83605b6ede35754a1e843', '8dc71388fea9c3fd6452055a', '2c4e5ef20f7bc4bff7aa7301', '3a6c107da55dce7df0c5c04c', '7e56a0516c482d121cd99bc1', '228233a09c8164c6e564f551', 'b628445609db036ce56787c3', '4bb1514c5befb0ece60fdb11', '644187bf34aa3678b61cb3f5', 'bd1e0ce3084fab70f0a0f6db', '25d2b1ca042e80e4dec9ba6c', '5fdedc40e18f8009f6111be2', '997ad426b096ea558462f1a2', '79fe38dca4831802e82026a6', '1081d7abee1a338f85c00408', 'c0f3de8a38ca15677c20c16d', '5b078faf4cef1188372987db', '65a18d6c6863a8702f23d4ed', 'f52d83becf30a588f36e34f3', '89ef9c7f4b5b2407980dfada', 'ac9b3f14d853d992c65f6faa', 'd555deebd511e5b4c5c57695', 'd0236a73c2938bd7a69aac21', 'bf7b0e75c5c6bf62f8ebec79', '5137f76e33516dfdead9f682', 'f9adfa5449b4f14c535921e5', 'dc21479affad398d7e20b2da', 'ab607c4930656aed65054027', 'b70079e92720b4a5b0ac3a9a', 'fcd6e9ee48fbda60a4afb671', '3c7c50f6746a47772cb02cbf', 'ddaecde2d7500bcb038b6060', 'f8334a7c23e689cadd23c209', 'fa7d7ca1c281f5d1e6a549c9', '34324beee54e081e5e88f130', '0bf3d99fa1e1eb8dd643a066', 'fa8402cd41bf604fac740f8c', '66e4509cc3f44d918845b252', '1175293359f3af457f69e353', 'abae98d91941955983212127', '7dab61a9dbafa23e083cd77e', 'a77b1077b6a8778b2e1e5123', 'e7b550eaa8e671a43a12d80f', 'a70c341de1bc993eef26586f', 'ab86f0ba83c400b1a9f9b6c3', '3afe51cbe0baae4f9809635a', '925ed6c9ab8d40d8dc632226', '0a32f1c36ff8b32b47e43478', '242ad67d83b98dc87f0a257c', '169d3a6eec5e7a3446cd5c85', '0293a5acee37151a49ceaa8a', '9d2d12172b2bedc5632b132e', 'e4d3934ae79126d2f578ee32', 'f66542e8f77bde61ef62dc26', 'be30995ff00536a1057c7245', '315fe7012ff34a06a1448165', 'eefb36fdfc2d06211f4348ec', '073c3923948729f403a5e5a3', 'c123e03a1725cd7b860dadff', '1459009171aa5baa3803a221', 'f517e3cce89ac464b8a1e6e1', '28a2d17f20583959defd0234', '3c7a16e5114441d4d413d8fd', '434dfa0e21a4e11280d53e6e', 'a975cd9e522a7abecfd9d1ff', '68312cee150a54cd1fa02383', '6277e9a8851e3c1a4ad9cd6e', '271c09dde1ad0ae0ce21d6e5', '2d292b7a053eb9f6d89638af', 'b2c10ed422acd1b5e903bf20', 'b64781d0b4bde8ed18b8cb5d', 'e07cb0702bd8c962c980b344', '040d18e997bb872c3314ccba', 'e50069b13140ebddc5f39a48', 'a34a60cc88fbeb47c1d1c41d', 'ea31f61daec8ba1d5d9fb9f8', 'db468e7d4e952084d2241b01', 'f5565e8dca592ac7658c9ee6', '1a52e19cc4c2bea04555d722', '65f468deef71db0042d17c04', '8ffeebf80d9e33afb70ec3ec', '5750149e3e7fafb11a1a5090', '2dc6aa9a4ecdf77dc85c452e', '3dcaebddfb2987ddb1dc6ae7', 'eec94693605289856658f678', '3859ca46fafef561a7272be8', '828e100d1270a025a702476f', '5cbd34f92a55a8e7c2f987ce', 'a38ecaf9f7fe8c5a81432f27', '3a7b1ab9c06a0e50231e8017', '2add4b6f52a7f92255a99795', '9e5c20a2a5d9bd9a11019222', 'bd5f6fd5ab13ce62634ea939', '16daefeea8782307bdc2f5f7', '23bbac068db32a4e588f2d9e', '102866b5841e8a98e3f1d51b', '416bb5f6b916ace9fd639fbc', 'f2fb4d6b40dabed3a0ffdc3e', 'd6c396b04821fd366efe7a49', 'cf057692f01ed1e43b7ab26f', 'c3ec8c1023fa687bb2624e68', '5dbb876ab254d8863d9a17ce', '1b28768e1c1598353e806a5d', '3359b6d79281a1940ec5c65c', 'a25bb889984fbcb71773db73', 'fce59dd5045419545d12fe57', '3eb0479be3a32cecf1cfc9a1', 'd4e9772857153946f3bf287d', 'ff6ea5e1101cdc2781d7466a', '3f2bb642b30df18f43f0428a', '57280c52999208a8f3104301', '19c3aaa1bb33be228b47ea7b', '4a9da1e78cc48ca85038714a', '436811ca71744e404dd509d5', '6408991bd45a8b1bed727d8d', 'b7db8d58388d97ad0352fd3f', '23ef89f430d2312cd46e8a1d', '15d1606a584e98abfb4203b3', '47b4b008bc5e93c16c231277', 'a7865e6aada988aba5950707', '03f81bdff77fe530b0d0fe7d', '665268e8c88a193b5ec8005f', '93e00f471a0dcb56dfb1ea6e', 'd18670a4c314b569054a32a3', '68ee1d315023f57029b6ce03', '26c74839913ab4510813fb05', '2bc23738094540fb7b4e565e', '036dc7fd74fcfcf46d3ee504', '3274494f44c1ffdda4c98220', '620be6a2707f02d1b5444ed9', '1a393a5c12d21a7f7e392418', '7a94050770d72ccb6594539a', '972b49483131cf603f6639f5', '7ae500ee11764d469951ff85', 'b440a7a78eb175aad7326406', '615f5677e858fc4ef464a1a0', '04da33946099754d422c8015', 'aba66c29e51149f140d80325', 'd4677f8cd4b45df639326bef', '57db051f5e8f25c8927f61ad', 'b594bc62abf53801dd98efe3', '05708c73dfad0a3f4781563a', 'cd81a8fa98d2679535f3372d', '45128f30bf831e9b55cca497', 'dcefbced3548a05ff203d8a9', 'b4cddff0a459aeb457378e32', 'bc354ef513b2215446177f31', 'eaa2bc139459a0e6de3f0a33', 'f7b36fae7e1f6246c0b81fd5', 'c921232bb890d4227c27bc79', '7a5650e936855a3fa424dc59', 'd6325d5bf0c0e255155bb97d', 'fe412705ae90c13acf0a2033', '750dbf95a8c1c5e4d75ecefe', '0925d99c93fdf4626caf71cc', '834e30eb03b26e7bd61a9b19', 'd27110d877b8d72776989d66', '36c7455252fe5e86cee2f9ff', '0565efc9f6e08966694b0d93', 'd9de692b97657d92d074c361', '29529a65ec54c70785eb5133', 'cd9b4dacacdde7494c082761', '2142e73a54b9782926053e6a', '82db68532c1fe0fc76c6c017', 'c642922a8ac294d31682581d', '2f95bc2423afa4e0a3965518', '11a6356dddd6cc1e2a155810', '43dc5805c85d11ad9ce1eb53', '955c6240945fc39d733c8375', 'e55eee58f7de7acb4afa8764', '2195808ddabb497385b40858', '107acacd9df083f664395e57', '97516d1ecb3c025c618fb0ef', '58036fbf344f61c449c588f0', '632459fd456c31f024bdf938', 'f6875e17c4dd27a3b3e56653', 'e346948b183416231db2bb3c', 'e1c8e8780d98ea2f4d439813', '61d76023e4eecb1aac307c96', '7d5c2f5180cb8edef4ee7d95', '48965885b40400e08e4d8528', '64a43632d54bb861d083b284', 'fb14ee1d9363c64de1cb8c84', 'feb492e9caf0343b3c2f2166', '99ffb7abd20ff1b14fcdae61', '87a3ea2e67ade278c0c2e7e5', '122180d2410c37fb1d467316', 'cb29881e7d27f8f23e3a8502', '30444a0364fc39ff849021b5', 'b7925774086e29f5d02b778f', '569bfe18989623d3f5c6678a', '137db7f9de6adce5df221be5', '4f0abb317b82d6a5f186ef14', 'dc56faa6ef9caadfd8ca6880', '797af2b7be25b810c1fa0b00', '04f7c8bdde444d9384216f93', '7d6cd973b881473d4b309a26', '11e07c7cfecad5cb89401830', '26ca7defafe27bfa854cf965', 'c3b19c4c394c0f1b38639a43', '7cfaf497121871d021a26099', '17940d37a58d13908074e9d2', '91233f4f7f64dbd5fbd43579', 'df5a70f5890755916496aef6', 'd66c3f48f55c47d9fb861e1f', '26ceeacb486699b10996ccda', '28a983d2c071ad3739459886', 'dcd2227eec0068298417064f', '8f621fd97d1842a4a61410fa', 'ee59f6b32fc0b17f2e1e888b', 'bcbe7556b4dbff73f99a68a6', 'dd84074c0fd0874c556d0511', '30c85360417e25270068544b', '1efc0b4233b41debd5e85794', '39b8b45889cc5475dedfa102', '9c5f4de218634410a8efb1a9', 'c204f2867fbb32ebf4703865', '0544bc6c320c47d80b7b3c78', 'd9585c679577af82dd88c509', 'a8e86dcf95b5f3203f351589', '1a89de1d88c68408b38a9c56', '0ce9c8a93ef40fa209454a71', 'f6274c47226150acc9cef0e2', '8d3d64b56c340125f70300f3', '113ee06f4d8c5df754253b48', '24ad2857877ae3f6da374f4c', 'ad521f49d4f6250463adc2a9', '09c4726f77bd8073eeb8d985', '8288ab2fa75b4a191de46940', '52e1920bba1dc62e51feb58b', '6a8ea90422439952b0b95d0a', '7041b79655fa30e1c31b1c57', '3f7e59eb07f66f58689fdf28', '8140c1e65784238caf1362ad', 'ec318c164a262760140ba3ff', '26aa4388a8897474b77aa481', '909967a65d2b569fddd45064', '95a628ad73ca8b9a1ccdf74a', '31cdceeb50d5b9593b6c8055', '5fb21a95a15d64c85db2fed8', 'b88e4ef160b32df83a1e6e63', '163f4af47f19becb80903c30', '072f960a91e48e6fe38d81a1', 'b9e7f10e8737b4fd67bc29db', '2fb580e18c83d31b38426b65', '2f74275a2c13953fc65e324f', '6b87c27e7eaa3734d66015e0', '17c8391662dfc6e28aa56464', 'f6001dcc7f0b69fb01da77ee', '631830633e3ef0505c85ca98', 'd9cc62f7c052734452299128', 'fff1f1751b80965886ad5fbd', '44142bfb9b0cf7c3ae3ebb6a', '47dbc50e60c6491af7433121', '20a337b806f34bbcaf6383e9', '5cce095f827f40e0736c9405', 'ab6219b3365eb3a41f89b20b', '78deb17fb4b0f07c1c1b0051', '2e302933ba1ba62f25b09b46', '0c6cdc444ee911941bfd23f0', '02a069698a803a8419fa294c', '41deb2b6334194be2b87c10f', 'c66b8f121c0ec0bc328c5dad', '56eab13d0583a58c43247431', 'af5718c6edddceb0646a23e6', '7f24de340048d1b87aca545d', '96a8776128757eb24aa751cc', 'e2f69e562ea54caf705bd0c2', 'f301f472f3dfd88f91cb2316', 'ce45eba5e3053962a503afb0', '1bf033967053a3e88b60ffec', 'aafda5799cef4cdbb1a8c0e0', 'ae715e89afd0fb60fdd2b53c', 'a041560dafe724349feb959f', 'b8c79b9be82f4813cd52ed92', '17e15ae68d3705f96b36cfb4', 'd526b1d43696d492cab8fec9', '8304664f47f63bb4e4aedbc5', 'd73922f383164918bb919ccd', '96b8daf19be21be478a7950f', '1e7e5b854e3946d368c6016f', '07cfa2305771336777be3c17', '421b9af53a232e69883ca462', 'df2081f769425d13a4ff054f', 'ac29c708a74c9c79fcbab164', 'e7119697712668b05c2da0e5', '8a1b6e9c62cf3eae76e1d86d', 'f7f4a6f9abf6c8424b79c205', 'e629cd0656dc5fe7580121c9', 'a7f9bb55036040073e02ba0e', '1a16b0cbd84a464357e6fb02', '2e71a00ad2d28b3a77dfcd7e', 'd365fe598240a0df514f9daa', '4883a2a4fe195a7f18fa9e6e', '5e629ad0ef424581e32da93e', '884dee5de94299004db9a1f2', 'b76a7905227123a769fc9e14', 'cc2d4eae2f2d008d9c2c9518', '4ad4465cd7b99c50bc48d1df', 'dba831b22948cb6030f2a0dd', 'e8888e24b833fbc7c8316ded', '6b473d162048ac1a1c32fab8', '88a7e76c42b80b33bdb68d60', 'dcebcd167c495b6e52892fc8', 'ce36c547c1a37852e65fc5c3', '8f20718e8f7720e51c34a9b9', '0c36b014ddebc557e87c1e72', '8afa74497c4d9b8c7f0fe659', 'acc3a9c211f42e9d6d154a20', '782822c98c2534ba56c1c45b', 'fd65cc9a15899b7d467ba196', 'f79c2af96dde359ecee262e9', '17de3ba481cc927f60d16233', '82de427493ba0005e55da2e9', 'd999d5a343bd58aa54b40298', '8970ce40dfe4e0498bf2959e', '024f3a6b35669ffe35709f85', 'c1052714fdc43216d8caaaa3', 'a3703a6f4da15988521301ef', 'd58380e3bc5d293e5d7d4718', '982fb7efe92d6f33dcdb9848', '26befa90776e4ef7c35488fc', '1792bdbac4e9db2d02bb207a', 'c6e0a3d4dc4ef5f0f7b05662', '0918bda2bde8b0408f60fc3e', '2aa7ae5c7002d9117a347f9e', '4b2f2ac3530b71844f36b481', '2559181f4a14ba86cf190ad5', 'e1a802bbddcfa313978c2d4b', '20e39fab12a387f9a7fcce7e', 'cb462d0dd320361bdac44dad', '4a52128ae4a63ad0dc8d6410', 'cac9008f4f2f7e8937a4e13a', 'e72e07c6e4ff2480d2708585', '0845c5b2d9f8bde33129dc7a', 'bcc21d5d3111f89ef9a098f9', '73b0f8fd2749c9bf490fe19c', '1e5faf727375a9ada1941625', '4b895ff0d3cb5fd9fe1e5e50', '52b6906b922b93a286a69090', '5a36e2b8accac68f5996e75c', '521083ecdc8d7be6649f758c', 'aa46c093a028ee5e0201520e', '0e1a076c06d4a3c6b66107e3', 'f6c6d5c25fc74762144de677', '878e753f48874ad8f8ceab3c', '42b510fee11c5b77449a9840', 'dc2a2b0ab8c3da8e52bdaa44', '52796db611e85270a50a17e5', '5a7361bff9784d49a8234e8a', '347ab7a4fae1946384a4e79f', 'f691d2a9bc22649ae9adddac', '94d863c5097e63e95a31ebf4', 'c7cc1c1c0a6dfab998b9a573', '3721cd5bc8e32a4de1812101', '51e820358aab679bf6555ec8', 'aa7534c96dd01ae4543b138b', '1936469b953a861d9b26f745', '41f819d9fd8944e5602a6279', 'e07aaf85d212b1a4dea88b36', '65c849c2aad2c56207e5cd6e', 'd754a3e8d810070834fab3af', '4741dccccfea59439b0c12b8', '4eaa02f29374fda17d73e7cc', '2f8dde64c76d63b846def4a0', '0a91b31731530c53ab09872e', 'a5137665c5ab5a44b8006d8e', '22b41e8ee0723aa4a6acf31c', 'f082ad77c50f76200f9ef93d', 'b8c5fe61ece23bbbe04cf389', '3ba76ddc2f81e4273838d8ae', '1aa406c499de99518294077e', '92eed7c2713d3eb38d53dcd1', 'd7533f37a1589e2a8f4df73e', 'd7cb00a4818527abbd869e4f', 'b5dcc8918a0bc3fb72bf3b6b', 'b9e107def562596e07c5c476', 'f3249c1cae12b134951c017d', '0efae2c62f95516d380e6775', '04c15bde72e4c64e49a380e7', '00f2bfbc43dcc4875ed114f9', '467265322cf858e76174f260', 'e277a867e388255263046134', 'd7fb401aec234c8c77430b13', '877f60bb26ea0d5229a4665b', '261c55328ac8ffc4792c6e5e', 'eeb43c515ff535d263e55711', 'f14cb951f41a1c19af6d82c9', '27640049ed54c86d051fc8ff', '83619f693733b0a1c2937f55', '274367d1fab86c9296ee0ceb', 'eed48c889b928f3ee845e151', 'a8995e515e945700a73e1a38', 'b711a8c66ded68ed4cd6199c', 'd2dd4d4753286d5a02aee69a', '7363a00d1729eca1fc81049b', 'fc608735d9ab6fc5bd43a04c', '94f9e6d642b39e6a9d1a0559', '92ec6272af144fdb3b7740bd', 'cbcb60f4c34e7c1afabdf477', 'fa30ead3c41cae309bafcade', '733e2d8ccc688ba33154a9ab', 'e973b4ccb6182ec1b934fe53', '28146fa3c758abba5cbdbfae', '296dc134fad4a300a3e8605b', 'c26f64ab0e5b645c25c3281c', '9dbe9323c793aa4ded67391f', '112f416ddb62edda1db7a561', '5bc31e9ba087ef781c202f7d', 'd1c500e1dc43c5cae4cf9075', '3d262da4f3ade06a2f6f3db1', '926dd0924833df1c1df58531', '7ebc983b2a055bd196b0257b', '73752639a8e1cbb92081f23b', 'cfc537434f52b06b620d9254', 'e5dcbea951b8bc21c9c8bccf', 'f0792acd794b3cf007d78f92', '6264718a6161659bf85a5b7c', '01fe648fde411db8cc5023ce', 'd3b9aefc8549a18cee8f540a', 'ebc57b735ed65bf597257c3e', '7f6a053c4c7996cce251e27b', '891190b131bd38e70baa856f', '07ee97c7d111eb378921826a', '5459dfb5c9c49adbe57a0564', '0994bfb0d80d586c3e6b991b', '723f3f4a1100077de462dfa3', '754e29dd9545b861d06c17c4', '0a8995a9063c29d358b7b288', '6dfb148b96ec46dd4baf1399', 'bb93faad71aaa3ed0164496c', 'e567aa9d37acea95bac0a52f', 'cf44316ed6f26cdb2af0efb9', 'aafe7bc8473b0240ac6c912c', 'b179e910614a955e056b279f', 'a789bf245942cca833ba3d9e', '928843eaa6be302dc4f25820', 'ea31ed3fce1a143af74ceab2', '8dbbbd8602f5f3527cad26cd', '5939dbebe9fc6fd912fa8878', 'e14e80dd4ca4e48a6ecac19b', 'f1e1021aefe5f99b0283d0b0', '038c76dd2c59256fd7b9ae46', '7a49c6dcd4b96553b57013d0', '774183417c33e5ca1129707b', '888e5315d7db699f3ac78093', '56902909daa613c259aedbde', '3a3ab651adc4530ed40be652', '7e79e5876cb4505b0d14e7f2', 'eb1d1c55d70459e5c91b366d', '40af2c18046760f0127c35fb', '7a9d8c4e3514be8609110241', 'ff8f65ff38e91c62de0fab77', '3347c7735b3a39f53f492495', '95c5860371dc9446921eec10', 'b69d13810f1abe3029a6d7ba', 'cd3f347fafd6a0b53706f949', 'e36f6d845834296a2ace08cd', '23065749b2b2053dc0c8dcbc', 'cd943bf7074ac723717f6ade', 'e4f4aa529c397e3b7d0ddcd2', '3df2ee46a071840f122d563f', 'ffdf7c7b7b7b047429a3497b', '30ed0a6953999ac4024916ae', 'ef2cdb36472c00261392f95a', '25766b07f551c549f6e3c32f', '4d2e6a2bf7e989ac0488030c', 'a803b49ece53f378a4fcf0d6', '91e430cc8aa46185aee7b418', 'a00afef4fe749df9db791752', 'c00a358c2d55cd8c5497fc99', '75d97d3e27240d4fbce0b019', '543fac252e1b711db022052e', '4534d3ce04ba517f06d9eeec', '1a0886c3a3d7dd6afb64dabb', 'd9f612942f090356e944ba24', '99248704a41adef41854911d', '240b36c04ba129e0ec06c297', '4972d1004d8c1ef2af211806', '85217448903d24f91d5ea081', '14b3bbee2a55aa5ae2fdf038', '7fa7ba261095aaef6e6a3b4f', '63f037abd22df66334ece29c', '55bae74b1c4dde44613794ce', '2aa05532775a51572241041f', 'e4b5f1fc800b0d54f32ed37b', 'db398e1ac2a8d286cc4b53bb', '5768b3ec354138c3fd79bb7f', 'e7db6c421273de71b7f9b8a7', '05ae0033f4e813609ca5d462', 'b48e7a50e9e73818c7619a51', '2eaf0a50018f2abf03e6f2da', '641457e48596a76706eaa733', '9b52e008ae7f63b3fa3eeb3d', 'a3f40dc2c562eaeeb1b1acb1', '92628b8e1f9f488eca11c7ea', '904c2c0c49be0f63d95d5358', 'd5e0cf8341d186a59aa14536', 'ab0dc7cef40d44572a80367e', '45ea928adb31250e23c1e7d7', '8c6f20f6c2e2c7185fddb381', '437e22cc3839c9e567107949', 'f2719ed44a2bcf2baaa42242', '0679067bdc3a032cbc68f962', 'e330c2e4df1717b019f638e1', '2cc3cfa013ef1b065613e661', 'ec5cf43c52672339fb5e9d7f', '4a7d4830011d65962d460041', 'ffeeae0595efa3f5c9f10a86', '4862ed4025ee2b4c353f6545', 'b1cb5d3e6f5cc86239c34959', 'ab4e1e2da052427fa2ed9d07', '9baa4740ed5e93a3f8178055', 'd37a478c48d46a196ddaac05', '1d9b6672711d15ed28bd19bc', '2d72caa3a5dafdb3b343b78e', 'c3138909fa5b171f0d57fabd', '946656a7c18d9898d7d2613c', '423eabf79f7a6b056f9dea1e', 'f460b01f60e21810e3c0e875', 'aa9cf98a6cfcfc591fd1d744', 'd1bf30f1b6904076c39146bb', '53ff8403c661d26f398402c6', '22c001b4fbec510a6a36e644', '240c55269dbe044f71ee51c5', '9304aef38384b969a06b3abe', 'd73c8f5b0105e85440aa6baf', '37c0bde96e8c70d1dcfce0ca', '28150962c7244064887e1cfd', '9cfc6425bde940cf398a73dc', '3783e47702fc97ed7cdea710', 'bbfcc311f9650f6a3a91f0b6', 'a790bd7026f83ac5ff0e68c1', '9d8591acb0d3258f159e45cc', '327a6b8b85b9df578f97d124', 'c4583562855d6e407a1c88ed', '08a1f3896026c957daada255', '6e7eea4d83bc22c485bd34f3', '2c1c7ca9c89b574bbf2e0995', 'b77757e9df39efd72596255e', '5fd4f4ab7afda4e90c2af26a', 'a2dcdcf12890887cb1bf85a7', 'cd2f14c6acbcef17dcbd4989', '5d83b1d1c458bcc64023c23e', 'e447bf35d8f5b5f515e7b40e', '1b56d7ab012fcdd2c4eec4c3', '5ccd34698e938f99b49819c5', '42a736dc3448b6c72bebe5a9', 'b727c4a8aaf41e038a4aabf6', 'ded7c37a33a0d81b227fca60', 'f7dca6ca66a468ed7f41631a', '94693223b09516e219df459b', '9862dfab336a7e119e848d7f', '188357b19ef7a1e1306dde6a', '03cc245c1d997582959cd48a', '5b73fda84131aee9f4b13b57', 'b491a9d1d8f94456fa46b689', 'e0871385561b20faaecfa48c', 'bb4344288238a4637074b5b3', '7615134b4fa7ff6ddf73b525', '45de049f9307b8c592a68f2c', '03cee97f39a5dbd735cc25ea', '8794ed581e861d00471884fd', '46ff832eeb6e9d538497577e', '115e3caf13dbeb8dd223df9f', 'c0cedb965b06326bbddb2eb4', 'dc8519f946507f8fe299e28d', '2eabc9e68c01f195e82de460', 'baddc58b8aca169735d88f8d', 'bb88168bfe852b10ec4208d8', '7ba5a831808e4e5851837fe5', '72f9d3cf5bb88a5d34be8b2e', '7d9cdd88b75501b509687396', '103007809bffe0c602448146', '6fc2d38e2e0de21eec21ab72', 'fded99b20da76568aee99315', 'e93e1b76d0204d31a3174cc1', '2753f3dc8c10c48e64cf034a', 'a59aa4e1124cf98b542230d0', '275184cf2bd75d7ada2cab2a', '6d16d17d6f59ace9a2e0a9bd', '7f9f201c03d5f3b1e2d247ca', '122e9c77f038fff730af3012', 'b678b8112793dc9ca55c90b3', '4ead555e8bf055e8e8c7bc2f', '2366c7c9140924ccf9f4b123', '03a5a6bba8bab1a26a453a24', 'f5b78cf9f326f6c6ae745067', 'cb9ca5309bb33b28efa1b130', '9b0dc7c21af10bc7f1f0ef8b', '878106bea4b63d355fcf0ef6', '25df58c9b9009d8a32d96d15', '232cc5cdd5e1b965d61da342', '8ce7af691c9be7d9abda7cc7', 'fb1c9ab851ce79aecda9c32e', '7f8e8713a9f47bec5ebb47bb', '36d78a53fb451b1de2c95f2f', 'ca2d821af5309a1a9e06bffa', 'bca05145ac82b49ae8acc4b4', '682676ee539e16fc31ab086e', 'aa3736eecab5271da4440d63', '86831d5ce56c04ce7f23fd47', '942603b5dceccf0a7d2a31df', '894403f12b36b4f785b9894d', '1138580aa607ef75fdf6df17', 'd3bf0e541f1e4e8cb0f4066a', '28f891c6136adc2119884018', '12fbd03c50369014a82f4756', 'db4ef4453f0482846262ad5c', '004aab9ab72eb76ab6d10d57', 'be05d63abe091e094958fc47', 'd7f6b7afdf1779d271fed4bc', 'fb61ff0592412ac1416aee55', '0fd2ccbe30809ad0253a004f', 'e474a2417040aa88bad3b8f1', '4e6dcd007988152470193f41', 'e65b59a5ae495773129a972f', 'c7913f24b079937963ea9f4f', 'ab6c84f4aad1e16e5caea9b6', 'bbb1655c44fb049ef7b879ae', 'ee666395a082d03bb08f340b', '02c83f838a71d8a05881f29c', 'c2e4f992fdf2b0fe03106e5a', '774301e86755e13414d55d0b', 'e5f98987539902de04cf8a9e', 'cfb014c016bea7b3e220c08f', '771257ca5b02630533cafe73', '3c937ae915d99a3eb8b08241', '07c1c8b47f2651220e2fa40f', 'e65459f8f7e59ea27494cb7b', 'fa7d9e05618f719c725c75ab', '6a258cd10ee1f1a03e0c9d23', 'e4740c820cb8320bffa0e957', 'a0275ba4dd2c244770e9553e', '27b1b0cb6cac06060411bcfb', 'ba0e6ef5be18634efe802c90', '1e7fca2277094f23cec3aa76', '8c24b509ca406f3cf4ea3e2a', '6c8ad401188a69f144f026f6', '3c573f4b3f5561f9da5c2ca0', 'e8f80475c0b36304390859e0', '55ea65a1f7c485a457c4696d', 'c98219f7cb3992603434bc25', '0d3e4b5300ddd4eb6f8b7629', '32b1864cd437a05f94495679', 'f46e8931e74e00facf2ddbd7', '592fc15a830589ea90962e04', 'f32d842f0e3bf602efb3e22f', '9b039ee786a20e3b239037e0', '7f006b94d6653a3b89d33cc2', 'e3659a41757c0fd2645fe816', '45b872b3b1c160f0ef5249c5', '476e4488035d145ab89ef7ae', '6ad5a9078781b4734aa37e35', '112cb104c8ac40bc947d642a', '8d848bb37c4790115eb54b25', '773553bf367568bb392e4143', '26ce902d74db9f732e88776c', '95f50999819423b14b82ff47', '30472e5c27673faeb87b6a0d', '39292afed1a39dd0e0b8a031', '21c6f3b0cb788bda4faf8249', '8a3f528d01b5216685826b2a', '876fc2621bff0c8dd69e9b66', '06e428e5b1ed6505097a25ad', '80804f44b70738e1d5232084', '05d218c03d4f3db81a54165a', 'd6c2a396d94d370d6f2348f2', 'c010215bbebd2aff0b853669', '35cf8678b7b636890f6218de', '37e1a7e88398803e5188be91', '40aa706064637ead2ae39af7', '5f2be37c9bd6389d80599c5f', '8478e6de5e5ee9e5033f7355', '861a7b73edbd60ca44e59f7c', '179e0c7223f1d82e5c946ad0', 'd6b45e0644198773e61b027c', 'd8ce0d4331097090b007f237', '47b903aa15da43a35db353c7', '0c0b7b1acba7c1472c2ffd97', 'a4b29cbfbb96679f14e6eac0', '82ed4968374026cba4624178', '0981b590800b50362ed9bd99', '5cc361b3a9d1cee29ed3d437', '11f0c0917f60ce2086cc646c', '8fd77ab450ceaf3df06b0177', 'b4067b5953f2f9bf38f0cf12', '23652e6ecf5fc87dd7d50a98', 'ac606737f9bd303254cf3a86', 'dff52a931ff5d9812d2e68c8', '4e6d83c0c7ba1ea3a2bf658b', '064e1e18ab989d89c93ed694', 'ea237bbea67442bc6b962cce', '4c7f81e40d7fe7c76ef35275', '0e2ed5b1977c59f79cff3b72', 'fee1526403313e5913e5874b', '1653c4779514ff5b7d86cad6', '9d1688657943a3556c9c8704', 'e720394bdbfa2cd55a520dc3', '966d1ead03418408fd0eccc1', 'b0b4926abc6fba2f9b78a017', '1c91054ab8b9cc71f46ad1dd', 'e9f0066c2e5b7c4c2d7fe515', '560ac67e93ac8a709bbc10ea', '5a435c4f165c08508edbd449', '3b0e6898490e151ff0c9d63d', '7ce2a21d5cd40b04d8cb2c75', 'f21b3abcfb7c410d3b31bc30', 'e8433f2ef9b3e709b1fe04cf', '5b28d4b561ee2e25d84025fb', '73d71dd48759ebd3e31a1e91', '1d5e1f6694e66a38eb9d48b3', 'e99894fa240f028ed3221457', '9ef4ff1a80eff792fae7eaf6', 'b58e546890ee6007f8e2974b', '0a52d95713114e75cad62068', '567c419acd4847f820befc6f', '0caf055cee4dccc45176c275', '2dd85238210fd7a67447c15c', '4c511e76ad5fcd971a417e7f', 'cc3ae3ee46938d74fbd6ba5e', 'a6fe11704f68e1f821cfc45e', 'fe646e876da3a9452e4e05ea', '4a6773499778d85e09dc660a', '5452c625522e88957199e9f0', 'b1ee8ce4305d98f2883b695b', '5077dabbbdb1f143ad870dd9', '4d0e1664ae29fa72ddcd640f', '56cc6ac2512f4026f211bada', 'c13460734de88497b6d17501', 'd6557e346d781e08feab81d0', 'f0a44b72608f1fb8a8a9bebc', 'e93b96a3e733e74dba4a0f26', 'bedebf884aabb5a8dcfaed9a', '740e35ffd9a5157bb6bf16ad', 'a092e1a9ae5251db64ee68be', '1ada788cf4c8e059533b5f04', '4d4dd766a53d16c73dfa5445', '85d31f9d8735d20c26163c0b', '189fc63254a11c6dfeb8fba5', '937063660ee9c96fa16dd7f5', '2814f1edb1bea5a93666884f', 'e22e5a88ca77a9f96af45fd7', '2c1f374a404a551c3391df72', '9be85669c081afc82d4c6a57', 'a5f1e48fb3c060e9e95251f2', 'af0bb751dca92abe9b101475', 'a3481de61e2fdd7ec5b2daad', '11b1d4acc1e68f70deb1fd99', 'fdc15c3b4760871eec9eb7f4', '2ff2e805ec42ef3feedcd1aa', 'f838d7118ed779a45387d3aa', '41380d1d5d0e6d1c497a8317', 'ab7b619c104c7acdd3b347a6', 'b9aa9ee30245b8000f1127e3', 'd711ad001701aaf7a999ff6f', 'd518a22ef06007a9c93db34b', 'af972afb21a4db1766988356', 'a773e86681735be6c53a92b5', '361dee11faf11169d073ea66', 'ae5ec3820a0b5ba66f56bc5a', '822c7c92c1f48adca005dc81', '81ab57679b81047f17e36e2c', '52b4c6302fbd18b90e270e93', 'efd16ed6fcf1c6e667f9bca7', 'c4b6b11d95a82c6b74f94e76', 'e2ae9a4a36ba36236e991b0e', 'c1ae78fc2d85e6eca4bb40d9', '17bc287452c28a3ba71e2fe5', '0ac5e8c127eb6f8f74e5d260', '7c84a7a9dd72cfd25b8b859c', '018d243f5ca33716687af47d', '86c276704c3a408a1f31e367', '6316365253c771062657103d', '3b7aac248d67a932c390edb8', '9adca592b48d4fd0d62f45d1', 'd84c6c7fe6daa03fe7f81c8b', '4ae26018d8ea48c61224e513', '0367956da12e06e2e598864f', '1af0e5232d922453e5d2e3ae', '0eec887f694582394cfc6f10', '8b3ac39d04cb2b0c9c7c2ef7', 'a959a44bac364940384687df', 'd1786dec0eca017b0b1f5d7b', 'bddff1513f83253443df0ee2', '55cd50500d3f96c291347d01', '670b3cac2ff679b4a4fb429c', 'a6b9ade99c3cfb9b0eddcbec', 'c91e6629b913e405efe9b9e5', '6767d8e3b7af5307480d3e8c', 'f603f6954b5ed9f4cb1b3c15', '74be377366123df29a790c8c', 'fec026b891afb9bccb1664e9', '388e3fc0fa30e6c5b9011872', '45ff22c09f3754e81e8ab8b4', '1d35d6275c13a75467d5621f', '99dc14e34af5f8b1b714560f', '79e773e17e3c570dd78813ae', '1696ad4b19442533de0141ff', '794da47ae77cd75fe2914cf2', '7fa8d89115dcb79bd3b9d8b6', '30bb66210d2f8e9a6b6b709f', '395c9fa32c41aa7400cb5a87', 'fe5c43f286b65fdccd87ecbd', '1938b1fa4edd438feb5ae416', '1dab5b5124587cef9d328d99', '437ed2f1fe3f680053f1e3de', 'f4d88d6b65c3f2fef3bf62c5', '87278f47491e99c15504a52a', '1f207d94f4dd9613e4d69a5d', '7170b2897858fa87237babee', '9e7aa17566ee6e70df48c838', '4e5496cc5a22509ea5c3e4e8', '88a6c24100e056a0cd5afdeb', 'c4cdd9f12bc74981468685d3', '5a47ea8047b87b5f311738fc', 'aa866c43eb90dfddc649fe35', '88903941545e70b4a021e3b2', '6ec5c2c1bd1fc8781c4fea87', '285483bc9981158e35956874', '921675022a09cbed462a1741', 'b3b04512888e6be067ea0094', 'f2b643094d07ac4dcac036f6', '77a561b95489d211e0dec613', 'c6666ef9e4ba2cde6ec58824', 'efd275d1b7116eb72bf67aaa', '0e1d898b2e27b9241962d250', '4e1f8471625f8559d0c64629', '742e8151840906cdb2000fee', '59d3175a30ad9fe65e39996d', '558b74ae3a2858468e9b6d75', 'ba3296488999e2e149c3a32e', '781ef8abeed146047598411d', '2ce2c777d5cf2c8bf9c60de2', '97da967a6eec6c3d02e10772', 'be95e0c0ef52ac9abbba1a3c', '4a41f13171a4d40a9cb9e53b', '32bd2842efa8e518c4f30155', '30604ac94506d0892a2fd65e', 'f710a9e23d2b119bb3cbd7d6', '6d3fe547b78cd9bdc187e610', '5a0f11cd2d321ee0bbab6b6c', 'f26a53de07f2471e33f3f8b5', 'd06643d034d4d04e5457cae5', '3e877dc92daa5d8f28115762', '5565327861ed5fcac13b11e2', '34a5e8b5a91c17bdf4999b17', '935c667c51ade2f8d9a18b79', '63e6ff5237da6b07b0c8a2d7', 'b2506d21f50185686a959e38', '7fafde7941ee8321b6875326', '4a4b1ff6e491614e8bed8e49', '465aed14cf9939565ad6d4cc', 'd44b7e9b8f15bdcd053d65f3', 'd80871d283fcf3c937bc3387', 'f6066d140303a698b6edceea', 'a803aa24d51a01da7f6a534e', '9ee9faec0727283454a64f52', '120f063de471a96faf9b302a', '8ad9e925a3bc2f9da4940ed1', 'a9a9222a8d37bab9e6d5a6a2', '54bc89ef44d4c2ee5d31aeec', '36961c041d723a40cd3af9bc', '58005b8292ece24dcde6f455', '7172db99077f820626236cfa', 'f591b46504d2236b89d77bf8', 'ae10b786bdd68be86808411b', 'f0229fb196610726d6ec7c44', '94ebd65b4f618bfded23ea2d', '8d6edf1fda9d534cd9ec0c9f', 'ddbe991f30c6934480e21599', '2ac19b54bada84606ebec21c', 'd97ce57b0238741d318dd305', 'c5b41500133543c1bd41eb66', 'a5b1c0e43266c3abbd391cf4', '3c79d8c37eae0b006674c9c6', 'b661bb18d48da0b0b3f54277', 'a8dc3b5c9cad1f39f5e216c6', '58b2237d10cf18728234ae55', 'ad935ae937227d5927667234', '1dea8e8367ea15758b8ca92e', 'd3085358f26b085a3251d71d', '5ce9e6b643c409ca7510c4f0', '53c9148b613c58bca3b23674', 'ec8e06e2b743a81436720c46', '0b6a628ddf97a2a792d52b70', 'a4ead1605ee2cae02541b57b', 'a81a9ceee607e440b6b6e0ef', 'bfb03e1d79c3802ab3081d33', '45cf62bc8aba279eba7b413a', '9ad11c0699674c054d7a4074', 'af3705067de009f76d7a8031', '8da39f47f61d4bd9b47d1f6e', '5eabde65a4146642bc2431c9', '99ae2a1c4797235aeeccbd8a', 'ab584de115671b8402117e00', 'bf638c88c79e23f84c8e2529', '0920f71c3325e1a9f1fa383b', '38d26509efa287e305910833', '1ece08272edfd635b238cb47', '231d73add777a1a3ca6f2873', '8652b04e3fb0b55bfcabf37a', 'b663ddcb1000b3c27f988cc2', '9f56b7e6de37d05e0ac335a3', '0bf13d65d6a6c37aaf9ffd42', 'eee2d17dec0a42b12da8deaa', 'cd0bcb070c47177a7ad4ff35', '05c7819c63aa7a68dc9545c3', '07c2cabe27d018ef8bc90ed3', '6eaa704e430235558d82f887', '5035c14e77fc86f7e758328a', '488e2a77c6798e98c810e20b', '5e26962b8d9bc2994ab47e5d', 'c189d34efcb37085fa7b7cb4', '2dcb5e76008ed58c6fcf21ab', 'c35d03883eff2c60ecc563cf', '0468ce0daa5a2cba57e45350', 'c559da124dcc274c8d5b1e61', 'eddd42b7835d2666ea1728ba', 'ad9224e407b2a53c4120193b', '7f904e1c55c930388a753052', 'f4d15c6e05db8c46f07c865f', '7b319dcf4efec30297a50d9b', '3d1061a32eb79f759245bffb', '06f4ed18e0175feb847ceb18', '64417089c0eeb8c42da6c9c2', '896c8f2f1440f307d4f71409', '5a702ecafc152197b73cc54c', '6fae636a877faa698dbc3148', 'c296b026cf38437fb7dfc933', '3d734e7730e119eb7ecbb9e5', '09a8d5869533c169168ee661', '131ea45cf61be3a504988801', 'd0d4ddd524dec4c4fd73c769', '444002e65b58c6f479197866', 'c9cf1ade991005f5fffbd47d', '2ca4465dba3c16260aab1d62', 'd8faa21afb298080c233542b', '621f1abf8ceb45784a8a62b6', '03126bd2f49e133b299a8f4d', 'def0418fbc10900a82ffd5b9', 'bec56d5d887095fdec4a748d', '54422dbdbf89248bf6be26fb', '9258a1a83e5bbfc697468adf', '561c6a4161ac2feb86d80aed', '76f01a85f8f50fc5f408fa3b', '3dfc1e7e0bb1375c1771ec03', 'c32cd76c5b0aa08c81251752', '78512e3b7c9ea984222bfee1', 'a39005834defa0da659aa0e9', '113cd45e55e5ce4b019aad28', '59a23b41fa280018e0e17257', 'fe9f0b6e8813418d172e1e1c', 'ddbdcf0355e30978ef2bda62', '6b877eb6c1fe51cbc74bc649', '3a019edb3d03bf43064b460c', '510cd856f97ccd8e1ae62400', '88fdf3da1ae1fa49b61efe01', '99da27a442847a01bbdb593a', 'd838d9dd02777dbf09b9e81b', 'ba575890ff7ebaa1dcaa88c2', '3d81d416bd9cb490c9afa856', '3f525ce33fe40722b1b64deb', 'bf54c19771c5bb94ae4d9258', 'b7d1939430a21c6f12cd36da', '0cd0b92b050e9e355d9c8775', 'a7ffd50743215e43ab4b4249', 'e8d600176ca42258e8ab175a', 'f98f47f9d3ab7a1af147e5ac', '26e67a0d26da3791abc625a2', '9935a33215fc04cc9ed9c438', '3ba74bf54de10d143025c7db', '6a0ee1b4229838dcbe29e41a', '0112d30f1318ad87f07d5ace', '5a471bc5d991ced2d535cfb7', '699d1833d8f298ac738b03d6', '6efcf394736a462c14ad905e', '027be20fe6b2508766d312ac', '366e4fe872705e8dbb87ae20', '2384e194896033ece54e7e01', '0cfe903dde7855d41478137f', '745585ee3b0d6a5e1b414a94', '0eb2954ae5544e9247d70c59', 'c1a661557ac7c238626ba6d2', '4981e0855f969f301153a2e2', 'bc8f51d9cc16b51ab2a55aaa', 'f5024826f56df8252bfc76ad', '42caec4ca4a8bdfb2bf0e159', 'cd05e6424347ce699cf7b7cd', '690bde321b749a8d1310a710', 'f07d01a1db0173ba1a3cfff4', '654c90f267446af8ba8f70b5', '23b4c91212b33b3feec1624d', '6e4750dd27d5b6fd5f5faf2e', '615149dac9c4e11fbde8d9bc', 'a7957c2fffd3930db882e4cc', '30b60fadbc9e5ba919ab8f81', 'a1d4a46462d0cd1e638cddc8', '4f00325c6536b67bbcfa20b1', '8419db544e116248cf67bf17', '296ec4ec76a62cac4fd007bb', '1e2f66da2eb65a0b588daf76', '60bf7b753de50724e7fe0465', 'd701f4d1d856c591e1e4c95d', '4c376d728b885b57cae6d692', '3b2a3869e8ca4ddc183bfbfe', '3fc571e83a604003d6461674', '340a6488743a4a60f4797d75', 'ca8aadc66b1fcaf0dbac962e', 'ca889d0ba7397111451ebf74', '88c671a2840f4530415bcdf6', '5d27d425de44d1e9e60bb681', '0843691130d6cd5cd2dedc9f', '4293159f67c757b21ef6659a', '1a2803a90ebc58ce4b381cce', '271a7ff6c3f876ddc5c5cbfc', '86cbd6023ea3c6b4277ad089', 'cc2bba4f303536420f4558fe', 'a5828bf7dab24b1221372dc4', 'e5cad69b2c1bd6709789926f', '5238005ffc47bc3719f52f2a', '55298e7d2d87edab46d2e4e0', '6b6d306062e42562e6047276', 'c8d18210963921f83f907052', '4127d2f4d3dde8b9a50cddeb', '5febe2a89e917d60303afd4c', '68d2cf8d2fa30727fc51e480', 'eb7bf6c61602ad306a17337c', 'f85c9633e450cf4188a98ce3', 'f094acde3e855985c85bc122', 'e3c9d792118d17e382f1eb65', 'f0106cb7094a1c199a9c6565', '5cb77adf0cc7efec9a38adba', '5acdc780ba8984cef61073b2', '5d8d3d9c0e88b7b656bc2f3e', 'd47700b1f0c8efe72117c59e', 'b1a78da076378d37eda3aeb6', '480c4f9f6cb6210afb07ec17', '0825d95545721aa700cc7fd0', 'd74b04155d86c3e804553ede', '920ad0d7946eb3abca368599', 'f90c169bc5f07a8ae6dacece', '9073e579594a4c3f92dad212', '99cc6b6a7018e6ce37338641', 'a4914a96d11642f0050fc3d3', '9da1c2b4d2477e7d54541e82', '0cd28c037e9d62e1fe5d608a', '78c274657cd4e1d8e8b02190', '7cfc885a581b81aedac1d706', '880554dbb2de7644801cbf6e', '5dcb3867960ccfe76a673b5e', 'a6e9aa314afc2689dfc084db', '98f8d45306d4c05c5916a214', '767f78eb035eac463d6a7505', '05424dfd1bc74bf21ddc5688', '4694f530b836736c5f4fd656', '03597122b60940059ca941bd', '94b0437ac528f3909e945a5f', '69b677906abcc409eb49619a', '7ccdae90c6ad3af703d3e038', 'd55a49b733c16c813474898b', '7f326a0a5a46eb805b8f5a56', '567d369cd559cd950e3354cf', '9bae33f8c355733757e36325', 'f335eed9cf01ee1b0747a75a', '563335adf3dce85aa6c280d0', 'dc9b13fe2202c498d8511fe7', 'b89ae914fde1da12628b1901', '008eed7a13c0d37c26d9a293', 'e39761455f93b4f0ebb90b4e', 'abb065f7fb28acb0c3c8fb68', 'b5ebca4336ca90885d7d6381', '3f228b2d28b47133dbf76724', '098602cc877f3e4c36bc908a', 'a14b794e12f6637f98c72ade', '052079a05ce7afbbced7a57a', '95b288888e266b0b15c485fd', '1d3f884b7931238b1dbb1779', '7adf373e9c0d4a3cd7f5fec3', '48e8561f4462026521fab248', '6fab218a9bcfb128b745f81b', 'dc05a582149cb9a35f095c0b', 'f5897f6587ae16c7c674b41f', '2c1feec1d1f2e0f1260812d2', 'd5ae1b4f859d19123f8193a4', '6d461d83bedc6045d8cf7019', '75ad30a366fbe3a6f2ed6f8a', '950bba952500eb9d19279afe', '68de14b96fc28cb3d5819bcb', '027706ca26ae55a15b9f1d91', '58dc0f1db2dd25ed12cb221c', '86633ae70ad8fa5a8c7ee1ad', '131676838dec830d875d80ad', '7a6b657fddbeb52ba6d8450c', '96e382017b141bc1518941f3', '908ae520eb086d09751ea4b9', '90c8f7dcff48de642efa7222', 'f5e30b7ed7e2dc03d9e33f9d', '37805d9674cc2e4525168916', 'de050e3cfdd8c8ef07cdf7bc', '9ab9f7bcf85120221b47db91', '5d8ba988aeacba3a822c6143', '003865fdb611e9f27fe18281', 'f17da97011f380b6bc7c87eb', 'f727d26ce2437b323535a192', 'e07839bc9af48a037d0d54bb', '67b61395fd1f2d6c03d0af1e', '5ea4690a08942372011bee45', 'db4af3e1cff04a496f2168cb', '095a491640c35f9a56195a9d', '5b1d543d54897c267c07f555', 'b02b2e4bfa20498bce6b232d', '5c5d5137fe45b2eb60a11cc5', '5572350469c75b9bc5b406cd', '00c6c90e6841d1dfe2515346', '3922a8bf089907b9a543783e', 'ef58c8f426926b9b7c5610fc', '2c1b4a7fbad74a8a44675a71', 'e5b66a1b55593f1824235d1a', 'dedd0a8a0ba377a957737cd9', '9564984f5e6bba259c9cbe18', '2706ea1872fb85222790f131', '0ad0dc8594dbfe64d10295e8', '85c4cb07f011b2641b16c688', 'c1f3f0db61bac26ec0d7afba', '2b2a1cb7c1f3e55513ccdcd8', 'f1c637616d0c91843526eb96', '620d90e5c2bc12b7e637d7b2', '05334e2bb5ed306293d184c4', '535fb807f200d61057c1b7a0', '362ddfa50f43176eb146320b', '28bf2891ea69cdd52915b657', '80466ce112a1c1006d70d876', 'f9308fa63d859b237ccb712b', '9c85a8ada2ee0422d27bcb39', '45e5fa3d7ddb3e52763ec749', 'f907fb44dd458e21bcac102c', '0878aade13d38cab157cad47', '5e86d97c72cc49ff2ce98709', '6aa4881be1a49d2ae7f3e749', 'e965cf8b6399b0933da46e48', '79257401a1158ff7232db9fd', 'c1b05b990820fdea69b71d1a', '67a50f9b79bc4e4a7c653ac5', '39d97a0dad007c5882b2d34b', '02e100aec6d99e6f5934caa5', '4637ee6f3a563e19535756a3', 'b2a5c5b1233bd06110dd5253', '2a3d64117cc11a9362dcd9fd', 'b6d9cd67e22e2ef748217cd1', '84ba715b229207e9b74e2c7f', 'cbec37a67b1882b8d6f5c38a', 'd6a206ecc5cbf7eeccb7956b', 'c7af43822b2032b4d685af10', '4c475fcaf3bf16551e866c3c', '18010be66782b5371bb31160', 'b822898d1d41ded52d61fbed', 'b589fb2df1dcb6da13ec9456', 'f3303ed15c820c9b329af410', '6cd63183970459480e3afa9b', '04f71c7e519351b6f93b7777', '99a500fd67403f12fc30f8b6', 'a09c071ef325a1bc1e1417a1', '0821be3636ee8eab640a750b', 'ad87f821d1417e88606b21d0', '66d3360a6cad5a5a584ea115', '2a32cb9fdb4241702a454055', '39d4a4bdf91208fe3d0468a5', 'b6b449e2a6346dfeed443761', '645012622fad2129a6fe1db6', '2e016fdfd5dd7f3e7f3be7cd', '8ca8f566936f59b5c916eadf', '8060993fd02e3caa91347361', '1bbc56c2fd1aad4535efd121', '9162de3307e705f564c4492d', 'f9f35588ccc8bc79535ff166', 'ae9c55faced4361a10905a51', 'ff6ae54dadd27c88cff99254', '73a651d26844c7e023b2bfc1', '8ef6fa9dfc5f788fb73b69e8', '438eaca992b625cafb55b6db', '99abc2a37fa7ff26ae5a4483', '11334e5323118eea80ce40d5', '04252ccebd8d2d108f1880fc', '5c20529abfd911e57654f545', '70fb08c9ae39f471ccb4c81a', 'f46ac5597a933d3aa191df19', '42450225f8907884075ad901', 'd062f51ae3bd2b4a5b501051', '0c11df1e6368179cdb62d5ea', '90edd0b36b71d1dde04a4381', 'ae7068db15837f529f79fa01', 'bb37a5a6fa2b7bfb4a31e4e7', 'd6c3eb4c10881ccf9ced74ae', '54ecb54032c2c4402da787c8', '3b483bc7971f9931801a356e', 'f9926355acee735005a5866f', '48ea16ef9a9f1871ed032c14', '84cf86069630ec83176f8f8e', 'fde6441b3751a0976d557a92', 'd83c205b14f14e3bcf90bd5a', 'b6403378bbfbec78e67126fc', '9bbd99cc180d65878b372ad9', '4ae4d8179801e38d38744603', '33bb875daecee7aae0a79d8a', 'ed8eb61d00ca803fbe330b9c', '1e7b6f713dc28ec89c51ea69', '8940911fa3f2d95d03fc272e', '618f91256c79080bd2fc27d0', 'bae3bed8ddded1a1b46a172f', '216744fcbadbfb5384e8c226', '5ee025cab135eb911d61888a', 'f6b867f588ae42e84d410450', '8de008a99045692b6c9079bb', '963d648d770fcb43743e09b4', '61467a096265ec16474e107e', 'e1784c5485d83cd0645a3d4e', '1a9e4c04cde439b3eb51a5ee', 'f111218b574bd10dcf361deb', '820528745b6eb9d481abf58f', '48ce377b6362c251e67e2e6b', '416848aeaf8b172ffb8fe4fb', '81fecc104d9ef8ac42378b81', 'e07bc2b8ae12376224aac0c9', '67f5a1fdc92cd01b4aedb45c', '48805e4216bd012669a77b8c', '1558f54b2c3bec57f2893d4f', 'ab0e982e3bb15b1ab0e9c576', 'e54938671b05e5c6ac687af2', '2207f2b9a9690a68915d6ab4', 'c247847fea9d213094a3045f', 'dbd23b051c5c2e2ce67a439b', '7a476916387b8ccd604b7f3e', '8ff3fa3aa1d227c7f0860781', '314918b25acf3b59dd2f8ad6', 'f9e2b0a131460704a8a57a4f', '16690ffc32c0b935ca799d7f', '8ab3e1bbd488c2eaae721412', '48a5e161532f3acc6752f577', '42ba16664bb27443701345aa', '1e6bb4278191e2e7636f9b0b', 'fd5726998d426a2fdca616fc', '757779a8ac74dd38488f923f', '7fc9012c75133098e145243a', '8683f07aa65fa12c04532cd7', '68827b6e5c9eec5eb540e971', '861e1a2621058a2c9affd693', '9f63970e733b63fae113c2a8', 'c2498660106f0841540500d3', 'f6ff7f1d41f19c951d2854e9', '44de7bcceae079f9e8bfdaaf', '921bedddb3b4dad89ed751aa', '4ad13911a0c3cadf96e3052c', '4391a17af3d3dc9b48eb23de', '701c361638b72b18b59910b7', '5205a0314efeddff42fe6437', '5a4d87a7bd80bc03275287c6', '85e40ee7c74d7603718dca90', 'c6fff4b55ab874dfb73037a3', '50231ace46e9680780376e5f', 'c84cfe8470cb11125e4f78bc', '581c5fbb07539eb5493641eb', 'd559f760db83349c7ce1a73b', '2ea0eb184438ab7110b6c335', '11781310efb83f845ca54e72', 'e7f9bc2207fce85235ec07aa', 'deb0649dc5dfba070e57b20a', '54cf4ad46263c89423b40945', '341d7a85d3366d8be3f55673', 'ae481d3d9b25f812bf25bdfd', '882e8bdaae60f6bdfa661677', 'f39b6fca5e6f640b836a9c9c', '3ed75cc0aecb87eee22cf8e5', 'f854c9821a5c5435e850b71e', '37192bb658b60d3559cff295', '473b5484bdbc4e254b426c4c', '8767ec4e6f5bb384a55e1f3a', '5a57c249d0fff38a58052135', 'c1a94ccad673ddf5a68e93e3', '470559b06a3cc6cf01345c4a', '6874b240b1ee6575829fb705', '3eaf001189831be5d9a41258', '13bbb7977ea8096ece5542dc', '792f2622a77b8638438de22f', '80b96b20149664dff5b51fb1', '77fee139a7a8698c4a12156a', '90ca159192db0f36dc910080', '86c494ae04729b5345b49a12', '82c59daa8e3a56e7f5ad97c0', '3ac8f2ef698c9eee139d3ece', '493f197a6d56dbacf99556ab', '49bd4300b2e50aa508c70a40', '4fb913f81273537cc819bba4', 'e07ed121ec710b96ce8e6acd', '40c4039e5ddeb88faf4449aa', 'da5f3dae68433524c0462406', '066f306279b80b6d43827f27', '9d564188b506bcd7d94a1018', '9f637b49dd6bf5b92a192d46', '116aad46ae0fef5a747954b1', '8c465916ae512fb241ab372c', '13742e41da6ed8f3b472927c', '62c407ce4b823a8f721bf1b5', '8c8b5170a56e94b0724e4b97', 'ace4be317f182e1697b40080', 'e1e117c17a8d654329d349cf', '00ab16773d5c5cbe1e63f28b', '3ebc0a16e6352b3a0ce7bfab', '0d8c124936a0fc726774b99e', 'b2690f1d201d900a6e245a5a', 'b0ef9ac5dcce6d06f4eb450d', 'e66bc926c13901e2b96e1418', '890eb501221e32541f524d63', '5767b253bcb5c54fa1aaaadc', 'c99ab73b237415f36d5185ab', '7f9686faa27e555657f81477', '4313578eaa6f5e20b0f3a246', 'e0d6ebb9ae85186bd60eadb3', 'e123951f763462b9fe67c32c', '4f9e42945038788848999c30', '3c902daacd4588721711f210', '955058f5985e47dd049eded6', '5c8d918b88b696fa22b10f23', 'ce6918d801a0e9dc37e563ce', 'fc73eadf00468623cbf19884', '4f2d444fc44c6244f4d959c7', '70d4f706eb7c1197729174d6', '4ebb5e52ed23ff0830bbedbf', '4e62b0e57830a46896da0604', '5b3ff38fc5977d41f2919e7f', '9906ee00ac2183b7e809821c', 'd8830bd1398db83dd14ba4d6', 'c2f2672cddbd186cf0790169', 'd073173860e35bfa703b57ab', '20de623f537039c51aaf5c1a', '51e8f8f67f2e66a1e780c1a3', '9206421c128de64e2474230a', '0468c52ae504e3db09fd4e8d', '5e099470827356f7917d86bf', '2723a0b2a202e96ddb72ec44', '6a7324498e10c064190ceb7f', 'bf1e8983b1cc3c09f253f07c', 'ae62f6afd4c306068c936631', 'ef47010e396a58191a716c15', 'ac0778f01b4dfce5b48de369', '193a8bd008df2bc9ae99adf8', '5d2e380e135d1c3beebbb4b8', '07032b1d51ef6d34a32ed424', '8c389720f8914eabd76867e2', 'dc198d4ae3abb990cb9902e1', '66a7bb5b8a5d8c05eb6fe97c', 'c1e6eda2955990fe92f24709', 'fc8ee142c3b432f169fa7cdc', 'f18eb420cfdd900530bf3999', '5c9e3563429336a3a6497c07', 'e3d50b7cc908a38055145b12', 'fa03821db7826057951a8f17', 'f946291e703d6e542a4a7d37', '5d54f26da17bc7fdbfc404d3', '55952982603c114a5b29a8b0', 'c1bb80af8e65bc3a342a8f5f', '7a437c8dbddf61c5a8051a64', 'c4e464a5e3c26b34a598c2d4', 'f8421512590cea257bf8a931', '92968aac60b31a25b1b7a9e2', 'ffc00c5a91336c29e74e82e7', '653d08c20f74e5bc126dbcac', '4f7c481bcc13707e66944d07', 'b0c7bdb6be37ebfe3feb04a6', '7793a26811956045c0aad41d', 'ac5c206d44772bba22a9ebfe', '127846a633997fbb95a316a9', 'ba17453769db45c0f15880db', 'c6e39eac55b1a26adabaa844', '7f969459fa4b9cddf822c495', 'e257942d050e74a2e2aef5b3', '08afa3fcbebe341dfdf62b15', '6fb281ee6d2d6ec101b35dc4', '799e8f8735eda5e3dfa8855f', '4f3f80819d74ba44d60716b2', '366c5a5077a210313a50c552', '5f0250669656b6e45463dfba', '27672ae2ddb12a394c90cad6', '389610e48fedce18d3b1ef8d', '4805f5b946dd24bdc7c044c0', 'd376f746682d3677c16ad196', '232c1cf9aed1b4611fb6d99a', '2869bb3db5897f9d72d506b0', 'dbb22b767c34f1cecea22ea4', '6496ef7a5d347a3e46d2bec0', '9d4a3fe390f0fef8dc0d86b3', 'd0c0f7766e9f698b1439c34e', '7fd127de8b5bc25c0ca5a31b', '5f2a159055d6adad640855a4', '19971ad86aeae49201fc7a93', 'c84349e69cbe2cf09f686cd5', 'b463fec617a5b7561a49f7e8', 'c9e6ec1ba862ca6788412403', '27c48e778f2f116680270dd6', 'ebbbea82024643bb7a0d0271', 'b184bcbbaadeb5289f8fd10a', 'd459384c23821c7436fd1a3e', '695030002227c1585f70824e', 'cefa3a76e1b80de7cca8cbf1', '695dff1ad99f6d2eb4de81db', '9a56a0173232de3b3d548756', '9b6f8be92fbf3a67eba1ac22', '0032247aa14645cbf758a680', 'ac99a2f4b7ce6677c8f21cf0', 'ecbc2ee919ccc6a0dea03692', '0f1f7818e92f4038e40e8fb5', '55089d9089a6992078371da4', 'd165a95f794e3d301e6f6179', '1d9b591db242abe298d896a5', '02aa04b3e6868db7eb1fed99', 'db2ec5a725e4b2775b055f88', 'f0042425f5c80fc4ec492cf0', 'a962b9d8317a6e4edbdd29f0', '2bbc414d187b0af13c72744e', 'a990c12b1e421dffb6cca4e2', 'e80cfa3eba8292aa667080e9', '405a65223844faf30d226448', '06c554d6edfd2380ecdb7e9f', 'cf4eb47f352c6460fa580827', 'de4256f2df1bf1aaa0eb15bb', 'b352e9e544d9e4edbcabcb01', 'c74358b1e7b5bc977788edc9', '56ad123e50882b48474bc758', '032dbf61616563e773c37078', '236ef17c9fdf9071b7c4a6b4', 'c3627e6abec2c90a0651a0e7', 'd12cf57d8405a554dab7fa15', 'c9bd206b23c8ece065ccbc5f', '59b4f366d08a05218ec8287d', '975040b9662968e36fedac64', '2b2758c78e28d13baca5b743', 'dc2ea06004264d56a9d2fc41', 'b6e5095ddd979d4bfc1eecfb', 'c08a8ca378cac26a4872dd1c', '89f0db596b270220fda6c25f', '79d16bbe75c1b79b191237dd', '4f56cb9467f8f3d5205a4396', 'e156f73b1bfc7f7069b386b3', 'a0ba285d46d08d5da3b63d69', '3dbc092974709a580db73d5d', 'bb12c097d6c3840101205ef8', '26f7019ccc450e407b7f54db', 'd5331cbc78765c496545988f', '327c193923b31d4de7547a06', '5c94acc60a698d8e066b2346', '87ea2c2233393dc64798684e', '5a251e4eca446bc174bf6ee3', 'a14cb4f846f35ff7611f1dbc', '0104804c5c294f840bfc43b0', 'c1dfd71e56e3403bac064d97', '4fd2779af0fb5ce25434c775', '4a8d139fbdf3433a295f03d3', '65026ec4c48a494f09194273', 'f59080441b975f79286dcd09', '0f36a6421cf0404aebb87507', 'ffdfd1a0a23a14c7d23101f8', '6c01e0679abf5f4770e5efe4', '83fcd6e49ddcd0e710cd01fb', '0097bca5984143bf4c458509', 'b9ac1bb7e36dd0d95acbf39c', '45153a5a7e5066d969dc5e94', '9330e1bf456cb3ad13b7333e', '37921e0dd6b843c93c0dacc1', '2d135d2b1bde82eddce53d88', '1f8f753b781c5e7a44238a71', '13d656d846a740eeb1467267', '16e880e54314b4d23201e4d1', '4de48cd89d593e47d6e93688', '46beded22d8893f7ce7fbb8d', 'f93686c3008e71187f331de5', 'a2e230e390689e566a02bb77', '5e42606ba946ba548d180e31', 'af7ad9cea92641ef8e97f7c1', 'c70087e768a59793cb584211', 'e60031fe0c3c45aa32032148', 'c578a495c2dae5a5b4a612bd', 'aa8a3e6c3b2e1ac22610e5df', '6841f0afef30c9eaf743f781', 'b3a9bd9b492cf5ebf684f04b', 'bf8b0be840875d402d706d58', '8738512f4dab78e20d4a3a23', 'ef514e32ea077744d1c08f2e', '9a53dfd94198f8a68458fa6d', '04c9a043e311b54b777c1b7d', 'd487fac15a8ce3ed54ed440e', '167d39516102c791d110d62b', '44e0c98b6f1723e728d1382d', '77caf8ab10948c4b56ca183d', '89130abd0de50ce13b9c3566', '3a8edca352170e0eec95d919', '6349f71964ff7e144cdd2cba', 'cbe81158af8ca0c5186959f0', 'e1ea16fb2fe09b1b73839ca3', '03cdbce2386e1c8684bf2a13', '8fe130affd01259653e65799', '506c9dbd5d01f2cf98f45ec5', '4b4a86909d0c7240eeb9f9f2', 'bb8bc2404e614f44d69a488c', '51beaf6f4ac792c505183c8f', 'ffd78170fcf2def8a4cfe87e', '3a3cae7df796116acb43c341', 'be836b4ae0b043e2a4a3ff81', 'b6d5c0f90ce664eba9acb6bf', 'd327924a18220cf4ac6ca8ba', 'e54a1e3c51bc1b0c7bca37f7', '130ed6628164c3afe9589f2d', '6b368507937b705eba056861', '509007e836380f20bbceca57', '4464d8ca9583f59be4160810', 'c66698669f239c7f44238998', '6d3b33c130ee573fc9b4e5f8', '6b4f7abe50c5cf5f9fe5385a', '4fd5da8b9c864e5a3800f681', '2ba257c83dfd7776e8506244', 'e9b6fc1c47118c5de09e95d7', '93ee1ffd46ebada0f537dc47', '4be47d4fcbaf07a2f5b1d8ac', '28f850662f724d2a12bab092', '750b75263b3b402e66549596', '5941ed9f1a4d31ed438338d9', 'ac7bf3a501336d2c4fb93d27', '6ee1790753b54f997c67b31c', '460140392f817cccb9e244d4', '1b28343aacf8cb3fdf1051df', 'ff9d739f6aef4f0e6a4fad34', '8a1a5f5b16afc5af43b04d08', '1aa433cdad6f6e1610a4c24f', '72544e79d8ced4be6541a0a1', 'e6c6113c42e3afffa9a446d8', 'b83e75dcbb1f8cc1a0718f8a', 'b208f8a2d2336ea49139fb02', 'af1b692aa2f8340f719c17fe', '88d1d764d3e45a0ff254d45a', '7c81288ded12d53cddc28dea', 'c7834523cd66eb840495c036', 'a30a6f58cc091f3a0949184c', '051c19cebb0a8796d0c84043', '3ba708e58388ca50083283e8', 'fbb2af617d1dcbd3c073bbe0', 'a5e4283c5899fd833228b799', '555044660eecd23dbd5c8fa2', '19bbba7c30b65e559cde2364', '6b9aea1e113e3ec6de66929b', '8a0c73ca152264371f4310c1', 'f1e84b550c51a00e780daaa4', '2eb3e9db6880c98531ae9697', '2ba80682f1e2b0050e0acece', 'a6965f79793a92b7e6553d61', '1a5433aa4aa1b3959ef3e77f', '68ed3b6273aa80637c7691c7', 'fa51b74dc317c3f8478a0ff5', '4613327670f705e8aa839350', '86ab734fd86c4c14b393eecc', '716b0a0b383a839c836a20ba', '72faafda75d4e4a844d6cd9d', '4aaf4f3c76752b37f232e69b', 'daf529dca91ee00e8da51d58', '3825f15fdd46e295e266d4e2', '0d8dbb180db73cb98f531c2d', '0aab4dbdaf2cafdd4466a80a', '855969a5637352d329e6b650', '56dc9b6a0a55ec1fc9f4a5c8', '6a4f0f27325a4881d537e381', '4e4d519fec610e5878e325da', 'd9c4c3a85c5787478f083a3a', '00bc7d25ccf848dbe8ebd03d', '46a6c77172cbf9196d74a902', '6c5ae1376c35e10f1ed23a4e', 'ccf62a429718ac33d9c26686', 'd15888d8cda931dc5035830d', 'caa992eaae720918e04f0b4d', '150069fefa392b944fd23073', 'fb908288af351cf6ad047aec', '48990ab07c7867ac45c57394', '9f458a33e3737acb61d26a1c', '87d7d4cf52e2d839fed96143', 'fd67ddabf75b779af8cfe4ac', 'ffbd3d45d651d7e4ecf8aeaa', '07d28012648c5a33f74fb154', 'eff7745b76fcafa8bf36d64d', '984b06bd38c5e69abd10d736', '8f5e6c6df7b4307eb679bfd9', '76457237914bf971488e9425', '7f05f81e2c4bccc575d180b8', 'e6f3a62b65568a7ae075f4d2', 'c0684c1ca2e984f005e2f914', 'ef4ea41e6cdc6751ebe50de2', '5f697dd690488492bf17ca8e', '964c6e643ec90bc499a92aea', 'ee1994bbfcf913af08ad4dd8', 'acabae620677b5ffeff62317', 'fdf5c1e275419554ef051eb7', 'c630812541cf6dfbf08a52c9', '362416f9fea1bf8466b44a48', 'dba29179e51c6b419b68143d', 'cea6be007be41bfc9fde406e', 'bf7d668907b28a333bad876e', '6cc10dddb478d438f52a9dfb', '47e52d08523b3df6810e4e7b', '3018865bd3e3ef7fcede4eb2', '94e88227ead8378786e00436', 'b4a201694189deda17a0ac3f', '024dcd124ec3d33f8ac7d1e6', '3355ff6ec63f5859b0030ed5', '7b61d39dc6064005d5fe1b91', 'b6d3b1cf1ff9f38a9adebb0a', '063d2d7c311c16f3cc0916a7', 'de0f8a295e6a5cf79b31633d', '9011b8d82bdbbf46bb8ecbb9', '26d017535d48be13b43f72f2', '1794f31aaf8abd01fe9c8e47', '132aee5ba3480c54ca8cee44', '808756e7c648673865499708', '5c31e3d97360a4d0dc136eba', '42ec95f5707880f8478c4eb9', 'c5f4c7e6139e15ca5adacd50', '02fe4d0195664f0dc082a343', 'c4c116a340d78cd933a79870', 'c11781d3de0756093079a3b6', '924d74602015e6d3739732e2', '8946a6077d0e165e482e261f', '5df781cee8420b4e67b5b670', 'b3ed67a0532299ba3cb949a9', '34e916a3d87884c2b17eed2f', 'ba8da70ae7c876cdadf6d50e', '3b6ed4de3ab4d728ea08e28b', 'fcf30c1dc6ce58162c86998c', 'bc12c47d96a21b5e21142ed7', '41d43a2f58e87c8f4d88b801', '08996b07e2ed8aa176fe423e', '9dfacc2c7888378be3ee3aac', 'e55cd6da77f12e9a3c3752aa', 'ba4c239a6efd2a45b4fd4c15', '9f9170a12486ac9447866fbe', '986a2a3bde40fef4fc375ef2', '3c0ac8693894186ae1e49461', '412c09bd6869eec57b61b8ab', '464395597c069391d5a6f398', '43731ce15c8a2d2bccfff70e', '3cd0a6cd42161066ac6ee01a', '218a35d3fd0012d75ff34412', '52505c841a4763efd35adac6', '65e654ff18e5887458e5aa25', '69b33b1e544e77eca6472b64', '6d177c7ee3f8bf320492ec8b', 'b90aaff4f6dc54dd7eefdaae', '960af01d63ac5e922c0eb129', 'bf8467e0d8948ac0db8f7fa1', '217aba84a14d98a4827d6be1', '4d9bd3d3dbfcb23cf47cb0c6', '19514defe49fe155ab776c71', '2be33c796f39654a64acc2af', '217fb62b4029d43c8d4778f8', 'efe02e55b9988af366a8030b', 'fabc6fda184e4c3f17a6f07e', 'ccc5d12c1c88d7a708f03f70', 'b6cd8d8d63a88cfb0db6d978', 'b91c712088f552af0be44e46', '722cbb6c7cc7ed4d2c24e87d', '22f424d1096d768470e60a6d', '52ab9f0636d7c7efa44fbe81', '1117a3336b3c103b088eb297', 'af2418efda8240fde827a469', 'e459f2e457c29b8387ed9964', '73f03c4b396e0636de5ad08b', 'a61a197e35f3b625c9540a0a', 'c5d9d0626f74f9062b8f7509', 'abc85f653325ca0da7e82fce', 'b1838eeaf67182e2d4080d5d', 'dc333dc95c29a9b3f3719647', '78444405504330982a1f5e0a', '1e8e254a1ff71001475df244', 'f22d564ed9f345b78756fe88', 'd84b738e8882f159cbf1debf', 'cb28a22dfa640e40700d6ace', 'e71755ea81b230d5dd2a212d', 'ddf67e92449897f5c52db5d2', '880dda6394687e6af314914f', 'e1c93dd5e81567e826a17f47', '95315cf3377aff338fc6744d', 'cd94bbb9784884dac45123cd', 'dc972f955fcddfb8a89d6ba2', '565427eaa17c1b7db560f4e9', '055c46f26772f5e92ff54ba1', 'e487dbd0cdcc7e16522be18e', '86b774ee38e2c7aa2ac12919', '63e5457b5b019e78c8dbf939', 'c7a759042b7285ebd4faf3f8', 'afe1bb1212af5b8def3b6bca', 'd0b77b1523060bc5563a0484', '4678e394b805643ece243dbd', 'cb5415c33f751a6b441a1cd4', '33dd2e95b6eaf89b0361b109', '897c83c8728e2e3ada59235e', 'd41f44da71b3e6d40f476229', '37f2202c7041980e8e71b098', '64873d6508dd0dea262a7cd7', 'c57560772bbe0f01b4467b62', '1f9d4e5d9ff5a5dce1860541', '931a6cae10afc8a4e19e7a2b', '84ee48b9c8a46dca91210f99', 'b6c95050bdc4cd4c317d476e', '949c6b3479c7ce4f2acd3003', '1c66f7fcfad7cbff26b54abe', 'db5bac94ce7826d253dc454e', '0f3620b0b09198874571d19d', '6277902bacde54e836a5d433', 'dc47e1e9c572da5b543bcf0e', '4a42f97a1663ba9024599519', 'cae94b9b74b0ff5b8f016878', 'b294fc478c483f32414156f0', '5d2dfd7a5a2882eb9da2724d', '408df91458c4945438a0d705', '367a2504a54faf728f7f96fc', '56950cbe39154cd6825d8851', '83a394225c13181e2fd82725', '8527b64a6629ebc78cca2a01', '9535260fe83b84161cfcbef0', '953f77740c16c1a9a435f427', '9e9072f0ced4b6c391c00916', '88a7b298bbf40e3593b5f065', '61ac6587433ff400f0293adc', '7e323066fd515e38f24d8cbe', '06b6972a43b2dba9856ec0bd', 'dc27aa9c5779993d3b2034ed', '39619ec2f079e47413f41d16', '2eec2f8d9b73d99dd0701546', 'f3e83011de5accbea5625903', '65de4c7841bdbd16627b5d55', '12a5396f55e7c3fd73c0c640', '8f2bc494dad4b896a4fa2912', '71e8c2b5076850658d8e63ed', '5e54019ee712a69d9eb50369', '0c54d58c887f5d5cfcec260c', 'a7a3de424d31c00f89567ff3', '49844eb3d519ede694dbad6b', '62ccca10373d7fea84d98e31', 'd1c26e1486ac8b878082f4ea', 'b90455e3cd10a2bcfe8f3419', 'ede3b2dd4e96f4b8027fd757', 'fe2b896743388c3285fd2973', 'af95f1ae9259d68f2fe0a56f', 'f056ac2de0d1253ccdc6c556', '7a01a7e71c780f176eb7b360', '3316ce93c81fea759846ffdb', '089ab5e83166d7733ba43ccc', '9b2ab198452a5ac2f78b9ebf', 'e6f198df1f603a2a44353e4d', 'd8a47bc9987e7055d48e418b', '527f4ad3f397267a5cdd7622', '0939295415266bebd843029a', '356174c53f28f728dccdef72', 'c1a9f03dd5bb3142dac26180', '07a08dc4b74589ad11ceabfd', '21516330871ebef6b95137ea', 'c7841b68bdb2089ac264a977', '83ef051d3b1070d79701011f', '2de4e7fa2f4e70e798676fe5', 'add9d8c55cfa9b469ea183bf', '3f09bed66cb7c82a92b7dcb0', 'f0d3b6aed52a69df797206eb', '876c247db73f4411e78223a2', 'e4c9451763f7e1edfdb8a185', 'edb3cbffb2caabbeb6d54ab6', '35b706cc431e421ccc4d295f', '8121c662bf6e3f319ab5b9f9', '9628d71c349327c8e53e3df4', '05a019fa9f7c243ee7ac5682', 'adcd9306676f578f4acf1d8a', '4daceca1922e2f7b36597c87', '687bceb15b59fc60e8fe6650', '671549860b2c1a2b4f5752a3', '3658db3e1651d577b0730f29', '9b11adf840122cc37bef0ed4', '32add9759f1cb2aad3668ce7', '7fe3a3267061ac2383bb66cb', '17b596080425a3e13fe4f66b', '00144320e5ae44ed871c5db7', 'ef8f70442734cae2d9b783a3', '3cec04d92cd89035dc5758b1', 'de2dd163eefb7cd6f7fe4767', '11a1a3c59f2b62a99f566f9f', '938fe2e5e3beaeff9c65cbe4', '513415b2f83b280737f76ca1', '6b24642366cb89db4096210b', 'f7c14865b950690588b06349', '64b39620ce3e1a170ffb4a84', 'f235f99faeb9fd03302dd63c', '97b11bd8315c504b3001f159', '47b3d7f69bda0102d243c44b', 'fc39ef8cc2866f09ef373bdd', '14f4bb19aad791593fd86e30', '819929d03e825e64c34b20ad', '6560334262dd340b665256e1', 'decc4b6118addbb54d49b4ee', 'cdd93c0461e3923a22aa155f', '3e1d007895353da9f631ad02', '73a58a83894d2589594daf4a', '13467297765b0e75201a52e3', 'b6556ac9fb3dd561d02e99a5', '45b7526b9941e4579af43e6c', '2cbebf97accbbf3a5041776c', 'a3bc01d2aacfcab611fc1c53', 'b755ff2035aac255f467595c', '96055c134a9e795b09937032', '0d8f8539a8e82f5daa90562f', '8cdcafd00523784d37d8dad5', '08eeb31e70fedda9acf60d5d', 'ca0b792691b7ae80aefbc093', 'c6b942401a65b3fa2db93ef0', 'f35e3b8882888f20f738170e', '2a09cc17e6b8947dbc425e98', '408a90b2c2390990c83c0be0', '3968a40f9da4c7f52e8f7dea', 'd7c14bbe3a56d6a3b48cc26d', 'be691057d7c16aac7ebabc58', '753481148eded16306edf567', 'b81ed5d5887f1e702281cc7c', 'e40b14c3c51819949e2f549e', 'ccb20fe5f0ec69b335b58f1c', '1688c6b7696b2a979945cb6c', '98eb6c243d1dff5092eb4c38', '7824e920bc0ac651cb49b706', '5da9ae74c519002875122c59', '26e74aadac80448d7df8bab6', '3ab5f4f4e306a69472e20429', '1c0fc6d294954a3775cc36df', 'b0e33df4abb89b92c708cf89', '451dfc06ff9455d76225f86b', '486be4b5d2429d76a159f7bb', 'f67d746e41ace34ddad71fba', 'b99ca86c27c7418b8cadc2bb', '6c0d7988692dd2731863ec96', '56a8d8e09edb2cee2e4d93a3', '60d0f145200cc583dc1c9dbb', '41539321bbcb2564370db4b1', '9c4faa51bc29012ddcee7e11', '5c872eafe61305c165ef7490', '11bb6b4e96dfc29737cec768', 'bb8a1fa7460a1e93f7fe94cd', '4cc7f474aee41be6f9a8dc37', '3afcd24ffddc745b26111a19', 'e45d3d0893b986609bb61212', '2c4e0725c06cb24d740f8090', 'e443e032271f916c3381b735', 'd9e6af32ff852ac88dc76577', 'd8cceb3ec5f0418b29f0a459', '5af27d478c355763b0000b8b', '029b91056c419bf0d15c3c15', 'cb7b80bbdfdc960e82ea8bf3', 'f8961f88221514dc6b646933', '3917dc2e272fabe6467257d2', '8f3012a3f38700d9fef0fbad', '6897e02993c3a8b24377556b', '21fe976dd2fd2be6db9c01b6', 'c8620b45b18ebc1c914a2581', 'f60d7cbfd76dabfff55dc3fa', '88eb5064597a8bdbd091db48', '0f16647da206cfafc77bdb03', 'd110cb39c939189ff2381a4e', '903fa8b66fbddfcd2c54d16c', '0ba53e15e28cc6c41c12f29b', '4c853a58d04f9b3b5fb7cf1c', '177361783d0e88008a827338', 'ded63a32010e347a3a99d26d', '1e114a0ca464f5bf590ace7d', 'f3e47e3f679e8381a5c4a2b6', '7b572da72e10a69e40094361', 'efc40de8a506d0e04de52dd0', '79435a6fda1d423ee215c027', '47ed4895c2459c6df72bbc21', '95a56ae5ea17a6e60f36afb6', '73bfff1ea31aa4d903100d70', '29a1dcd96e7a8c556183b81f', '55a91f4eaa637abafc6b75b7', '085c8ca9cb97ef04b07e9465', 'adfd9a5399c408d1e11a4aa2', 'f1d835a5bb021603f18ae280', 'fa3f52c79b018b43a9e8090a', 'b6cca58570a4d4174cb71b3e', 'd9d32742eb8e9436fd593092', 'cc5fbcfde89a0973970e7397', 'c79aa16d36ce764a13078e7b', '762190765b6e9b306ee94b34', 'fbbd2e1b86a772b593ee1bb9', '3f24154f91b27bdc47594852', '9b97c77977d5e0060179aa15', 'db037fde5163630eb1dacbe1', '76c552ca9be899eab747b7a3', 'c152c5dd0a1f2626db79696c', '1c513ac8c299151372834f1a', 'ca03ac7bbb7eccf0152f825a', '3ae2168575144fa7bff0773b', '1e888452b37ac8ca86b6980c', '24ebd2bae7cfabd18b6ce9c8', '21dbea03500cf77a64577287', 'bbaf6db3927ca6221096a678', '995e071fb1a801ad2552a7c2', 'b0fa39290a379ac3962d1215', '2ca1d1be2d4d07ebcd6b3235', '6dd0dd2307f507f9c42eea63', '1f9b6689da5fdcc23879a5ac', '9d188dcdbafa3802c326bff0', 'a6dfce8ef3e5a14b57bd2d11', 'bbfa77367f4475e333c7a834', '7183861df46553ab538458ae', '137099cf125111be9c3e94c3', '88f1c32259e7e65db186fc61', 'c8b35c10890db1d889786310', '412c53a53a3b1c06f1f68772', '38cab6c7f7f7fe731b55ebde', 'e50c094ffc2b4008e3005839', '69c7281826029c1b41a34049', '64633965444f470a4ca586e8', '676f00b844b8685a14e6582b', '58820822f031297565e686b7', 'c868b0184dd86f732c24d8f6', '582b1e6739323885d6dd7148', 'a566581cd7454020e0914ed3', '8a498aa27f9b433e78ba0a00', 'a8ce51c1370a7fb07b65da1c', '1b5f2850fe93f1eb4438b9dd', '23016e3fbba29157468b85f0', 'ad25eb02b71d4d267ce0abfc', 'f2147dbedaab703750fcd937', 'edf02ff65e3bddb4db278a87', 'db075c3a76dad8cee21d6089', '054b6f8bf46fb8b641b71498', '6ef2fe833cee5960612ae052', 'ee04b4b7af645ba90c2bd384', '0b6c432395ef9fcbfe105e93', '5e25f7703857496eb27b9a2a', '40adf249c767a37afb9398c6', '7b58a0880a46238d4e9722c0', '9dfc1f05e2a00f866e5a96b6', '0c1c6ad6a0a679043de5adc2', '7ea687da89af68315ce96f56', '34bcde5942f36df939445209', '4a6a55a4bf98ebabca394606', '549e20a8edaac5f7b05ecb41', '6daf43327893e27cc1c785bb', 'e4b74a53ea1be8cc09b170cb', 'b6cdfe2edf6838e152af3c54', 'bbb5e4ef8fa79866856181d3', 'c47c4a63334997fb668032de', '9bcc50dfeada714797755ff0', 'd01b05000d59848ec7db20fc', 'f4222a52ce7d21c3c9d3c000', '4278528d67400edefc633789', '7bd54b9aeab884f12aad013d', 'd531eb280735fb30a757905a', '00979fbe4ba004cc20246b9a', '9eaee8b12a9d726c44201f25', '279b2975d141762b456cd18d', 'a1d2ad87eb4e531d5e0486d3', '36fa0c204674ed02e032e699', '11c93be39a2819fec36e2a6b', '5132adcd87a30d937fa216b4', '3f355b4c88735775a5eeacb2', '14dc70100f62f8b317f16a1c', 'a3c1f40e880ba9d30165da29', 'ea99947eb86635891276c5de', '55a82d52a8bcc98c682b8a78', 'bb21fc57075b8a90bdec2466', 'ee73ce9db61eca17bccfc7ee', '5661fb129ea343e46075bab5', '82eed12efc2bbbf2dd01b1c2', 'dd41fa87a9bb005a4d9cfe78', '21a13676c67585e41b8f6a67', 'a0cdae836281b14960231c43', 'f14d881d1381c847c13301a6', '6f9909683d56ed89f9e559bc', 'ec4b556e4ac98f7c6485240b', 'c85dcc855c873d1ffc99f027', '54ce172ad4dee0a2a6d24cd0', '06445e2823bf14c47a058abe', '11608a4c97632da4a6c7043d', 'f482fa51f88bdcc934bc4754', 'e054b776ce8b992288d3a151', 'e8162ad0bfd3adb9a2c2f908', '10ed8799a239ae7d1d0f79c9', 'c919552da540025ef269dfef', '5401b6a61d136580b9f69be2', '3831c2c777259f2c220dcceb', 'fc1d2f78dd540b2cf1aed9b9', '9605044db0cc93ca8e59d0be', 'bde07b33be302a136b2699b4', '76b2409a30b5bbbeab3d334b', '63963fa9f83cbade78c334a0', 'ae2b2591d8e2e64d87cd4240', '9e1a47f578512d0f3910fa36', '8e4ed37b59452ca69b3481b2', '129e758237d6a21a110b1f7c', 'c673226d59266c9f24c1559d', 'decffce701731474c7a1532f', '770ad5d0ecd285dc97b984b2', '0688645b190580e5eaf4bad5', 'e2c201a20662ad1fab6cc5ef', '662b2f7dbfe34ec1b9a8e485', '6ef2183a66a1c25b6446eee9', 'cdba77ccb92d5b91ada3a6dc', '2701dd64f96330440b0d5b10', '6b5916a645e1dcf8aaef7a8d', 'd8ee53098c33deb8fdb3b50b', '42b32b8c9018073085ea61c5', '1f6fb1acb94a920e308918de', 'ac175862df937e28b15bb023', '9235d1bea2de86e8bfe34a29', '42338b681fd350441ca9efc0', '1d22e6440ebc8254221ff9ab', '4244cfa368679a0ccc3f5672', '6c72b9c6d194e26c1ee7f466', '8b05dac24440c0e125c2982d', '03b89b45a7325ecb997b183f', '6e3ef13b7c663dcb6c9945ec', 'dac65a4d9eca6e3f5529ae4b', 'e8fdd9acc2da7140baf49188', '9c48cfc44e14602d0728ed28', 'b3b289b80bbadf3f9be2ebc4', 'f6a020353c429522bafc3321', '7acfb197a239ef58e7f08525', '0b9e4acffe9d8f86bd9be2bf', 'd091004cb9fc04cd233d1142', '821e3fe48e8557a30caa67cf', 'a301cbb555555b4a30c9dfbe', 'b280ebdb1c738becbca7cc1d', 'a6e53a5c90ec55b54a024a95', 'df4e908303402aa200726682', 'a6c506df1317e23580129055', 'b587cd8c1c145a6a99b52e8e', '17a79ba0e1aeb153b34e461a', 'db0532f93811b5c3527eb224', '42fee8cbef2d81610c0f6a7b', '8fb8495a86fc33185eb96c55', 'fc3894dd76e5cc3a753eedfb', 'd668c80dc28d9c4f1a984524', 'ad15992e182e0964c4084195', 'f9f4d6def655d54dcbd63348', '7cf79d6d78b98237ceed2c66', '304190e81318d73ef0c5f885', '8b39463fdf4a8b3980e64af0', 'a410edd0be9764d12a841458', '67a50aa49b80a0cadb830e34', '77020ee533db2c04412900f0', '9e339e1a8f7393ed2f0a342e', '5442daaf8455ec924ced4a84', 'a512e2c581e537c6e95d2626', 'b4ebdda80c6329d3a8363c7e', 'b6b8fff2d091a4950a8656fc', '38e2f42ebf3b484fd618abc2', '9838b1b25dbb387afc8f07aa', '3ee6a4091b6e165e3eab53d4', '02b3b650c8a76d49c5223798', '5d0429ce6caa78a35b8b997e', 'da71745a0892dc4e3347b091', 'd72f15251b85ed2e1b191e0f', 'ae863d8431919bbfb1dca0db', '214a7cc494b5ad3fd78e9765', '42495442e7c6484bb48ed957', 'abe89412efcd41bf266d253a', '01898f9cb797a1bb35415331', '045bf7ee10229a2cde7504e7', '45e96cdfdd32151dd3592509', '371d12824fa1ffd7ef5e90e7', '3b684d2b82753b3d95f1dbc9', '4280ebde89a88a7f5565d9dd', '906878394c7c53d1c7d622c0', '0de02f3946d72e99a86d60ea', '6b42551afc7b875d354f4b01', 'b91fff10d613c5660031b070', 'dcfb3bfb9c133a83a862251a', 'c9b9077631942180f3a3b0ed', 'f4526c3446deb95d067dc788', 'e3e406fe664e626c9595b4ec', '4b5563f6063f368aaf4d032b', '650faa5ad60fd0f4f2dee70a', '6fbc822299d5ed6324fb6280', '819106b66507d6daacc3feba', 'a1a5f421d9b782f7e987091a', 'ab4e7468a6d2dfc3bdbc9ff6', '070f868f0ab84f4ec3f3982b', 'cff67763de893e7028b45382', '177414b028ffe63adf88e436', '96487dd035f8b985f4b01677', '314415a08a9c1d6bd28fe89e', '358fa6004175aca2698df8bb', '9446bf724e050f51ed6448e1', '6c4b2c8d659fcb229d747557', 'd53c2b6d7e4bf45b77a8dd12', '6fa5f1bd8164edcb10243287', 'cd7621aeaf5bf1a22ca8394e', '2a3d19cceb7e76962f6d84e6', '34b93ea1246f25eeebd0e8c9', 'c6ff88c99785463abe05ab14', 'bcaec1a9a3a9b59caef1e49a', '781a848c0f1a072d4667722d', '7f1d3e5201103ad28842a180', 'eae3d736ea15573510314df8', 'bb9f9e41ece52e577d67ea85', '3189eb16865c13742abd3f7a', '826d5f58864744f66f50a9f1', '613174eb83b532fe4e38b7fc', '0e206bae559f3646f2535376', 'b56a5ca8c263bc1137aded80', '411e30b09a68ac73906064aa', '28fb3dd077aebb1daf3e9fe4', 'cbb2aecba43342d92debc795', '16efb111485f01232222a8c4', '58be20bc10780428cb236a2e', '6992e079d5cc2aa7a2bb6cbe', '80343317e0783f2a96a603d5', '44b3905875474271bf26457e', 'b6199c44eb942b29559195b3', 'dd91706df84d8357cdef457f', 'aeb553a68c282c81e16d7c44', '956020fbb55b1050204ceebd', '133bfd224364a0a162d9e323', '5497d84d98c1646706086e2e', '0142fefc91ec6884f43de80b', '21e6de874970fa7ae9510d18', '933c11a9ca710be4b2120713', '7a2a83f4a894b5b5f2076da6', '778dec17c4569dd7f4da476a', 'def40a677b6ecbf4f1bd3de2', 'fb62db48ad7712c787e1d173', 'e8be8d8ac70685f324507cdc', '859635e6c88f004f9e9f32da', '001613e40181055fecd8dc18', 'ee03c89cedfa0f30f24da326', 'bfc0ef948f41f613e7769bc1', 'cb605fd1d340ab1ad0afe330', '425004d751172cad53c3ad6b', 'd11f27c0322c15dc8f10c8b2', '645da0fe1582ef9cccf3adb7', '83e367047d0aa921f3cb6d91', '4b381a5f887c98f632753d0c', '94565cd9b8a667a9b65034a4', '9401e788946c189532687a96', 'a1c948ed4a09091c1d92be84', '368476b74ef69f3552e2cb3d', '44ff2488f2d3d5682b6994b8', '970112eab9858a27e20a091f', 'd2d60e3fb7175ae8e24658d9', '44fdec17266371ad7f7871d7', 'dc99421b0fa75072b7fc597f', '34586824e9cd0af359187e34', 'ce91ec91b6aaa48439b33e96', 'fccae88f01f7fd8906029a4f', 'c06489b1989596c5c396021d', '5a4f493fdb61cf9a1f898407', '981338dedcce7e27679a41c7', '21e50a8f4be7dfdd1d9fb392', '53cdff279789d1183c4e5a86', 'f0220d6aa14301805fc7e420', 'acef00fb099d89d41958c435', '7c03a7d1027f6d34619316ee', 'cc6cddf1a72c4c14b010fdf1', '8cdc13df0df6b0ba2bfeed8c', 'ad181c030f922bb1d3793964', '0d5c93359124d85b4946ec95', '71d04374ffadf723feb6a4f5', '58c7b81fff91803d70fcd674', '3df956fea1348d1046fdd09d', 'cd733e64db1b7801954ac9ac', 'd34f3b955bd78b3126293e64', '1b4e7ac4a337c583b0d77b04', 'c4342f86b05d451aef82a90f', 'e6251eca229881bceb8a97c7', 'ef1717a5f8cb73c78748607d', 'a39b48bf94054784fed63d35', 'e51c2dd489fa0ebf1c2b7700', '92b7fb1f0888976bb221ed1d', 'b081cbc08146d7b9ab265566', '60fa5859e5561740ec7d024d', 'be52dc50e6aaa98ddf135fe9', '0e79ae45b54260645fa447df', '9e4d892692bac7261d1c86af', 'f617b7296ab248a05c6041c0', '5a930b48e4949a1ed44fe056', 'e11c8d2b04cdfacf76cca4dd', 'eb546f4e23ee7c0f0ace4e68', '36f1d4c5bd1c63cf74545e1f', '6fb7db09905b3e0b6571bb41', '0dd4139bd1f8141dabb5746b', '5fa52b07870c541ddad80fd4', 'd4667791b23ee3c61987de79', '3a60895a1bcc132fc939a54a', '23a4576cc256bed45465d6f4', 'bbe2b568ffdaf7c89fb508ab', '256fd3ca11317b9a7e82835b', '8ad38d6021157f461e8be73d', 'd9ff976abef3224333ca77ba', '99282beda9432fdc84953229', '3a2f38d0445a8f3784327832', 'f5ddb5194586e227ab8610fc', '785d76bc0b177869d3d36d87', '9ac29fcc00066ee270a82758', '3c0cb65bd0831752922d8073', '6ea26188016a8e0dcae6f2ca', '90b567e91dc4ca2e45144a58', '67cfd4b9ba04c04a487ec39f', 'e52d7f0f71c5a96d3ad444d8', '09defcd24314b8496fb3d74c', '37919d0f8db2140219307c6f', '22f6471acc2d184e7cfeeb6f', '48a6844f3ba6022354e2d189', '6b81072250740cd9e14626a0', '3c678de40d16a9eae2e6f6dd', 'f081cc4e63e6199eb7122b0c', '59217d3eca4038fcc33993f0', 'aac6ebb3d651674fd6c07123', '3611ae2dcaeae9a7d87cdf93', 'af69042027761577e56622e9', 'c905e6677e0cbf329230ebf2', '290b08ec95402e357dd162b0', '367b2116257001fe013bc048', '1f400039f5811e19f5da4593', 'df2943ec147894b6e5bfbe4f', '366c5196b25e3189805acc33', '5b0182b6de80a169f35424ab', '35845dbc8e2d2791d609cc18', 'cc37854387e108740577c491', '3753ef6947f42f1a4e5a6a63', '44976b84ff1c95d71e982f32', 'c749d56aa8cacdcfa66338ba', '634b0f8deeebe3bcb1a50a09', '7bd0fb1be2b05eacb63558d9', '8f6f18c72c81b1627f391252', '4e9aac252394c9a79ea2005d', 'cb26c31984006b29f2c93878', '17c962c6c3323c0e76fe972c', 'a54cc5aec8ac14dc7dd2bdbe', '5e947ca43ffbad49cde64c05', 'c1d67292940ffad4ade361e9', 'a5de915902ae68f1b9298fce', '1a33ef0177e3bdc49dafbced', 'f2298b0bf7b7aa99bc543176', 'ea3b6816231eff47e5f4ff99', 'd4838da30561bc40110b929d', 'af07d2b195d6add6909c4f64', '38b7e8d3f95badf4596cd29a', '1938082694abfabf0da88e32', 'a40c239f553ad63c5c40cc4c', '72ad619b7c1288429ab0e7e8', 'a978c41bf772b0328ae1c73e', '9c5b3244cf12068e0fc12891', '17f65319b8a03eaeeb2840a5', 'bf885e40699431f501098369', '1dbe09373cc9df99e58c1b27', 'ebde9f1b9d393f71e485fb70', '9556f5bb39ef85f316ec69f4'])\n",
            "SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'ampicillin sodium'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "For the **development phase** (until the release of the test data on Monday, February 26, 2024), we will use the validation data as our evaluation dataset. Therefore, we need to reorganize our data as follows:\n",
        "- Original Validation Data as Test Set: The existing validation data will now serve as our test set. This set will be used for final evaluations.\n",
        "- Split Original Training Data: We will split the original training data into new training and validation sets. This allows us to develop and tune our model effectively during the development phase.\n",
        "\n",
        "For the **final testing phase**, starting from the test data release on February 26, 2024, participants should use the original test dataset for final evaluations and submissions.\n"
      ],
      "metadata": {
        "id": "AWwpdNehvizS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define stratification criteria for consistent distribution between answerable and unanswerable questions\n",
        "stratify = ['unans' if train_label[id_]=='null' else 'ans' for id_ in list(train_label.keys())]\n",
        "\n",
        "# Split the original training data into new training and validation sets, while maintaining the distribution\n",
        "new_train_keys, new_valid_keys = train_test_split(\n",
        "    list(train_label.keys()),\n",
        "    train_size=0.8,\n",
        "    random_state=42,\n",
        "    stratify=stratify\n",
        ")\n",
        "\n",
        "# Initialize containers for the new training and validation sets\n",
        "new_train_data = []\n",
        "new_train_label = {}\n",
        "new_valid_data = []\n",
        "new_valid_label = {}\n",
        "\n",
        "# Sort each sample into the new training or validation set as determined by the split\n",
        "for sample in train_data['data']:\n",
        "    if sample['id'] in new_train_keys:\n",
        "        new_train_data.append(sample)\n",
        "        new_train_label[sample['id']] = train_label[sample['id']]\n",
        "    elif sample['id'] in new_valid_keys:\n",
        "        new_valid_data.append(sample)\n",
        "        new_valid_label[sample['id']] = train_label[sample['id']]\n",
        "    else:\n",
        "        # If a sample is neither in the train nor valid keys, raise an error\n",
        "        raise ValueError(f\"Error: Sample with ID {sample['id']} has an invalid split.\")\n",
        "\n",
        "# Structure the new datasets in a JSON-compatible format\n",
        "new_train_data = {'version': f'{DB_ID}_sample', 'data': new_train_data}\n",
        "new_valid_data = {'version': f'{DB_ID}_sample', 'data': new_valid_data}\n",
        "\n",
        "# Display the size of the new training and validation sets for verification\n",
        "print(f\"New Train data: {len(new_train_data['data'])} entries, New Train labels: {len(new_train_label)} entries, Unanswerable: {sum(value == 'null' for value in new_train_label.values())}\")\n",
        "print(f\"New Valid data: {len(new_valid_data['data'])} entries, New Valid labels: {len(new_valid_label)} entries, Unanswerable: {sum(value == 'null' for value in new_valid_label.values())}\")"
      ],
      "metadata": {
        "id": "eyFPYiShUvaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16048843-93a2-4328-9268-5699727d7f1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Train data: 4099 entries, New Train labels: 4099 entries, Unanswerable: 360\n",
            "New Valid data: 1025 entries, New Valid labels: 1025 entries, Unanswerable: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set directory for the new splitted data\n",
        "NEW_TRAIN_DIR = os.path.join(BASE_DATA_DIR, '__train')\n",
        "NEW_VALID_DIR = os.path.join(BASE_DATA_DIR, '__valid')\n",
        "NEW_TEST_DIR = os.path.join(BASE_DATA_DIR, 'valid')\n",
        "\n",
        "# Save the new datasets to JSON files for later use\n",
        "write_data(os.path.join(NEW_TRAIN_DIR, \"data.json\"), new_train_data)\n",
        "write_data(os.path.join(NEW_TRAIN_DIR, \"label.json\"), new_train_label)\n",
        "write_data(os.path.join(NEW_VALID_DIR, \"data.json\"), new_valid_data)\n",
        "write_data(os.path.join(NEW_VALID_DIR, \"label.json\"), new_valid_label)"
      ],
      "metadata": {
        "id": "whYT7kNoU6hV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the `Dataset` Class\n",
        "\n",
        "The next step is to create a `Dataset` class that will be used by PyTorch to feed data to our model. This class handles the tokenization of our questions and SQL labels, and prepares the data in a format that our T5 model can consume."
      ],
      "metadata": {
        "id": "Xl1s7RQ9v7gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def encode_file(tokenizer, text, max_length, truncation=True, padding=True, return_tensors=\"pt\"):\n",
        "    \"\"\"\n",
        "    Tokenizes the text and returns tensors.\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        max_length=max_length,\n",
        "        truncation=truncation,\n",
        "        padding=padding,\n",
        "        return_tensors=return_tensors,\n",
        "    )\n",
        "\n",
        "\n",
        "class T5Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset class for the T5 model, handling the conversion of natural language questions to SQL queries.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        data_dir,\n",
        "        is_test=False,\n",
        "        max_source_length=256, # natural langauge question\n",
        "        max_target_length=512, # SQL\n",
        "        db_id='mimiciii', # NOTE: `mimic_iv` will be used for codabench\n",
        "        tables_file=None,\n",
        "        exclude_unans=False, # exclude unanswerable questions b/c they have no valid sql.\n",
        "        random_seed=0,\n",
        "        append_schema_info=False,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.db_id = db_id\n",
        "        self.is_test = is_test # this option does not include target label\n",
        "        self.random = random.Random(random_seed) # initialized for schema shuffling\n",
        "        self.max_source_length = max_source_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "        # Load data from JSON files\n",
        "        with open(f'{data_dir}/data.json') as json_file:\n",
        "            data = json.load(json_file)[\"data\"]\n",
        "\n",
        "        label = {}\n",
        "        if not self.is_test:\n",
        "            with open(f'{data_dir}/label.json') as json_file:\n",
        "                label = json.load(json_file)\n",
        "\n",
        "        self.db_json = None\n",
        "        if tables_file:\n",
        "            with open(tables_file) as f:\n",
        "                self.db_json = json.load(f)\n",
        "\n",
        "        # Process and encode the samples from the loaded data\n",
        "        ids = []\n",
        "        questions = []\n",
        "        labels = []\n",
        "        for sample in data:\n",
        "\n",
        "            # id\n",
        "            if exclude_unans:\n",
        "                if sample[\"id\"] in label and label[sample[\"id\"]] == \"null\":\n",
        "                    continue\n",
        "            ids.append(sample['id'])\n",
        "\n",
        "            # question\n",
        "            question = self.preprocess_sample(sample, append_schema_info)\n",
        "            questions.append(question)\n",
        "\n",
        "            # label\n",
        "            if not self.is_test:\n",
        "                labels.append(label[sample[\"id\"]])\n",
        "\n",
        "        self.ids = ids\n",
        "        question_encoded = encode_file(tokenizer, questions, max_length=self.max_source_length)\n",
        "        self.source_ids, self.source_mask = question_encoded['input_ids'], question_encoded['attention_mask']\n",
        "        if not self.is_test:\n",
        "            label_encoded = encode_file(tokenizer, labels, max_length=self.max_target_length)\n",
        "            self.target_ids = label_encoded['input_ids']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.is_test:\n",
        "            return {\n",
        "                \"id\": self.ids[index],\n",
        "                \"source_ids\": self.source_ids[index],\n",
        "                \"source_mask\": self.source_mask[index]\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"id\": self.ids[index],\n",
        "                \"source_ids\": self.source_ids[index],\n",
        "                \"source_mask\": self.source_mask[index],\n",
        "                \"target_ids\": self.target_ids[index]\n",
        "            }\n",
        "\n",
        "    def preprocess_sample(self, sample, append_schema_info=False):\n",
        "        \"\"\"\n",
        "        Processes a single data sample, adding schema description to the question.\n",
        "        \"\"\"\n",
        "        question = sample[\"question\"]\n",
        "\n",
        "        if append_schema_info:\n",
        "            if self.db_json:\n",
        "                tables_json = [db for db in self.db_json if db[\"db_id\"] == self.db_id][0]\n",
        "                schema_description = self.get_schema_description(tables_json)\n",
        "                question += f\" {schema_description}\"\n",
        "            return question\n",
        "        else:\n",
        "            return question\n",
        "\n",
        "    def get_schema_description(self, tables_json, shuffle_schema=False):\n",
        "        \"\"\"\n",
        "        Generates a textual description of the database schema.\n",
        "        \"\"\"\n",
        "        table_names = tables_json[\"table_names_original\"]\n",
        "        if shuffle_schema:\n",
        "            self.random.shuffle(table_names)\n",
        "\n",
        "        columns = [\n",
        "            (column_name[0], column_name[1].lower(), column_type.lower())\n",
        "            for column_name, column_type in zip(tables_json[\"column_names_original\"], tables_json[\"column_types\"])\n",
        "        ]\n",
        "\n",
        "        schema_description = [\"\"]\n",
        "        for table_index, table_name in enumerate(table_names):\n",
        "            table_columns = [column[1] for column in columns if column[0] == table_index]\n",
        "            if shuffle_schema:\n",
        "                self.random.shuffle(table_columns)\n",
        "            column_desc = \" , \".join(table_columns)\n",
        "            schema_description.append(f\"{table_name.lower()} : {column_desc}\")\n",
        "\n",
        "        return \" | \".join(schema_description)\n",
        "\n",
        "    def collate_fn(self, batch, return_tensors='pt', padding=True, truncation=True):\n",
        "        \"\"\"\n",
        "        Collate function for the DataLoader.\n",
        "        \"\"\"\n",
        "        ids = [x[\"id\"] for x in batch]\n",
        "        input_ids = torch.stack([x[\"source_ids\"] for x in batch]) # BS x SL\n",
        "        masks = torch.stack([x[\"source_mask\"] for x in batch]) # BS x SL\n",
        "        pad_token_id = self.tokenizer.pad_token_id\n",
        "        source_ids, source_mask = trim_batch(input_ids, pad_token_id, attention_mask=masks)\n",
        "\n",
        "        if self.is_test:\n",
        "            return {\n",
        "                \"source_ids\": source_ids,\n",
        "                \"source_mask\": source_mask,\n",
        "                \"id\": ids,\n",
        "            }\n",
        "        else:\n",
        "            target_ids = torch.stack([x[\"target_ids\"] for x in batch]) # BS x SL\n",
        "            target_ids = trim_batch(target_ids, pad_token_id)\n",
        "            return {\n",
        "                \"source_ids\": source_ids,\n",
        "                \"source_mask\": source_mask,\n",
        "                \"target_ids\": target_ids,\n",
        "                \"id\": ids,\n",
        "            }\n",
        "\n",
        "def trim_batch(input_ids, pad_token_id, attention_mask=None):\n",
        "    \"\"\"\n",
        "    Trims padding from batches of tokenized text.\n",
        "    \"\"\"\n",
        "    keep_column_mask = input_ids.ne(pad_token_id).any(dim=0)\n",
        "    if attention_mask is None:\n",
        "        return input_ids[:, keep_column_mask]\n",
        "    else:\n",
        "        return (input_ids[:, keep_column_mask], attention_mask[:, keep_column_mask])"
      ],
      "metadata": {
        "id": "daUPXnrHU-ls"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a simple guide on how to use the `T5Dataset` class:"
      ],
      "metadata": {
        "id": "6CoNpglEBh_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "train_dataset = T5Dataset(\n",
        "    tokenizer=tokenizer,\n",
        "    data_dir=NEW_TRAIN_DIR,\n",
        "    tables_file=TABLES_PATH,\n",
        "    db_id=DB_ID,  # NOTE: `mimic_iv` will be used for codabench\n",
        "    append_schema_info=False,\n",
        ")\n",
        "\n",
        "sample_idx = 1\n",
        "decoded_sample_src = tokenizer.decode(train_dataset[sample_idx]['source_ids'])\n",
        "decoded_sample_trg = tokenizer.decode(train_dataset[sample_idx]['target_ids'])\n",
        "print('\\n')\n",
        "print(f\"source ids: {decoded_sample_src}\")\n",
        "print(f\"target ids: {decoded_sample_trg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qioHnAwA8ax4",
        "outputId": "2a5e9b9d-5efc-4230-a097-11c75f51f77a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "source ids: How is olanzapine (disintegrating tablet) typically consumed?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "target ids: SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'olanzapine (disintegrating tablet)'</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Construct a Text-to-SQL Baseline Model\n",
        "\n",
        "In this step, we set up and train a T5 model to translate natural language queries into SQL statements. The process involves several key stages including argument parsing, model initialization, data preparation, and the actual training."
      ],
      "metadata": {
        "id": "9gTpu3aSU-yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "faTUkypoVA4C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_default_args(parser):\n",
        "    \"\"\"\n",
        "    Define and set default arguments for the script.\n",
        "    \"\"\"\n",
        "    parser.add_argument(\"--db_id\", type=str, default=\"mimiciii\", help=\"database name\")  # NOTE: `mimic_iv` will be used for codabench\n",
        "    parser.add_argument(\"--train_data_dir\", type=str, help=\"train data path\")\n",
        "    parser.add_argument(\"--valid_data_dir\", type=str, help=\"valid data path\")\n",
        "    parser.add_argument(\"--test_data_dir\", type=str, help=\"test data path\")\n",
        "    parser.add_argument(\"--tables_file\", type=str, help=\"table schema path\")\n",
        "\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"outputs\", help=\"output directory\")\n",
        "    parser.add_argument(\"--output_file\", type=str, default=\"prediction_raw.json\", help=\"output file name\")\n",
        "\n",
        "    # basic parameters\n",
        "    parser.add_argument(\"--exp_name\", type=str, default=None, help=\"name of the experiment\")\n",
        "    parser.add_argument(\"--model_name\", type=str, default=None)\n",
        "    parser.add_argument(\"--save_checkpoint_path\", type=str, default=None)\n",
        "    parser.add_argument(\"--load_checkpoint_path\", type=str, default=None)\n",
        "\n",
        "    # training parameters\n",
        "    parser.add_argument(\"--train_batch_size\", type=int, default=8)\n",
        "    parser.add_argument(\"--valid_batch_size\", type=int, default=4)\n",
        "    parser.add_argument(\"--test_batch_size\", type=int, default=4)\n",
        "    parser.add_argument(\"--max_source_length\", type=int, default=512)\n",
        "    parser.add_argument(\"--max_target_length\", type=int, default=512)\n",
        "    parser.add_argument(\"--train_epochs\", type=int, default=100)\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-4, help=\"learning rate\")\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=1)\n",
        "    parser.add_argument(\"--warmup_steps\", type=int, default=0)\n",
        "    parser.add_argument(\"--max_grad_norm\", type=str, default=1.0)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.1)\n",
        "    parser.add_argument(\"--adam_epsilon\", type=float, default=1e-8)\n",
        "\n",
        "    parser.add_argument(\"--report_every_step\", type=int, default=1000)\n",
        "    parser.add_argument(\"--eval_every_step\", type=int, default=-1000)\n",
        "    parser.add_argument(\"--save_every_epoch\", type=bool, default=False)\n",
        "    parser.add_argument(\"--bf16\", type=bool, default=False)\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "\n",
        "    # generation parameters\n",
        "    parser.add_argument(\"--num_beams\", type=int, default=1)\n",
        "    parser.add_argument(\"--num_samples\", type=int, default=1)\n",
        "    return parser\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    \"\"\"\n",
        "    Ensure reproducibility by setting the seed for random number generation.\n",
        "    \"\"\"\n",
        "    np.random.seed(args.seed)\n",
        "    random.seed(args.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.manual_seed(args.seed)\n",
        "        torch.cuda.manual_seed(args.seed)\n",
        "        torch.cuda.manual_seed_all(args.seed)  # if use multi-GPU\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def save_model(model, optimizer, scheduler, step, best_metric, args, name=\"last\"):\n",
        "    \"\"\"\n",
        "    Save model checkpoints during or after training.\n",
        "    \"\"\"\n",
        "    os.makedirs(args.save_model_path, exist_ok=True)\n",
        "\n",
        "    save_file_path = os.path.join(args.save_model_path, f\"checkpoint_{name}.pth.tar\")\n",
        "    state_dict = {\n",
        "        \"step\": step,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"scheduler_state_dict\": scheduler.state_dict() if scheduler is not None else None,\n",
        "        \"args\": args,\n",
        "        \"best_metric\": best_metric,\n",
        "    }\n",
        "    torch.save(state_dict, save_file_path)\n",
        "    print(f\"Model checkpoint '{name}' saved successfully to {save_file_path}.\")\n",
        "\n",
        "\n",
        "def load_model(model, load_model_path, args, reset_optim=False):\n",
        "    \"\"\"\n",
        "    Load a saved model checkpoint.\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(load_model_path, weights_only=False)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    prev_args = checkpoint[\"args\"]\n",
        "    args = update_args(new_args=args, prev_args=prev_args)\n",
        "\n",
        "    step = checkpoint[\"step\"]\n",
        "    best_metric = checkpoint[\"best_metric\"]\n",
        "    if not reset_optim:\n",
        "        optimizer, scheduler = set_optim(model, args)\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    else:\n",
        "        optimizer, scheduler = set_optim(args, model)\n",
        "\n",
        "    return model, optimizer, scheduler, args, step, best_metric\n",
        "\n",
        "\n",
        "def update_args(new_args, prev_args):\n",
        "    \"\"\"\n",
        "    Update training arguments with the values saved in the checkpoint.\n",
        "    \"\"\"\n",
        "    for arg in vars(prev_args):\n",
        "        if arg not in new_args:\n",
        "            setattr(new_args, arg, getattr(prev_args, arg))\n",
        "    return new_args\n",
        "\n",
        "\n",
        "def set_optim(model, args):\n",
        "    \"\"\"\n",
        "    Initialize the optimizer and learning rate scheduler for the model.\n",
        "    \"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay, eps=args.adam_epsilon)\n",
        "    t_total = (len(train_loader.dataset) // (args.train_batch_size * max(1, args.n_gpu))) * args.train_epochs // args.gradient_accumulation_steps\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
        "    return optimizer, scheduler\n",
        "\n",
        "\n",
        "def train(tokenizer, model, train_loader, optimizer, step=0, valid_loader=None, best_metric=-1, scheduler=None, args=None):\n",
        "    \"\"\"\n",
        "    Conduct the training process for a given model.\n",
        "    \"\"\"\n",
        "    train_loss_list = []\n",
        "    batch_idx = 0\n",
        "\n",
        "    if best_metric == -1:\n",
        "        best_metric = np.inf\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(1, args.train_epochs + 1):\n",
        "        model.train()  # Set the model to training mode\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # Extract and send batch data to the specified device\n",
        "            source_ids = batch[\"source_ids\"].to(args.device)\n",
        "            attention_mask = batch[\"source_mask\"].to(args.device)\n",
        "            labels = batch[\"target_ids\"].to(args.device)\n",
        "\n",
        "             # Making padded ids (pad=0) are set to -100, which means ignore for loss calculation\n",
        "            labels[labels[:,:]==tokenizer.pad_token_id] = -100\n",
        "            labels = labels.to(args.device)\n",
        "\n",
        "            # Forward pass and calculate loss\n",
        "            loss = model(input_ids=source_ids, attention_mask=attention_mask, labels=labels)[0]\n",
        "            # Normalize loss to account for gradient accumulation\n",
        "            loss = torch.mean(loss) / args.gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient accumulation logic\n",
        "            if batch_idx % args.gradient_accumulation_steps == 0:\n",
        "                # Clip gradients to avoid exploding gradient problem\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()  # Update model parameters\n",
        "                if scheduler:\n",
        "                    scheduler.step()  # Update learning rate\n",
        "                model.zero_grad()  # Reset gradients\n",
        "                step += 1\n",
        "\n",
        "            train_loss_list.append(loss.item())\n",
        "\n",
        "            # Get the current learning rate from scheduler or optimizer\n",
        "            lr = scheduler.get_last_lr()[0] if scheduler else optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "            # Log training progress\n",
        "            if batch_idx % (args.report_every_step * args.gradient_accumulation_steps) == 0:\n",
        "                log = f\"epoch: {epoch} (step: {step}) | \"\n",
        "                log += f\"train loss: {sum(train_loss_list)/len(train_loss_list):.6f} | \"\n",
        "                log += f\"lr: {lr:.6f}\"\n",
        "                print(log)\n",
        "                train_loss_list = []\n",
        "\n",
        "            # Validation step\n",
        "            if valid_loader and batch_idx % (args.eval_every_step * args.gradient_accumulation_steps) == 0:\n",
        "                model.eval()  # Set the model to evaluation mode\n",
        "                valid_loss_list = []\n",
        "                with torch.no_grad():\n",
        "                    for i, batch in enumerate(valid_loader):\n",
        "                        ids = batch[\"source_ids\"].to(args.device)\n",
        "                        mask = batch[\"source_mask\"].to(args.device)\n",
        "                        labels = batch[\"target_ids\"].to(args.device)\n",
        "\n",
        "                        labels[labels[:,:]==tokenizer.pad_token_id] = -100\n",
        "                        labels = labels.to(args.device)\n",
        "\n",
        "                        valid_loss = model(input_ids=ids, attention_mask=mask, labels=labels)[0]\n",
        "                        valid_loss_list.append(valid_loss.item())\n",
        "\n",
        "                    # Calculate average validation loss\n",
        "                    valid_loss = sum(valid_loss_list) / len(valid_loss_list)\n",
        "\n",
        "                    log = f\"epoch: {epoch} (step: {step})\"\n",
        "                    log += f\" | valid_loss: {valid_loss:.6f}\"\n",
        "                    print(log)\n",
        "\n",
        "                    if best_metric > valid_loss:\n",
        "                        best_metric = valid_loss\n",
        "                        save_model(model, optimizer, scheduler, step, best_metric, args, name=\"best\")\n",
        "\n",
        "                    model.train()  # Set the model back to training mode\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "            # Clear CUDA cache if it's a good time\n",
        "            if batch_idx % (args.eval_every_step * args.gradient_accumulation_steps) == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()  # Trigger Python garbage collection\n",
        "\n",
        "        # Save a checkpoint at the end of each epoch if specified in args\n",
        "        if args.save_every_epoch:\n",
        "            save_model(model, optimizer, scheduler, epoch, best_metric, args, name=f\"{epoch}\")\n",
        "\n",
        "\n",
        "def generate_sql(tokenizer, model, eval_loader, args):\n",
        "    # Set the model to evaluation mode. This turns off certain layers like dropout.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient calculations for efficiency, as they are not needed in evaluation.\n",
        "    with torch.no_grad():\n",
        "        out_eval = []\n",
        "\n",
        "        # Iterate over batches of data in the evaluation dataset.\n",
        "        for batch in tqdm(eval_loader):\n",
        "            # Extract relevant data from the batch.\n",
        "            ids = batch[\"id\"]\n",
        "            source_ids = batch[\"source_ids\"].to(args.device)\n",
        "            attention_mask = batch[\"source_mask\"].to(args.device)\n",
        "\n",
        "            # Generate predictions using the model.\n",
        "            generation_output = model.generate(\n",
        "                input_ids=source_ids,\n",
        "                max_length=args.max_target_length,\n",
        "                num_beams=args.num_beams,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "            )\n",
        "\n",
        "            # Move the generated sequences to the CPU if using CUDA.\n",
        "            preds = generation_output[\"sequences\"].cpu() if args.device == \"cuda\" else generation_output[\"sequences\"]\n",
        "\n",
        "            # Process logits and calculate probabilities and entropies.\n",
        "            logits = torch.stack(generation_output[\"scores\"], dim=1)[:: int(args.num_beams / args.num_samples)]\n",
        "            logits = logits.cpu() if args.device == \"cuda\" else logits\n",
        "            probs = torch.softmax(logits, dim=2).float()\n",
        "            log_probs = torch.log_softmax(logits, dim=2).float()\n",
        "            entropies = (torch.sum(probs * log_probs, axis=2) * (-1)).numpy()\n",
        "\n",
        "            # Determine if the current batch is for testing or training.\n",
        "            is_test = True\n",
        "            if \"target_ids\" in batch:\n",
        "                is_test = False\n",
        "                reals = batch[\"target_ids\"]\n",
        "\n",
        "            # Initialize lists to store predictions, probabilities, and entropies.\n",
        "            pred_list = []\n",
        "            entropy_list = []\n",
        "\n",
        "            # Process each prediction in the batch.\n",
        "            for idx in range(len(preds)):\n",
        "                pred = preds[idx]\n",
        "                pred_tensor = preds[idx][1:]\n",
        "                entropy_truncated = entropies[idx].tolist()\n",
        "\n",
        "                # Truncate the prediction at the end-of-sequence token, if present.\n",
        "                if tokenizer.eos_token_id in pred_tensor:\n",
        "                    pred_eos_idx = torch.nonzero(pred_tensor == tokenizer.eos_token_id)[0].item()\n",
        "                    entropy_truncated = entropy_truncated[: pred_eos_idx + 1]\n",
        "\n",
        "                pred_list.append(pred)\n",
        "                entropy_list.append(entropy_truncated)\n",
        "\n",
        "            # Construct the output results for each prediction.\n",
        "            for idx in range(len(preds)):\n",
        "                result = {\n",
        "                    \"id\": ids[idx],\n",
        "                    \"question\": tokenizer.decode(source_ids[idx], skip_special_tokens=True),\n",
        "                    \"pred\": tokenizer.decode(pred_list[idx], skip_special_tokens=True),\n",
        "                    \"entropy\": entropy_list[idx],\n",
        "                }\n",
        "\n",
        "                # Include the real target output if it's training data.\n",
        "                if not is_test:\n",
        "                    result[\"real\"] = tokenizer.decode(reals[idx], skip_special_tokens=True)\n",
        "\n",
        "                out_eval.append(result)\n",
        "\n",
        "            # Clear cache after processing each batch\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "        return out_eval"
      ],
      "metadata": {
        "id": "I5hnuI4RdIWm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Argument Parsing\n",
        "\n",
        "First, we define and parse the necessary command-line arguments. These arguments configure the model, specify the paths for training, validation, and test data, and set various training parameters."
      ],
      "metadata": {
        "id": "WML26Rfir-Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and parse command line arguments for model configuration\n",
        "ARGS_STR = f\"\"\"\n",
        "--exp_name=t5-baseline \\\n",
        "--model_name=t5-base \\\n",
        "--train_data_dir={NEW_TRAIN_DIR} \\\n",
        "--valid_data_dir={NEW_VALID_DIR} \\\n",
        "--test_data_dir={NEW_TEST_DIR} \\\n",
        "--tables_file={TABLES_PATH} \\\n",
        "--train_epochs=10 \\\n",
        "--train_batch_size=4 \\\n",
        "--gradient_accumulation_steps=1 \\\n",
        "--learning_rate=1e-3 \\\n",
        "--report_every_step=10 \\\n",
        "--eval_every_step=10 \\\n",
        "--bf16=1\n",
        "\"\"\"\n",
        "\n",
        "# Parse arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "parser = add_default_args(parser)\n",
        "args = parser.parse_args(ARGS_STR.split())\n",
        "\n",
        "# Configure CUDA settings\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(args)\n",
        "\n",
        "# Determine device for training and set model save path\n",
        "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "args.n_gpu = torch.cuda.device_count()\n",
        "args.save_model_path = os.path.join(args.output_dir, args.exp_name)"
      ],
      "metadata": {
        "id": "kRk22MrRdJjv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Initialization\n",
        "\n",
        "Here, we initialize the T5 model and tokenizer. The model is configured to the appropriate device, and the tokenizer is extended with special tokens specific to our SQL translation task."
      ],
      "metadata": {
        "id": "iiY9s0Lso1gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize T5 model and set device\n",
        "model = T5ForConditionalGeneration.from_pretrained(args.model_name)\n",
        "model = model.to(args.device)\n",
        "\n",
        "# Convert model to bfloat16 precision if required\n",
        "if args.bf16:\n",
        "    print(\"bfloat16 precision will be used\")\n",
        "    model = model.to(torch.bfloat16)\n",
        "\n",
        "# Initialize tokenizer with additional SQL tokens\n",
        "add_tokens = [\"<\", \"<=\", \"<>\"]\n",
        "tokenizer = T5Tokenizer.from_pretrained(args.model_name)\n",
        "tokenizer.add_tokens(add_tokens)\n",
        "\n",
        "# Resize model token embeddings\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnIrttBRqbsO",
        "outputId": "79fc4ef3-c0c8-420b-d49a-ee85d82344d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bfloat16 precision will be used\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32103, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n",
        "\n",
        "We prepare the datasets for training, validation, and testing. This involves loading the data from specified paths and processing it into a format compatible with the T5 model."
      ],
      "metadata": {
        "id": "JcbG4vwvp9GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for dataset preparation\n",
        "dataset_kwargs = dict(\n",
        "    db_id=args.db_id,\n",
        "    max_source_length=args.max_source_length,\n",
        "    max_target_length=args.max_target_length,\n",
        "    tables_file=args.tables_file,\n",
        ")\n",
        "\n",
        "# Initialize datasets for different phases\n",
        "train_dataset = T5Dataset(tokenizer, args.train_data_dir, is_test=False, exclude_unans=True, **dataset_kwargs)\n",
        "valid_dataset = T5Dataset(tokenizer, args.valid_data_dir, is_test=False, exclude_unans=False, **dataset_kwargs)\n",
        "test_dataset = T5Dataset(tokenizer, args.test_data_dir, is_test=True, exclude_unans=False, **dataset_kwargs)\n",
        "\n",
        "# Create DataLoader instances for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.train_batch_size, collate_fn=train_dataset.collate_fn, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=args.valid_batch_size, collate_fn=valid_dataset.collate_fn, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.test_batch_size, collate_fn=test_dataset.collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "Fq-ROWfmqfHD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer and Scheduler\n",
        "\n",
        "Setting up the optimizer and learning rate scheduler is crucial for controlling and optimizing the training process."
      ],
      "metadata": {
        "id": "nkoyZyvyqHAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load existing model or initialize optimizer and scheduler\n",
        "if args.load_checkpoint_path:\n",
        "    model, optimizer, scheduler, args, step, best_metric = load_model(model, args.load_checkpoint_path, args)\n",
        "else:\n",
        "    step, best_metric = 0, -1\n",
        "    optimizer, scheduler = set_optim(model, args)"
      ],
      "metadata": {
        "id": "fP3ZjkA0IUIn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "Finally, we train the model on the dataset. The training process involves learning to generate SQL queries from textual descriptions through iterative forward and backward passes, loss computation, and parameter updates."
      ],
      "metadata": {
        "id": "mjVT23wFqKmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the training process\n",
        "train(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    step=step,\n",
        "    best_metric=best_metric,\n",
        "    args=args,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hn3Wf4_dLGx",
        "outputId": "28216e13-029e-4559-d623-2fe01b899bd9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 (step: 1) | train loss: 13.437500 | lr: 0.001000\n",
            "epoch: 1 (step: 1) | valid_loss: 4.786539\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 11) | train loss: 3.004688 | lr: 0.000999\n",
            "epoch: 1 (step: 11) | valid_loss: 2.121398\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 21) | train loss: 1.575000 | lr: 0.000998\n",
            "epoch: 1 (step: 21) | valid_loss: 1.594746\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 31) | train loss: 1.060547 | lr: 0.000997\n",
            "epoch: 1 (step: 31) | valid_loss: 1.409940\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 41) | train loss: 0.858594 | lr: 0.000996\n",
            "epoch: 1 (step: 41) | valid_loss: 1.262920\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 51) | train loss: 0.742578 | lr: 0.000995\n",
            "epoch: 1 (step: 51) | valid_loss: 1.204086\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 61) | train loss: 0.530859 | lr: 0.000993\n",
            "epoch: 1 (step: 61) | valid_loss: 1.143739\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 71) | train loss: 0.532227 | lr: 0.000992\n",
            "epoch: 1 (step: 71) | valid_loss: 1.157521\n",
            "epoch: 1 (step: 81) | train loss: 0.487891 | lr: 0.000991\n",
            "epoch: 1 (step: 81) | valid_loss: 1.128502\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 91) | train loss: 0.387500 | lr: 0.000990\n",
            "epoch: 1 (step: 91) | valid_loss: 1.163652\n",
            "epoch: 1 (step: 101) | train loss: 0.367578 | lr: 0.000989\n",
            "epoch: 1 (step: 101) | valid_loss: 1.111334\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 111) | train loss: 0.447266 | lr: 0.000988\n",
            "epoch: 1 (step: 111) | valid_loss: 1.057893\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 121) | train loss: 0.360840 | lr: 0.000987\n",
            "epoch: 1 (step: 121) | valid_loss: 1.033536\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 131) | train loss: 0.347656 | lr: 0.000986\n",
            "epoch: 1 (step: 131) | valid_loss: 1.034438\n",
            "epoch: 1 (step: 141) | train loss: 0.375977 | lr: 0.000985\n",
            "epoch: 1 (step: 141) | valid_loss: 1.034994\n",
            "epoch: 1 (step: 151) | train loss: 0.281836 | lr: 0.000984\n",
            "epoch: 1 (step: 151) | valid_loss: 1.043726\n",
            "epoch: 1 (step: 161) | train loss: 0.275586 | lr: 0.000983\n",
            "epoch: 1 (step: 161) | valid_loss: 1.004186\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 171) | train loss: 0.216504 | lr: 0.000982\n",
            "epoch: 1 (step: 171) | valid_loss: 1.003690\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 181) | train loss: 0.238184 | lr: 0.000981\n",
            "epoch: 1 (step: 181) | valid_loss: 0.997280\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 191) | train loss: 0.208984 | lr: 0.000980\n",
            "epoch: 1 (step: 191) | valid_loss: 1.005592\n",
            "epoch: 1 (step: 201) | train loss: 0.202051 | lr: 0.000978\n",
            "epoch: 1 (step: 201) | valid_loss: 0.995219\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 211) | train loss: 0.194629 | lr: 0.000977\n",
            "epoch: 1 (step: 211) | valid_loss: 0.999793\n",
            "epoch: 1 (step: 221) | train loss: 0.244336 | lr: 0.000976\n",
            "epoch: 1 (step: 221) | valid_loss: 0.990141\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 231) | train loss: 0.163330 | lr: 0.000975\n",
            "epoch: 1 (step: 231) | valid_loss: 0.985821\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 241) | train loss: 0.192529 | lr: 0.000974\n",
            "epoch: 1 (step: 241) | valid_loss: 0.979676\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 251) | train loss: 0.146582 | lr: 0.000973\n",
            "epoch: 1 (step: 251) | valid_loss: 0.980827\n",
            "epoch: 1 (step: 261) | train loss: 0.173926 | lr: 0.000972\n",
            "epoch: 1 (step: 261) | valid_loss: 0.980046\n",
            "epoch: 1 (step: 271) | train loss: 0.171924 | lr: 0.000971\n",
            "epoch: 1 (step: 271) | valid_loss: 0.967364\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 281) | train loss: 0.118311 | lr: 0.000970\n",
            "epoch: 1 (step: 281) | valid_loss: 0.961210\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 291) | train loss: 0.169873 | lr: 0.000969\n",
            "epoch: 1 (step: 291) | valid_loss: 0.946627\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 301) | train loss: 0.142676 | lr: 0.000968\n",
            "epoch: 1 (step: 301) | valid_loss: 0.911283\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 311) | train loss: 0.121289 | lr: 0.000967\n",
            "epoch: 1 (step: 311) | valid_loss: 0.890794\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 321) | train loss: 0.126514 | lr: 0.000966\n",
            "epoch: 1 (step: 321) | valid_loss: 0.916903\n",
            "epoch: 1 (step: 331) | train loss: 0.154639 | lr: 0.000965\n",
            "epoch: 1 (step: 331) | valid_loss: 0.943748\n",
            "epoch: 1 (step: 341) | train loss: 0.124854 | lr: 0.000963\n",
            "epoch: 1 (step: 341) | valid_loss: 0.936691\n",
            "epoch: 1 (step: 351) | train loss: 0.151514 | lr: 0.000962\n",
            "epoch: 1 (step: 351) | valid_loss: 0.917051\n",
            "epoch: 1 (step: 361) | train loss: 0.115137 | lr: 0.000961\n",
            "epoch: 1 (step: 361) | valid_loss: 0.908220\n",
            "epoch: 1 (step: 371) | train loss: 0.115479 | lr: 0.000960\n",
            "epoch: 1 (step: 371) | valid_loss: 0.916517\n",
            "epoch: 1 (step: 381) | train loss: 0.093091 | lr: 0.000959\n",
            "epoch: 1 (step: 381) | valid_loss: 0.906888\n",
            "epoch: 1 (step: 391) | train loss: 0.098853 | lr: 0.000958\n",
            "epoch: 1 (step: 391) | valid_loss: 0.895684\n",
            "epoch: 1 (step: 401) | train loss: 0.108984 | lr: 0.000957\n",
            "epoch: 1 (step: 401) | valid_loss: 0.885239\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 411) | train loss: 0.102832 | lr: 0.000956\n",
            "epoch: 1 (step: 411) | valid_loss: 0.881845\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 421) | train loss: 0.102246 | lr: 0.000955\n",
            "epoch: 1 (step: 421) | valid_loss: 0.866531\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 431) | train loss: 0.095801 | lr: 0.000954\n",
            "epoch: 1 (step: 431) | valid_loss: 0.875787\n",
            "epoch: 1 (step: 441) | train loss: 0.107324 | lr: 0.000953\n",
            "epoch: 1 (step: 441) | valid_loss: 0.900489\n",
            "epoch: 1 (step: 451) | train loss: 0.092236 | lr: 0.000952\n",
            "epoch: 1 (step: 451) | valid_loss: 0.917432\n",
            "epoch: 1 (step: 461) | train loss: 0.107471 | lr: 0.000951\n",
            "epoch: 1 (step: 461) | valid_loss: 0.901768\n",
            "epoch: 1 (step: 471) | train loss: 0.089209 | lr: 0.000950\n",
            "epoch: 1 (step: 471) | valid_loss: 0.886056\n",
            "epoch: 1 (step: 481) | train loss: 0.077271 | lr: 0.000949\n",
            "epoch: 1 (step: 481) | valid_loss: 0.890821\n",
            "epoch: 1 (step: 491) | train loss: 0.093188 | lr: 0.000947\n",
            "epoch: 1 (step: 491) | valid_loss: 0.888357\n",
            "epoch: 1 (step: 501) | train loss: 0.095288 | lr: 0.000946\n",
            "epoch: 1 (step: 501) | valid_loss: 0.907823\n",
            "epoch: 1 (step: 511) | train loss: 0.078662 | lr: 0.000945\n",
            "epoch: 1 (step: 511) | valid_loss: 0.891479\n",
            "epoch: 1 (step: 521) | train loss: 0.092188 | lr: 0.000944\n",
            "epoch: 1 (step: 521) | valid_loss: 0.881724\n",
            "epoch: 1 (step: 531) | train loss: 0.074609 | lr: 0.000943\n",
            "epoch: 1 (step: 531) | valid_loss: 0.891395\n",
            "epoch: 1 (step: 541) | train loss: 0.076831 | lr: 0.000942\n",
            "epoch: 1 (step: 541) | valid_loss: 0.914378\n",
            "epoch: 1 (step: 551) | train loss: 0.082788 | lr: 0.000941\n",
            "epoch: 1 (step: 551) | valid_loss: 0.898359\n",
            "epoch: 1 (step: 561) | train loss: 0.078320 | lr: 0.000940\n",
            "epoch: 1 (step: 561) | valid_loss: 0.898564\n",
            "epoch: 1 (step: 571) | train loss: 0.066309 | lr: 0.000939\n",
            "epoch: 1 (step: 571) | valid_loss: 0.918876\n",
            "epoch: 1 (step: 581) | train loss: 0.076172 | lr: 0.000938\n",
            "epoch: 1 (step: 581) | valid_loss: 0.932306\n",
            "epoch: 1 (step: 591) | train loss: 0.063843 | lr: 0.000937\n",
            "epoch: 1 (step: 591) | valid_loss: 0.919433\n",
            "epoch: 1 (step: 601) | train loss: 0.055225 | lr: 0.000936\n",
            "epoch: 1 (step: 601) | valid_loss: 0.916229\n",
            "epoch: 1 (step: 611) | train loss: 0.070337 | lr: 0.000935\n",
            "epoch: 1 (step: 611) | valid_loss: 0.919716\n",
            "epoch: 1 (step: 621) | train loss: 0.065186 | lr: 0.000934\n",
            "epoch: 1 (step: 621) | valid_loss: 0.912822\n",
            "epoch: 1 (step: 631) | train loss: 0.065796 | lr: 0.000932\n",
            "epoch: 1 (step: 631) | valid_loss: 0.915153\n",
            "epoch: 1 (step: 641) | train loss: 0.063818 | lr: 0.000931\n",
            "epoch: 1 (step: 641) | valid_loss: 0.913971\n",
            "epoch: 1 (step: 651) | train loss: 0.063867 | lr: 0.000930\n",
            "epoch: 1 (step: 651) | valid_loss: 0.900372\n",
            "epoch: 1 (step: 661) | train loss: 0.068542 | lr: 0.000929\n",
            "epoch: 1 (step: 661) | valid_loss: 0.880035\n",
            "epoch: 1 (step: 671) | train loss: 0.071753 | lr: 0.000928\n",
            "epoch: 1 (step: 671) | valid_loss: 0.879116\n",
            "epoch: 1 (step: 681) | train loss: 0.066992 | lr: 0.000927\n",
            "epoch: 1 (step: 681) | valid_loss: 0.885241\n",
            "epoch: 1 (step: 691) | train loss: 0.061035 | lr: 0.000926\n",
            "epoch: 1 (step: 691) | valid_loss: 0.884983\n",
            "epoch: 1 (step: 701) | train loss: 0.046545 | lr: 0.000925\n",
            "epoch: 1 (step: 701) | valid_loss: 0.889855\n",
            "epoch: 1 (step: 711) | train loss: 0.068506 | lr: 0.000924\n",
            "epoch: 1 (step: 711) | valid_loss: 0.892762\n",
            "epoch: 1 (step: 721) | train loss: 0.047205 | lr: 0.000923\n",
            "epoch: 1 (step: 721) | valid_loss: 0.876846\n",
            "epoch: 1 (step: 731) | train loss: 0.047571 | lr: 0.000922\n",
            "epoch: 1 (step: 731) | valid_loss: 0.877830\n",
            "epoch: 1 (step: 741) | train loss: 0.056396 | lr: 0.000921\n",
            "epoch: 1 (step: 741) | valid_loss: 0.882812\n",
            "epoch: 1 (step: 751) | train loss: 0.047766 | lr: 0.000920\n",
            "epoch: 1 (step: 751) | valid_loss: 0.882478\n",
            "epoch: 1 (step: 761) | train loss: 0.045703 | lr: 0.000919\n",
            "epoch: 1 (step: 761) | valid_loss: 0.878214\n",
            "epoch: 1 (step: 771) | train loss: 0.056470 | lr: 0.000917\n",
            "epoch: 1 (step: 771) | valid_loss: 0.863303\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 781) | train loss: 0.047437 | lr: 0.000916\n",
            "epoch: 1 (step: 781) | valid_loss: 0.849045\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 791) | train loss: 0.050293 | lr: 0.000915\n",
            "epoch: 1 (step: 791) | valid_loss: 0.844053\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 1 (step: 801) | train loss: 0.046338 | lr: 0.000914\n",
            "epoch: 1 (step: 801) | valid_loss: 0.870839\n",
            "epoch: 1 (step: 811) | train loss: 0.041711 | lr: 0.000913\n",
            "epoch: 1 (step: 811) | valid_loss: 0.895357\n",
            "epoch: 1 (step: 821) | train loss: 0.052063 | lr: 0.000912\n",
            "epoch: 1 (step: 821) | valid_loss: 0.900944\n",
            "epoch: 1 (step: 831) | train loss: 0.033679 | lr: 0.000911\n",
            "epoch: 1 (step: 831) | valid_loss: 0.884698\n",
            "epoch: 1 (step: 841) | train loss: 0.041553 | lr: 0.000910\n",
            "epoch: 1 (step: 841) | valid_loss: 0.871337\n",
            "epoch: 1 (step: 851) | train loss: 0.045630 | lr: 0.000909\n",
            "epoch: 1 (step: 851) | valid_loss: 0.882396\n",
            "epoch: 1 (step: 861) | train loss: 0.041406 | lr: 0.000908\n",
            "epoch: 1 (step: 861) | valid_loss: 0.891248\n",
            "epoch: 1 (step: 871) | train loss: 0.037341 | lr: 0.000907\n",
            "epoch: 1 (step: 871) | valid_loss: 0.888039\n",
            "epoch: 1 (step: 881) | train loss: 0.056079 | lr: 0.000906\n",
            "epoch: 1 (step: 881) | valid_loss: 0.888386\n",
            "epoch: 1 (step: 891) | train loss: 0.045374 | lr: 0.000905\n",
            "epoch: 1 (step: 891) | valid_loss: 0.887545\n",
            "epoch: 1 (step: 901) | train loss: 0.045569 | lr: 0.000904\n",
            "epoch: 1 (step: 901) | valid_loss: 0.877923\n",
            "epoch: 1 (step: 911) | train loss: 0.040881 | lr: 0.000902\n",
            "epoch: 1 (step: 911) | valid_loss: 0.864184\n",
            "epoch: 1 (step: 921) | train loss: 0.043835 | lr: 0.000901\n",
            "epoch: 1 (step: 921) | valid_loss: 0.858145\n",
            "epoch: 1 (step: 931) | train loss: 0.042688 | lr: 0.000900\n",
            "epoch: 1 (step: 931) | valid_loss: 0.847755\n",
            "epoch: 2 (step: 941) | train loss: 0.052649 | lr: 0.000899\n",
            "epoch: 2 (step: 941) | valid_loss: 0.840608\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 2 (step: 951) | train loss: 0.037549 | lr: 0.000898\n",
            "epoch: 2 (step: 951) | valid_loss: 0.856250\n",
            "epoch: 2 (step: 961) | train loss: 0.038269 | lr: 0.000897\n",
            "epoch: 2 (step: 961) | valid_loss: 0.866498\n",
            "epoch: 2 (step: 971) | train loss: 0.033710 | lr: 0.000896\n",
            "epoch: 2 (step: 971) | valid_loss: 0.864700\n",
            "epoch: 2 (step: 981) | train loss: 0.027600 | lr: 0.000895\n",
            "epoch: 2 (step: 981) | valid_loss: 0.869303\n",
            "epoch: 2 (step: 991) | train loss: 0.037451 | lr: 0.000894\n",
            "epoch: 2 (step: 991) | valid_loss: 0.870779\n",
            "epoch: 2 (step: 1001) | train loss: 0.034558 | lr: 0.000893\n",
            "epoch: 2 (step: 1001) | valid_loss: 0.876949\n",
            "epoch: 2 (step: 1011) | train loss: 0.037268 | lr: 0.000892\n",
            "epoch: 2 (step: 1011) | valid_loss: 0.872040\n",
            "epoch: 2 (step: 1021) | train loss: 0.038013 | lr: 0.000891\n",
            "epoch: 2 (step: 1021) | valid_loss: 0.877798\n",
            "epoch: 2 (step: 1031) | train loss: 0.028088 | lr: 0.000890\n",
            "epoch: 2 (step: 1031) | valid_loss: 0.887558\n",
            "epoch: 2 (step: 1041) | train loss: 0.043176 | lr: 0.000889\n",
            "epoch: 2 (step: 1041) | valid_loss: 0.890662\n",
            "epoch: 2 (step: 1051) | train loss: 0.046924 | lr: 0.000887\n",
            "epoch: 2 (step: 1051) | valid_loss: 0.880101\n",
            "epoch: 2 (step: 1061) | train loss: 0.029825 | lr: 0.000886\n",
            "epoch: 2 (step: 1061) | valid_loss: 0.871875\n",
            "epoch: 2 (step: 1071) | train loss: 0.028864 | lr: 0.000885\n",
            "epoch: 2 (step: 1071) | valid_loss: 0.867396\n",
            "epoch: 2 (step: 1081) | train loss: 0.031909 | lr: 0.000884\n",
            "epoch: 2 (step: 1081) | valid_loss: 0.869821\n",
            "epoch: 2 (step: 1091) | train loss: 0.039490 | lr: 0.000883\n",
            "epoch: 2 (step: 1091) | valid_loss: 0.878238\n",
            "epoch: 2 (step: 1101) | train loss: 0.030591 | lr: 0.000882\n",
            "epoch: 2 (step: 1101) | valid_loss: 0.878540\n",
            "epoch: 2 (step: 1111) | train loss: 0.034735 | lr: 0.000881\n",
            "epoch: 2 (step: 1111) | valid_loss: 0.870426\n",
            "epoch: 2 (step: 1121) | train loss: 0.032507 | lr: 0.000880\n",
            "epoch: 2 (step: 1121) | valid_loss: 0.857944\n",
            "epoch: 2 (step: 1131) | train loss: 0.029950 | lr: 0.000879\n",
            "epoch: 2 (step: 1131) | valid_loss: 0.863086\n",
            "epoch: 2 (step: 1141) | train loss: 0.028009 | lr: 0.000878\n",
            "epoch: 2 (step: 1141) | valid_loss: 0.880722\n",
            "epoch: 2 (step: 1151) | train loss: 0.041284 | lr: 0.000877\n",
            "epoch: 2 (step: 1151) | valid_loss: 0.890637\n",
            "epoch: 2 (step: 1161) | train loss: 0.035486 | lr: 0.000876\n",
            "epoch: 2 (step: 1161) | valid_loss: 0.900951\n",
            "epoch: 2 (step: 1171) | train loss: 0.025208 | lr: 0.000875\n",
            "epoch: 2 (step: 1171) | valid_loss: 0.892895\n",
            "epoch: 2 (step: 1181) | train loss: 0.028296 | lr: 0.000874\n",
            "epoch: 2 (step: 1181) | valid_loss: 0.887938\n",
            "epoch: 2 (step: 1191) | train loss: 0.026331 | lr: 0.000872\n",
            "epoch: 2 (step: 1191) | valid_loss: 0.886372\n",
            "epoch: 2 (step: 1201) | train loss: 0.027783 | lr: 0.000871\n",
            "epoch: 2 (step: 1201) | valid_loss: 0.898917\n",
            "epoch: 2 (step: 1211) | train loss: 0.033807 | lr: 0.000870\n",
            "epoch: 2 (step: 1211) | valid_loss: 0.911655\n",
            "epoch: 2 (step: 1221) | train loss: 0.038452 | lr: 0.000869\n",
            "epoch: 2 (step: 1221) | valid_loss: 0.911879\n",
            "epoch: 2 (step: 1231) | train loss: 0.031409 | lr: 0.000868\n",
            "epoch: 2 (step: 1231) | valid_loss: 0.899772\n",
            "epoch: 2 (step: 1241) | train loss: 0.026340 | lr: 0.000867\n",
            "epoch: 2 (step: 1241) | valid_loss: 0.888938\n",
            "epoch: 2 (step: 1251) | train loss: 0.038147 | lr: 0.000866\n",
            "epoch: 2 (step: 1251) | valid_loss: 0.883052\n",
            "epoch: 2 (step: 1261) | train loss: 0.032971 | lr: 0.000865\n",
            "epoch: 2 (step: 1261) | valid_loss: 0.889568\n",
            "epoch: 2 (step: 1271) | train loss: 0.029114 | lr: 0.000864\n",
            "epoch: 2 (step: 1271) | valid_loss: 0.878768\n",
            "epoch: 2 (step: 1281) | train loss: 0.028424 | lr: 0.000863\n",
            "epoch: 2 (step: 1281) | valid_loss: 0.876073\n",
            "epoch: 2 (step: 1291) | train loss: 0.028143 | lr: 0.000862\n",
            "epoch: 2 (step: 1291) | valid_loss: 0.875170\n",
            "epoch: 2 (step: 1301) | train loss: 0.039978 | lr: 0.000861\n",
            "epoch: 2 (step: 1301) | valid_loss: 0.873402\n",
            "epoch: 2 (step: 1311) | train loss: 0.022754 | lr: 0.000860\n",
            "epoch: 2 (step: 1311) | valid_loss: 0.882867\n",
            "epoch: 2 (step: 1321) | train loss: 0.026416 | lr: 0.000859\n",
            "epoch: 2 (step: 1321) | valid_loss: 0.879770\n",
            "epoch: 2 (step: 1331) | train loss: 0.028094 | lr: 0.000857\n",
            "epoch: 2 (step: 1331) | valid_loss: 0.872478\n",
            "epoch: 2 (step: 1341) | train loss: 0.025977 | lr: 0.000856\n",
            "epoch: 2 (step: 1341) | valid_loss: 0.882906\n",
            "epoch: 2 (step: 1351) | train loss: 0.031152 | lr: 0.000855\n",
            "epoch: 2 (step: 1351) | valid_loss: 0.892195\n",
            "epoch: 2 (step: 1361) | train loss: 0.025214 | lr: 0.000854\n",
            "epoch: 2 (step: 1361) | valid_loss: 0.886445\n",
            "epoch: 2 (step: 1371) | train loss: 0.031384 | lr: 0.000853\n",
            "epoch: 2 (step: 1371) | valid_loss: 0.871661\n",
            "epoch: 2 (step: 1381) | train loss: 0.025299 | lr: 0.000852\n",
            "epoch: 2 (step: 1381) | valid_loss: 0.877638\n",
            "epoch: 2 (step: 1391) | train loss: 0.027911 | lr: 0.000851\n",
            "epoch: 2 (step: 1391) | valid_loss: 0.874600\n",
            "epoch: 2 (step: 1401) | train loss: 0.026984 | lr: 0.000850\n",
            "epoch: 2 (step: 1401) | valid_loss: 0.870949\n",
            "epoch: 2 (step: 1411) | train loss: 0.024908 | lr: 0.000849\n",
            "epoch: 2 (step: 1411) | valid_loss: 0.870666\n",
            "epoch: 2 (step: 1421) | train loss: 0.025050 | lr: 0.000848\n",
            "epoch: 2 (step: 1421) | valid_loss: 0.879000\n",
            "epoch: 2 (step: 1431) | train loss: 0.024695 | lr: 0.000847\n",
            "epoch: 2 (step: 1431) | valid_loss: 0.894407\n",
            "epoch: 2 (step: 1441) | train loss: 0.026308 | lr: 0.000846\n",
            "epoch: 2 (step: 1441) | valid_loss: 0.922288\n",
            "epoch: 2 (step: 1451) | train loss: 0.032758 | lr: 0.000845\n",
            "epoch: 2 (step: 1451) | valid_loss: 0.919932\n",
            "epoch: 2 (step: 1461) | train loss: 0.029636 | lr: 0.000844\n",
            "epoch: 2 (step: 1461) | valid_loss: 0.921433\n",
            "epoch: 2 (step: 1471) | train loss: 0.026425 | lr: 0.000843\n",
            "epoch: 2 (step: 1471) | valid_loss: 0.915293\n",
            "epoch: 2 (step: 1481) | train loss: 0.019772 | lr: 0.000841\n",
            "epoch: 2 (step: 1481) | valid_loss: 0.905648\n",
            "epoch: 2 (step: 1491) | train loss: 0.021152 | lr: 0.000840\n",
            "epoch: 2 (step: 1491) | valid_loss: 0.900388\n",
            "epoch: 2 (step: 1501) | train loss: 0.021619 | lr: 0.000839\n",
            "epoch: 2 (step: 1501) | valid_loss: 0.909011\n",
            "epoch: 2 (step: 1511) | train loss: 0.023157 | lr: 0.000838\n",
            "epoch: 2 (step: 1511) | valid_loss: 0.914742\n",
            "epoch: 2 (step: 1521) | train loss: 0.021265 | lr: 0.000837\n",
            "epoch: 2 (step: 1521) | valid_loss: 0.913208\n",
            "epoch: 2 (step: 1531) | train loss: 0.027557 | lr: 0.000836\n",
            "epoch: 2 (step: 1531) | valid_loss: 0.920778\n",
            "epoch: 2 (step: 1541) | train loss: 0.032861 | lr: 0.000835\n",
            "epoch: 2 (step: 1541) | valid_loss: 0.922905\n",
            "epoch: 2 (step: 1551) | train loss: 0.022552 | lr: 0.000834\n",
            "epoch: 2 (step: 1551) | valid_loss: 0.914514\n",
            "epoch: 2 (step: 1561) | train loss: 0.022891 | lr: 0.000833\n",
            "epoch: 2 (step: 1561) | valid_loss: 0.914257\n",
            "epoch: 2 (step: 1571) | train loss: 0.026471 | lr: 0.000832\n",
            "epoch: 2 (step: 1571) | valid_loss: 0.912906\n",
            "epoch: 2 (step: 1581) | train loss: 0.027338 | lr: 0.000831\n",
            "epoch: 2 (step: 1581) | valid_loss: 0.903229\n",
            "epoch: 2 (step: 1591) | train loss: 0.022723 | lr: 0.000830\n",
            "epoch: 2 (step: 1591) | valid_loss: 0.897765\n",
            "epoch: 2 (step: 1601) | train loss: 0.020853 | lr: 0.000829\n",
            "epoch: 2 (step: 1601) | valid_loss: 0.898356\n",
            "epoch: 2 (step: 1611) | train loss: 0.028558 | lr: 0.000828\n",
            "epoch: 2 (step: 1611) | valid_loss: 0.890326\n",
            "epoch: 2 (step: 1621) | train loss: 0.018878 | lr: 0.000826\n",
            "epoch: 2 (step: 1621) | valid_loss: 0.874601\n",
            "epoch: 2 (step: 1631) | train loss: 0.024573 | lr: 0.000825\n",
            "epoch: 2 (step: 1631) | valid_loss: 0.886213\n",
            "epoch: 2 (step: 1641) | train loss: 0.020599 | lr: 0.000824\n",
            "epoch: 2 (step: 1641) | valid_loss: 0.889565\n",
            "epoch: 2 (step: 1651) | train loss: 0.021472 | lr: 0.000823\n",
            "epoch: 2 (step: 1651) | valid_loss: 0.881423\n",
            "epoch: 2 (step: 1661) | train loss: 0.017719 | lr: 0.000822\n",
            "epoch: 2 (step: 1661) | valid_loss: 0.876832\n",
            "epoch: 2 (step: 1671) | train loss: 0.017987 | lr: 0.000821\n",
            "epoch: 2 (step: 1671) | valid_loss: 0.882182\n",
            "epoch: 2 (step: 1681) | train loss: 0.025104 | lr: 0.000820\n",
            "epoch: 2 (step: 1681) | valid_loss: 0.887228\n",
            "epoch: 2 (step: 1691) | train loss: 0.023309 | lr: 0.000819\n",
            "epoch: 2 (step: 1691) | valid_loss: 0.895726\n",
            "epoch: 2 (step: 1701) | train loss: 0.023593 | lr: 0.000818\n",
            "epoch: 2 (step: 1701) | valid_loss: 0.888375\n",
            "epoch: 2 (step: 1711) | train loss: 0.024792 | lr: 0.000817\n",
            "epoch: 2 (step: 1711) | valid_loss: 0.885047\n",
            "epoch: 2 (step: 1721) | train loss: 0.020233 | lr: 0.000816\n",
            "epoch: 2 (step: 1721) | valid_loss: 0.891851\n",
            "epoch: 2 (step: 1731) | train loss: 0.016797 | lr: 0.000815\n",
            "epoch: 2 (step: 1731) | valid_loss: 0.897001\n",
            "epoch: 2 (step: 1741) | train loss: 0.022968 | lr: 0.000814\n",
            "epoch: 2 (step: 1741) | valid_loss: 0.898126\n",
            "epoch: 2 (step: 1751) | train loss: 0.026031 | lr: 0.000813\n",
            "epoch: 2 (step: 1751) | valid_loss: 0.897751\n",
            "epoch: 2 (step: 1761) | train loss: 0.020337 | lr: 0.000811\n",
            "epoch: 2 (step: 1761) | valid_loss: 0.898053\n",
            "epoch: 2 (step: 1771) | train loss: 0.018842 | lr: 0.000810\n",
            "epoch: 2 (step: 1771) | valid_loss: 0.899279\n",
            "epoch: 2 (step: 1781) | train loss: 0.018622 | lr: 0.000809\n",
            "epoch: 2 (step: 1781) | valid_loss: 0.907476\n",
            "epoch: 2 (step: 1791) | train loss: 0.022327 | lr: 0.000808\n",
            "epoch: 2 (step: 1791) | valid_loss: 0.901124\n",
            "epoch: 2 (step: 1801) | train loss: 0.027026 | lr: 0.000807\n",
            "epoch: 2 (step: 1801) | valid_loss: 0.896343\n",
            "epoch: 2 (step: 1811) | train loss: 0.019789 | lr: 0.000806\n",
            "epoch: 2 (step: 1811) | valid_loss: 0.899899\n",
            "epoch: 2 (step: 1821) | train loss: 0.019054 | lr: 0.000805\n",
            "epoch: 2 (step: 1821) | valid_loss: 0.901182\n",
            "epoch: 2 (step: 1831) | train loss: 0.013632 | lr: 0.000804\n",
            "epoch: 2 (step: 1831) | valid_loss: 0.898462\n",
            "epoch: 2 (step: 1841) | train loss: 0.024677 | lr: 0.000803\n",
            "epoch: 2 (step: 1841) | valid_loss: 0.905723\n",
            "epoch: 2 (step: 1851) | train loss: 0.020282 | lr: 0.000802\n",
            "epoch: 2 (step: 1851) | valid_loss: 0.907810\n",
            "epoch: 2 (step: 1861) | train loss: 0.024237 | lr: 0.000801\n",
            "epoch: 2 (step: 1861) | valid_loss: 0.904610\n",
            "epoch: 3 (step: 1871) | train loss: 0.020844 | lr: 0.000800\n",
            "epoch: 3 (step: 1871) | valid_loss: 0.895417\n",
            "epoch: 3 (step: 1881) | train loss: 0.018845 | lr: 0.000799\n",
            "epoch: 3 (step: 1881) | valid_loss: 0.892184\n",
            "epoch: 3 (step: 1891) | train loss: 0.018625 | lr: 0.000798\n",
            "epoch: 3 (step: 1891) | valid_loss: 0.888309\n",
            "epoch: 3 (step: 1901) | train loss: 0.021344 | lr: 0.000796\n",
            "epoch: 3 (step: 1901) | valid_loss: 0.902525\n",
            "epoch: 3 (step: 1911) | train loss: 0.012402 | lr: 0.000795\n",
            "epoch: 3 (step: 1911) | valid_loss: 0.916825\n",
            "epoch: 3 (step: 1921) | train loss: 0.021674 | lr: 0.000794\n",
            "epoch: 3 (step: 1921) | valid_loss: 0.924924\n",
            "epoch: 3 (step: 1931) | train loss: 0.021118 | lr: 0.000793\n",
            "epoch: 3 (step: 1931) | valid_loss: 0.917727\n",
            "epoch: 3 (step: 1941) | train loss: 0.020654 | lr: 0.000792\n",
            "epoch: 3 (step: 1941) | valid_loss: 0.907700\n",
            "epoch: 3 (step: 1951) | train loss: 0.019653 | lr: 0.000791\n",
            "epoch: 3 (step: 1951) | valid_loss: 0.897785\n",
            "epoch: 3 (step: 1961) | train loss: 0.018964 | lr: 0.000790\n",
            "epoch: 3 (step: 1961) | valid_loss: 0.890242\n",
            "epoch: 3 (step: 1971) | train loss: 0.020053 | lr: 0.000789\n",
            "epoch: 3 (step: 1971) | valid_loss: 0.892610\n",
            "epoch: 3 (step: 1981) | train loss: 0.016345 | lr: 0.000788\n",
            "epoch: 3 (step: 1981) | valid_loss: 0.897728\n",
            "epoch: 3 (step: 1991) | train loss: 0.019202 | lr: 0.000787\n",
            "epoch: 3 (step: 1991) | valid_loss: 0.887305\n",
            "epoch: 3 (step: 2001) | train loss: 0.020697 | lr: 0.000786\n",
            "epoch: 3 (step: 2001) | valid_loss: 0.881780\n",
            "epoch: 3 (step: 2011) | train loss: 0.019275 | lr: 0.000785\n",
            "epoch: 3 (step: 2011) | valid_loss: 0.885267\n",
            "epoch: 3 (step: 2021) | train loss: 0.016182 | lr: 0.000784\n",
            "epoch: 3 (step: 2021) | valid_loss: 0.882607\n",
            "epoch: 3 (step: 2031) | train loss: 0.016873 | lr: 0.000783\n",
            "epoch: 3 (step: 2031) | valid_loss: 0.878510\n",
            "epoch: 3 (step: 2041) | train loss: 0.012204 | lr: 0.000781\n",
            "epoch: 3 (step: 2041) | valid_loss: 0.872195\n",
            "epoch: 3 (step: 2051) | train loss: 0.018173 | lr: 0.000780\n",
            "epoch: 3 (step: 2051) | valid_loss: 0.876465\n",
            "epoch: 3 (step: 2061) | train loss: 0.019781 | lr: 0.000779\n",
            "epoch: 3 (step: 2061) | valid_loss: 0.886698\n",
            "epoch: 3 (step: 2071) | train loss: 0.014478 | lr: 0.000778\n",
            "epoch: 3 (step: 2071) | valid_loss: 0.894541\n",
            "epoch: 3 (step: 2081) | train loss: 0.012457 | lr: 0.000777\n",
            "epoch: 3 (step: 2081) | valid_loss: 0.894756\n",
            "epoch: 3 (step: 2091) | train loss: 0.016125 | lr: 0.000776\n",
            "epoch: 3 (step: 2091) | valid_loss: 0.894197\n",
            "epoch: 3 (step: 2101) | train loss: 0.018732 | lr: 0.000775\n",
            "epoch: 3 (step: 2101) | valid_loss: 0.898846\n",
            "epoch: 3 (step: 2111) | train loss: 0.013641 | lr: 0.000774\n",
            "epoch: 3 (step: 2111) | valid_loss: 0.894277\n",
            "epoch: 3 (step: 2121) | train loss: 0.016730 | lr: 0.000773\n",
            "epoch: 3 (step: 2121) | valid_loss: 0.893498\n",
            "epoch: 3 (step: 2131) | train loss: 0.017123 | lr: 0.000772\n",
            "epoch: 3 (step: 2131) | valid_loss: 0.889955\n",
            "epoch: 3 (step: 2141) | train loss: 0.017094 | lr: 0.000771\n",
            "epoch: 3 (step: 2141) | valid_loss: 0.874723\n",
            "epoch: 3 (step: 2151) | train loss: 0.017528 | lr: 0.000770\n",
            "epoch: 3 (step: 2151) | valid_loss: 0.882924\n",
            "epoch: 3 (step: 2161) | train loss: 0.017899 | lr: 0.000769\n",
            "epoch: 3 (step: 2161) | valid_loss: 0.882597\n",
            "epoch: 3 (step: 2171) | train loss: 0.018298 | lr: 0.000768\n",
            "epoch: 3 (step: 2171) | valid_loss: 0.881206\n",
            "epoch: 3 (step: 2181) | train loss: 0.015082 | lr: 0.000766\n",
            "epoch: 3 (step: 2181) | valid_loss: 0.877121\n",
            "epoch: 3 (step: 2191) | train loss: 0.012566 | lr: 0.000765\n",
            "epoch: 3 (step: 2191) | valid_loss: 0.865146\n",
            "epoch: 3 (step: 2201) | train loss: 0.011607 | lr: 0.000764\n",
            "epoch: 3 (step: 2201) | valid_loss: 0.867926\n",
            "epoch: 3 (step: 2211) | train loss: 0.016455 | lr: 0.000763\n",
            "epoch: 3 (step: 2211) | valid_loss: 0.871417\n",
            "epoch: 3 (step: 2221) | train loss: 0.016147 | lr: 0.000762\n",
            "epoch: 3 (step: 2221) | valid_loss: 0.871851\n",
            "epoch: 3 (step: 2231) | train loss: 0.016635 | lr: 0.000761\n",
            "epoch: 3 (step: 2231) | valid_loss: 0.870927\n",
            "epoch: 3 (step: 2241) | train loss: 0.014590 | lr: 0.000760\n",
            "epoch: 3 (step: 2241) | valid_loss: 0.867861\n",
            "epoch: 3 (step: 2251) | train loss: 0.014944 | lr: 0.000759\n",
            "epoch: 3 (step: 2251) | valid_loss: 0.870406\n",
            "epoch: 3 (step: 2261) | train loss: 0.014395 | lr: 0.000758\n",
            "epoch: 3 (step: 2261) | valid_loss: 0.867052\n",
            "epoch: 3 (step: 2271) | train loss: 0.017245 | lr: 0.000757\n",
            "epoch: 3 (step: 2271) | valid_loss: 0.865512\n",
            "epoch: 3 (step: 2281) | train loss: 0.022566 | lr: 0.000756\n",
            "epoch: 3 (step: 2281) | valid_loss: 0.866711\n",
            "epoch: 3 (step: 2291) | train loss: 0.017291 | lr: 0.000755\n",
            "epoch: 3 (step: 2291) | valid_loss: 0.860447\n",
            "epoch: 3 (step: 2301) | train loss: 0.012056 | lr: 0.000754\n",
            "epoch: 3 (step: 2301) | valid_loss: 0.858124\n",
            "epoch: 3 (step: 2311) | train loss: 0.014313 | lr: 0.000753\n",
            "epoch: 3 (step: 2311) | valid_loss: 0.855730\n",
            "epoch: 3 (step: 2321) | train loss: 0.017142 | lr: 0.000751\n",
            "epoch: 3 (step: 2321) | valid_loss: 0.850367\n",
            "epoch: 3 (step: 2331) | train loss: 0.013589 | lr: 0.000750\n",
            "epoch: 3 (step: 2331) | valid_loss: 0.848396\n",
            "epoch: 3 (step: 2341) | train loss: 0.013455 | lr: 0.000749\n",
            "epoch: 3 (step: 2341) | valid_loss: 0.851940\n",
            "epoch: 3 (step: 2351) | train loss: 0.017542 | lr: 0.000748\n",
            "epoch: 3 (step: 2351) | valid_loss: 0.857481\n",
            "epoch: 3 (step: 2361) | train loss: 0.012988 | lr: 0.000747\n",
            "epoch: 3 (step: 2361) | valid_loss: 0.857507\n",
            "epoch: 3 (step: 2371) | train loss: 0.015753 | lr: 0.000746\n",
            "epoch: 3 (step: 2371) | valid_loss: 0.850077\n",
            "epoch: 3 (step: 2381) | train loss: 0.015057 | lr: 0.000745\n",
            "epoch: 3 (step: 2381) | valid_loss: 0.849559\n",
            "epoch: 3 (step: 2391) | train loss: 0.016315 | lr: 0.000744\n",
            "epoch: 3 (step: 2391) | valid_loss: 0.849330\n",
            "epoch: 3 (step: 2401) | train loss: 0.013531 | lr: 0.000743\n",
            "epoch: 3 (step: 2401) | valid_loss: 0.847741\n",
            "epoch: 3 (step: 2411) | train loss: 0.015546 | lr: 0.000742\n",
            "epoch: 3 (step: 2411) | valid_loss: 0.848617\n",
            "epoch: 3 (step: 2421) | train loss: 0.013702 | lr: 0.000741\n",
            "epoch: 3 (step: 2421) | valid_loss: 0.846629\n",
            "epoch: 3 (step: 2431) | train loss: 0.014380 | lr: 0.000740\n",
            "epoch: 3 (step: 2431) | valid_loss: 0.849101\n",
            "epoch: 3 (step: 2441) | train loss: 0.014032 | lr: 0.000739\n",
            "epoch: 3 (step: 2441) | valid_loss: 0.850832\n",
            "epoch: 3 (step: 2451) | train loss: 0.012207 | lr: 0.000738\n",
            "epoch: 3 (step: 2451) | valid_loss: 0.848489\n",
            "epoch: 3 (step: 2461) | train loss: 0.010551 | lr: 0.000737\n",
            "epoch: 3 (step: 2461) | valid_loss: 0.838286\n",
            "Model checkpoint 'best' saved successfully to outputs/t5-baseline/checkpoint_best.pth.tar.\n",
            "epoch: 3 (step: 2471) | train loss: 0.013322 | lr: 0.000735\n",
            "epoch: 3 (step: 2471) | valid_loss: 0.840147\n",
            "epoch: 3 (step: 2481) | train loss: 0.008975 | lr: 0.000734\n",
            "epoch: 3 (step: 2481) | valid_loss: 0.841066\n",
            "epoch: 3 (step: 2491) | train loss: 0.010071 | lr: 0.000733\n",
            "epoch: 3 (step: 2491) | valid_loss: 0.843441\n",
            "epoch: 3 (step: 2501) | train loss: 0.013507 | lr: 0.000732\n",
            "epoch: 3 (step: 2501) | valid_loss: 0.844911\n",
            "epoch: 3 (step: 2511) | train loss: 0.012408 | lr: 0.000731\n",
            "epoch: 3 (step: 2511) | valid_loss: 0.852220\n",
            "epoch: 3 (step: 2521) | train loss: 0.013000 | lr: 0.000730\n",
            "epoch: 3 (step: 2521) | valid_loss: 0.862942\n",
            "epoch: 3 (step: 2531) | train loss: 0.010942 | lr: 0.000729\n",
            "epoch: 3 (step: 2531) | valid_loss: 0.865012\n",
            "epoch: 3 (step: 2541) | train loss: 0.013004 | lr: 0.000728\n",
            "epoch: 3 (step: 2541) | valid_loss: 0.865378\n",
            "epoch: 3 (step: 2551) | train loss: 0.010736 | lr: 0.000727\n",
            "epoch: 3 (step: 2551) | valid_loss: 0.870139\n",
            "epoch: 3 (step: 2561) | train loss: 0.011600 | lr: 0.000726\n",
            "epoch: 3 (step: 2561) | valid_loss: 0.869810\n",
            "epoch: 3 (step: 2571) | train loss: 0.010562 | lr: 0.000725\n",
            "epoch: 3 (step: 2571) | valid_loss: 0.870490\n",
            "epoch: 3 (step: 2581) | train loss: 0.013101 | lr: 0.000724\n",
            "epoch: 3 (step: 2581) | valid_loss: 0.870598\n",
            "epoch: 3 (step: 2591) | train loss: 0.010797 | lr: 0.000723\n",
            "epoch: 3 (step: 2591) | valid_loss: 0.873816\n",
            "epoch: 3 (step: 2601) | train loss: 0.014023 | lr: 0.000722\n",
            "epoch: 3 (step: 2601) | valid_loss: 0.875200\n",
            "epoch: 3 (step: 2611) | train loss: 0.011336 | lr: 0.000720\n",
            "epoch: 3 (step: 2611) | valid_loss: 0.868846\n",
            "epoch: 3 (step: 2621) | train loss: 0.019608 | lr: 0.000719\n",
            "epoch: 3 (step: 2621) | valid_loss: 0.879177\n",
            "epoch: 3 (step: 2631) | train loss: 0.012201 | lr: 0.000718\n",
            "epoch: 3 (step: 2631) | valid_loss: 0.890084\n",
            "epoch: 3 (step: 2641) | train loss: 0.016415 | lr: 0.000717\n",
            "epoch: 3 (step: 2641) | valid_loss: 0.895581\n",
            "epoch: 3 (step: 2651) | train loss: 0.013412 | lr: 0.000716\n",
            "epoch: 3 (step: 2651) | valid_loss: 0.900723\n",
            "epoch: 3 (step: 2661) | train loss: 0.011430 | lr: 0.000715\n",
            "epoch: 3 (step: 2661) | valid_loss: 0.897259\n",
            "epoch: 3 (step: 2671) | train loss: 0.012814 | lr: 0.000714\n",
            "epoch: 3 (step: 2671) | valid_loss: 0.889916\n",
            "epoch: 3 (step: 2681) | train loss: 0.011646 | lr: 0.000713\n",
            "epoch: 3 (step: 2681) | valid_loss: 0.881846\n",
            "epoch: 3 (step: 2691) | train loss: 0.016721 | lr: 0.000712\n",
            "epoch: 3 (step: 2691) | valid_loss: 0.884740\n",
            "epoch: 3 (step: 2701) | train loss: 0.018273 | lr: 0.000711\n",
            "epoch: 3 (step: 2701) | valid_loss: 0.883701\n",
            "epoch: 3 (step: 2711) | train loss: 0.014509 | lr: 0.000710\n",
            "epoch: 3 (step: 2711) | valid_loss: 0.880655\n",
            "epoch: 3 (step: 2721) | train loss: 0.012479 | lr: 0.000709\n",
            "epoch: 3 (step: 2721) | valid_loss: 0.882593\n",
            "epoch: 3 (step: 2731) | train loss: 0.011121 | lr: 0.000708\n",
            "epoch: 3 (step: 2731) | valid_loss: 0.886245\n",
            "epoch: 3 (step: 2741) | train loss: 0.016922 | lr: 0.000707\n",
            "epoch: 3 (step: 2741) | valid_loss: 0.899730\n",
            "epoch: 3 (step: 2751) | train loss: 0.015948 | lr: 0.000705\n",
            "epoch: 3 (step: 2751) | valid_loss: 0.904858\n",
            "epoch: 3 (step: 2761) | train loss: 0.015179 | lr: 0.000704\n",
            "epoch: 3 (step: 2761) | valid_loss: 0.905954\n",
            "epoch: 3 (step: 2771) | train loss: 0.011852 | lr: 0.000703\n",
            "epoch: 3 (step: 2771) | valid_loss: 0.905259\n",
            "epoch: 3 (step: 2781) | train loss: 0.013797 | lr: 0.000702\n",
            "epoch: 3 (step: 2781) | valid_loss: 0.904393\n",
            "epoch: 3 (step: 2791) | train loss: 0.012079 | lr: 0.000701\n",
            "epoch: 3 (step: 2791) | valid_loss: 0.908412\n",
            "epoch: 3 (step: 2801) | train loss: 0.008153 | lr: 0.000700\n",
            "epoch: 3 (step: 2801) | valid_loss: 0.912925\n",
            "epoch: 4 (step: 2811) | train loss: 0.012396 | lr: 0.000699\n",
            "epoch: 4 (step: 2811) | valid_loss: 0.911122\n",
            "epoch: 4 (step: 2821) | train loss: 0.011963 | lr: 0.000698\n",
            "epoch: 4 (step: 2821) | valid_loss: 0.899393\n",
            "epoch: 4 (step: 2831) | train loss: 0.008537 | lr: 0.000697\n",
            "epoch: 4 (step: 2831) | valid_loss: 0.895707\n",
            "epoch: 4 (step: 2841) | train loss: 0.013675 | lr: 0.000696\n",
            "epoch: 4 (step: 2841) | valid_loss: 0.904579\n",
            "epoch: 4 (step: 2851) | train loss: 0.011703 | lr: 0.000695\n",
            "epoch: 4 (step: 2851) | valid_loss: 0.912875\n",
            "epoch: 4 (step: 2861) | train loss: 0.008904 | lr: 0.000694\n",
            "epoch: 4 (step: 2861) | valid_loss: 0.908997\n",
            "epoch: 4 (step: 2871) | train loss: 0.016330 | lr: 0.000693\n",
            "epoch: 4 (step: 2871) | valid_loss: 0.900640\n",
            "epoch: 4 (step: 2881) | train loss: 0.015793 | lr: 0.000692\n",
            "epoch: 4 (step: 2881) | valid_loss: 0.893322\n",
            "epoch: 4 (step: 2891) | train loss: 0.011429 | lr: 0.000690\n",
            "epoch: 4 (step: 2891) | valid_loss: 0.889327\n",
            "epoch: 4 (step: 2901) | train loss: 0.012958 | lr: 0.000689\n",
            "epoch: 4 (step: 2901) | valid_loss: 0.888055\n",
            "epoch: 4 (step: 2911) | train loss: 0.007619 | lr: 0.000688\n",
            "epoch: 4 (step: 2911) | valid_loss: 0.889727\n",
            "epoch: 4 (step: 2921) | train loss: 0.011565 | lr: 0.000687\n",
            "epoch: 4 (step: 2921) | valid_loss: 0.889711\n",
            "epoch: 4 (step: 2931) | train loss: 0.010623 | lr: 0.000686\n",
            "epoch: 4 (step: 2931) | valid_loss: 0.890207\n",
            "epoch: 4 (step: 2941) | train loss: 0.012074 | lr: 0.000685\n",
            "epoch: 4 (step: 2941) | valid_loss: 0.885774\n",
            "epoch: 4 (step: 2951) | train loss: 0.012518 | lr: 0.000684\n",
            "epoch: 4 (step: 2951) | valid_loss: 0.886768\n",
            "epoch: 4 (step: 2961) | train loss: 0.011198 | lr: 0.000683\n",
            "epoch: 4 (step: 2961) | valid_loss: 0.891659\n",
            "epoch: 4 (step: 2971) | train loss: 0.009341 | lr: 0.000682\n",
            "epoch: 4 (step: 2971) | valid_loss: 0.889144\n",
            "epoch: 4 (step: 2981) | train loss: 0.011520 | lr: 0.000681\n",
            "epoch: 4 (step: 2981) | valid_loss: 0.885542\n",
            "epoch: 4 (step: 2991) | train loss: 0.010384 | lr: 0.000680\n",
            "epoch: 4 (step: 2991) | valid_loss: 0.882658\n",
            "epoch: 4 (step: 3001) | train loss: 0.006913 | lr: 0.000679\n",
            "epoch: 4 (step: 3001) | valid_loss: 0.883666\n",
            "epoch: 4 (step: 3011) | train loss: 0.009821 | lr: 0.000678\n",
            "epoch: 4 (step: 3011) | valid_loss: 0.885320\n",
            "epoch: 4 (step: 3021) | train loss: 0.009863 | lr: 0.000677\n",
            "epoch: 4 (step: 3021) | valid_loss: 0.889400\n",
            "epoch: 4 (step: 3031) | train loss: 0.009566 | lr: 0.000675\n",
            "epoch: 4 (step: 3031) | valid_loss: 0.891089\n",
            "epoch: 4 (step: 3041) | train loss: 0.011768 | lr: 0.000674\n",
            "epoch: 4 (step: 3041) | valid_loss: 0.890322\n",
            "epoch: 4 (step: 3051) | train loss: 0.011984 | lr: 0.000673\n",
            "epoch: 4 (step: 3051) | valid_loss: 0.892293\n",
            "epoch: 4 (step: 3061) | train loss: 0.009798 | lr: 0.000672\n",
            "epoch: 4 (step: 3061) | valid_loss: 0.896750\n",
            "epoch: 4 (step: 3071) | train loss: 0.008345 | lr: 0.000671\n",
            "epoch: 4 (step: 3071) | valid_loss: 0.899260\n",
            "epoch: 4 (step: 3081) | train loss: 0.010223 | lr: 0.000670\n",
            "epoch: 4 (step: 3081) | valid_loss: 0.901923\n",
            "epoch: 4 (step: 3091) | train loss: 0.010563 | lr: 0.000669\n",
            "epoch: 4 (step: 3091) | valid_loss: 0.908448\n",
            "epoch: 4 (step: 3101) | train loss: 0.012683 | lr: 0.000668\n",
            "epoch: 4 (step: 3101) | valid_loss: 0.913243\n",
            "epoch: 4 (step: 3111) | train loss: 0.013361 | lr: 0.000667\n",
            "epoch: 4 (step: 3111) | valid_loss: 0.916362\n",
            "epoch: 4 (step: 3121) | train loss: 0.012357 | lr: 0.000666\n",
            "epoch: 4 (step: 3121) | valid_loss: 0.913985\n",
            "epoch: 4 (step: 3131) | train loss: 0.009268 | lr: 0.000665\n",
            "epoch: 4 (step: 3131) | valid_loss: 0.910396\n",
            "epoch: 4 (step: 3141) | train loss: 0.012143 | lr: 0.000664\n",
            "epoch: 4 (step: 3141) | valid_loss: 0.910774\n",
            "epoch: 4 (step: 3151) | train loss: 0.014207 | lr: 0.000663\n",
            "epoch: 4 (step: 3151) | valid_loss: 0.909962\n",
            "epoch: 4 (step: 3161) | train loss: 0.010446 | lr: 0.000662\n",
            "epoch: 4 (step: 3161) | valid_loss: 0.904876\n",
            "epoch: 4 (step: 3171) | train loss: 0.015051 | lr: 0.000660\n",
            "epoch: 4 (step: 3171) | valid_loss: 0.905394\n",
            "epoch: 4 (step: 3181) | train loss: 0.008499 | lr: 0.000659\n",
            "epoch: 4 (step: 3181) | valid_loss: 0.903566\n",
            "epoch: 4 (step: 3191) | train loss: 0.010184 | lr: 0.000658\n",
            "epoch: 4 (step: 3191) | valid_loss: 0.899034\n",
            "epoch: 4 (step: 3201) | train loss: 0.007733 | lr: 0.000657\n",
            "epoch: 4 (step: 3201) | valid_loss: 0.898252\n",
            "epoch: 4 (step: 3211) | train loss: 0.009979 | lr: 0.000656\n",
            "epoch: 4 (step: 3211) | valid_loss: 0.896541\n",
            "epoch: 4 (step: 3221) | train loss: 0.006153 | lr: 0.000655\n",
            "epoch: 4 (step: 3221) | valid_loss: 0.897531\n",
            "epoch: 4 (step: 3231) | train loss: 0.011807 | lr: 0.000654\n",
            "epoch: 4 (step: 3231) | valid_loss: 0.896823\n",
            "epoch: 4 (step: 3241) | train loss: 0.010188 | lr: 0.000653\n",
            "epoch: 4 (step: 3241) | valid_loss: 0.898519\n",
            "epoch: 4 (step: 3251) | train loss: 0.005992 | lr: 0.000652\n",
            "epoch: 4 (step: 3251) | valid_loss: 0.900965\n",
            "epoch: 4 (step: 3261) | train loss: 0.013791 | lr: 0.000651\n",
            "epoch: 4 (step: 3261) | valid_loss: 0.903651\n",
            "epoch: 4 (step: 3271) | train loss: 0.009386 | lr: 0.000650\n",
            "epoch: 4 (step: 3271) | valid_loss: 0.904838\n",
            "epoch: 4 (step: 3281) | train loss: 0.010229 | lr: 0.000649\n",
            "epoch: 4 (step: 3281) | valid_loss: 0.900373\n",
            "epoch: 4 (step: 3291) | train loss: 0.008624 | lr: 0.000648\n",
            "epoch: 4 (step: 3291) | valid_loss: 0.898369\n",
            "epoch: 4 (step: 3301) | train loss: 0.009293 | lr: 0.000647\n",
            "epoch: 4 (step: 3301) | valid_loss: 0.894948\n",
            "epoch: 4 (step: 3311) | train loss: 0.008914 | lr: 0.000646\n",
            "epoch: 4 (step: 3311) | valid_loss: 0.895932\n",
            "epoch: 4 (step: 3321) | train loss: 0.009323 | lr: 0.000644\n",
            "epoch: 4 (step: 3321) | valid_loss: 0.897609\n",
            "epoch: 4 (step: 3331) | train loss: 0.012955 | lr: 0.000643\n",
            "epoch: 4 (step: 3331) | valid_loss: 0.899816\n",
            "epoch: 4 (step: 3341) | train loss: 0.009306 | lr: 0.000642\n",
            "epoch: 4 (step: 3341) | valid_loss: 0.898631\n",
            "epoch: 4 (step: 3351) | train loss: 0.014316 | lr: 0.000641\n",
            "epoch: 4 (step: 3351) | valid_loss: 0.898401\n",
            "epoch: 4 (step: 3361) | train loss: 0.012941 | lr: 0.000640\n",
            "epoch: 4 (step: 3361) | valid_loss: 0.898195\n",
            "epoch: 4 (step: 3371) | train loss: 0.007269 | lr: 0.000639\n",
            "epoch: 4 (step: 3371) | valid_loss: 0.897694\n",
            "epoch: 4 (step: 3381) | train loss: 0.012700 | lr: 0.000638\n",
            "epoch: 4 (step: 3381) | valid_loss: 0.900348\n",
            "epoch: 4 (step: 3391) | train loss: 0.011008 | lr: 0.000637\n",
            "epoch: 4 (step: 3391) | valid_loss: 0.899128\n",
            "epoch: 4 (step: 3401) | train loss: 0.011328 | lr: 0.000636\n",
            "epoch: 4 (step: 3401) | valid_loss: 0.896425\n",
            "epoch: 4 (step: 3411) | train loss: 0.010056 | lr: 0.000635\n",
            "epoch: 4 (step: 3411) | valid_loss: 0.897162\n",
            "epoch: 4 (step: 3421) | train loss: 0.009405 | lr: 0.000634\n",
            "epoch: 4 (step: 3421) | valid_loss: 0.895671\n",
            "epoch: 4 (step: 3431) | train loss: 0.007957 | lr: 0.000633\n",
            "epoch: 4 (step: 3431) | valid_loss: 0.893502\n",
            "epoch: 4 (step: 3441) | train loss: 0.011172 | lr: 0.000632\n",
            "epoch: 4 (step: 3441) | valid_loss: 0.891258\n",
            "epoch: 4 (step: 3451) | train loss: 0.006477 | lr: 0.000631\n",
            "epoch: 4 (step: 3451) | valid_loss: 0.887523\n",
            "epoch: 4 (step: 3461) | train loss: 0.011288 | lr: 0.000629\n",
            "epoch: 4 (step: 3461) | valid_loss: 0.885796\n",
            "epoch: 4 (step: 3471) | train loss: 0.007498 | lr: 0.000628\n",
            "epoch: 4 (step: 3471) | valid_loss: 0.885351\n",
            "epoch: 4 (step: 3481) | train loss: 0.009715 | lr: 0.000627\n",
            "epoch: 4 (step: 3481) | valid_loss: 0.885130\n",
            "epoch: 4 (step: 3491) | train loss: 0.009467 | lr: 0.000626\n",
            "epoch: 4 (step: 3491) | valid_loss: 0.886800\n",
            "epoch: 4 (step: 3501) | train loss: 0.008476 | lr: 0.000625\n",
            "epoch: 4 (step: 3501) | valid_loss: 0.888253\n",
            "epoch: 4 (step: 3511) | train loss: 0.008556 | lr: 0.000624\n",
            "epoch: 4 (step: 3511) | valid_loss: 0.886825\n",
            "epoch: 4 (step: 3521) | train loss: 0.009599 | lr: 0.000623\n",
            "epoch: 4 (step: 3521) | valid_loss: 0.887318\n",
            "epoch: 4 (step: 3531) | train loss: 0.011458 | lr: 0.000622\n",
            "epoch: 4 (step: 3531) | valid_loss: 0.886572\n",
            "epoch: 4 (step: 3541) | train loss: 0.009688 | lr: 0.000621\n",
            "epoch: 4 (step: 3541) | valid_loss: 0.887249\n",
            "epoch: 4 (step: 3551) | train loss: 0.008430 | lr: 0.000620\n",
            "epoch: 4 (step: 3551) | valid_loss: 0.888443\n",
            "epoch: 4 (step: 3561) | train loss: 0.005807 | lr: 0.000619\n",
            "epoch: 4 (step: 3561) | valid_loss: 0.887459\n",
            "epoch: 4 (step: 3571) | train loss: 0.007452 | lr: 0.000618\n",
            "epoch: 4 (step: 3571) | valid_loss: 0.890131\n",
            "epoch: 4 (step: 3581) | train loss: 0.012120 | lr: 0.000617\n",
            "epoch: 4 (step: 3581) | valid_loss: 0.894026\n",
            "epoch: 4 (step: 3591) | train loss: 0.008537 | lr: 0.000616\n",
            "epoch: 4 (step: 3591) | valid_loss: 0.894890\n",
            "epoch: 4 (step: 3601) | train loss: 0.012399 | lr: 0.000614\n",
            "epoch: 4 (step: 3601) | valid_loss: 0.893194\n",
            "epoch: 4 (step: 3611) | train loss: 0.007373 | lr: 0.000613\n",
            "epoch: 4 (step: 3611) | valid_loss: 0.893800\n",
            "epoch: 4 (step: 3621) | train loss: 0.010606 | lr: 0.000612\n",
            "epoch: 4 (step: 3621) | valid_loss: 0.894723\n",
            "epoch: 4 (step: 3631) | train loss: 0.016354 | lr: 0.000611\n",
            "epoch: 4 (step: 3631) | valid_loss: 0.894747\n",
            "epoch: 4 (step: 3641) | train loss: 0.007124 | lr: 0.000610\n",
            "epoch: 4 (step: 3641) | valid_loss: 0.898598\n",
            "epoch: 4 (step: 3651) | train loss: 0.009813 | lr: 0.000609\n",
            "epoch: 4 (step: 3651) | valid_loss: 0.901997\n",
            "epoch: 4 (step: 3661) | train loss: 0.010284 | lr: 0.000608\n",
            "epoch: 4 (step: 3661) | valid_loss: 0.901016\n",
            "epoch: 4 (step: 3671) | train loss: 0.013653 | lr: 0.000607\n",
            "epoch: 4 (step: 3671) | valid_loss: 0.896652\n",
            "epoch: 4 (step: 3681) | train loss: 0.011420 | lr: 0.000606\n",
            "epoch: 4 (step: 3681) | valid_loss: 0.889580\n",
            "epoch: 4 (step: 3691) | train loss: 0.007771 | lr: 0.000605\n",
            "epoch: 4 (step: 3691) | valid_loss: 0.890268\n",
            "epoch: 4 (step: 3701) | train loss: 0.007758 | lr: 0.000604\n",
            "epoch: 4 (step: 3701) | valid_loss: 0.889037\n",
            "epoch: 4 (step: 3711) | train loss: 0.008990 | lr: 0.000603\n",
            "epoch: 4 (step: 3711) | valid_loss: 0.887084\n",
            "epoch: 4 (step: 3721) | train loss: 0.007472 | lr: 0.000602\n",
            "epoch: 4 (step: 3721) | valid_loss: 0.886637\n",
            "epoch: 4 (step: 3731) | train loss: 0.010454 | lr: 0.000601\n",
            "epoch: 4 (step: 3731) | valid_loss: 0.883479\n",
            "epoch: 5 (step: 3741) | train loss: 0.009059 | lr: 0.000599\n",
            "epoch: 5 (step: 3741) | valid_loss: 0.882478\n",
            "epoch: 5 (step: 3751) | train loss: 0.008426 | lr: 0.000598\n",
            "epoch: 5 (step: 3751) | valid_loss: 0.882270\n",
            "epoch: 5 (step: 3761) | train loss: 0.009790 | lr: 0.000597\n",
            "epoch: 5 (step: 3761) | valid_loss: 0.882741\n",
            "epoch: 5 (step: 3771) | train loss: 0.010582 | lr: 0.000596\n",
            "epoch: 5 (step: 3771) | valid_loss: 0.886742\n",
            "epoch: 5 (step: 3781) | train loss: 0.008908 | lr: 0.000595\n",
            "epoch: 5 (step: 3781) | valid_loss: 0.888179\n",
            "epoch: 5 (step: 3791) | train loss: 0.012590 | lr: 0.000594\n",
            "epoch: 5 (step: 3791) | valid_loss: 0.889131\n",
            "epoch: 5 (step: 3801) | train loss: 0.007378 | lr: 0.000593\n",
            "epoch: 5 (step: 3801) | valid_loss: 0.888573\n",
            "epoch: 5 (step: 3811) | train loss: 0.011601 | lr: 0.000592\n",
            "epoch: 5 (step: 3811) | valid_loss: 0.888164\n",
            "epoch: 5 (step: 3821) | train loss: 0.011722 | lr: 0.000591\n",
            "epoch: 5 (step: 3821) | valid_loss: 0.880212\n",
            "epoch: 5 (step: 3831) | train loss: 0.009020 | lr: 0.000590\n",
            "epoch: 5 (step: 3831) | valid_loss: 0.877243\n",
            "epoch: 5 (step: 3841) | train loss: 0.009220 | lr: 0.000589\n",
            "epoch: 5 (step: 3841) | valid_loss: 0.880354\n",
            "epoch: 5 (step: 3851) | train loss: 0.006726 | lr: 0.000588\n",
            "epoch: 5 (step: 3851) | valid_loss: 0.882494\n",
            "epoch: 5 (step: 3861) | train loss: 0.007447 | lr: 0.000587\n",
            "epoch: 5 (step: 3861) | valid_loss: 0.881643\n",
            "epoch: 5 (step: 3871) | train loss: 0.007607 | lr: 0.000586\n",
            "epoch: 5 (step: 3871) | valid_loss: 0.880882\n",
            "epoch: 5 (step: 3881) | train loss: 0.007323 | lr: 0.000584\n",
            "epoch: 5 (step: 3881) | valid_loss: 0.877941\n",
            "epoch: 5 (step: 3891) | train loss: 0.007837 | lr: 0.000583\n",
            "epoch: 5 (step: 3891) | valid_loss: 0.878644\n",
            "epoch: 5 (step: 3901) | train loss: 0.008572 | lr: 0.000582\n",
            "epoch: 5 (step: 3901) | valid_loss: 0.879150\n",
            "epoch: 5 (step: 3911) | train loss: 0.006541 | lr: 0.000581\n",
            "epoch: 5 (step: 3911) | valid_loss: 0.881580\n",
            "epoch: 5 (step: 3921) | train loss: 0.009677 | lr: 0.000580\n",
            "epoch: 5 (step: 3921) | valid_loss: 0.880673\n",
            "epoch: 5 (step: 3931) | train loss: 0.010970 | lr: 0.000579\n",
            "epoch: 5 (step: 3931) | valid_loss: 0.879465\n",
            "epoch: 5 (step: 3941) | train loss: 0.011537 | lr: 0.000578\n",
            "epoch: 5 (step: 3941) | valid_loss: 0.879470\n",
            "epoch: 5 (step: 3951) | train loss: 0.011967 | lr: 0.000577\n",
            "epoch: 5 (step: 3951) | valid_loss: 0.883721\n",
            "epoch: 5 (step: 3961) | train loss: 0.009897 | lr: 0.000576\n",
            "epoch: 5 (step: 3961) | valid_loss: 0.890370\n",
            "epoch: 5 (step: 3971) | train loss: 0.007483 | lr: 0.000575\n",
            "epoch: 5 (step: 3971) | valid_loss: 0.892021\n",
            "epoch: 5 (step: 3981) | train loss: 0.010435 | lr: 0.000574\n",
            "epoch: 5 (step: 3981) | valid_loss: 0.891995\n",
            "epoch: 5 (step: 3991) | train loss: 0.008401 | lr: 0.000573\n",
            "epoch: 5 (step: 3991) | valid_loss: 0.889544\n",
            "epoch: 5 (step: 4001) | train loss: 0.008192 | lr: 0.000572\n",
            "epoch: 5 (step: 4001) | valid_loss: 0.886133\n",
            "epoch: 5 (step: 4011) | train loss: 0.008433 | lr: 0.000571\n",
            "epoch: 5 (step: 4011) | valid_loss: 0.883701\n",
            "epoch: 5 (step: 4021) | train loss: 0.006795 | lr: 0.000569\n",
            "epoch: 5 (step: 4021) | valid_loss: 0.879107\n",
            "epoch: 5 (step: 4031) | train loss: 0.009178 | lr: 0.000568\n",
            "epoch: 5 (step: 4031) | valid_loss: 0.877657\n",
            "epoch: 5 (step: 4041) | train loss: 0.007550 | lr: 0.000567\n",
            "epoch: 5 (step: 4041) | valid_loss: 0.877925\n",
            "epoch: 5 (step: 4051) | train loss: 0.011139 | lr: 0.000566\n",
            "epoch: 5 (step: 4051) | valid_loss: 0.877189\n",
            "epoch: 5 (step: 4061) | train loss: 0.007631 | lr: 0.000565\n",
            "epoch: 5 (step: 4061) | valid_loss: 0.877385\n",
            "epoch: 5 (step: 4071) | train loss: 0.006932 | lr: 0.000564\n",
            "epoch: 5 (step: 4071) | valid_loss: 0.877861\n",
            "epoch: 5 (step: 4081) | train loss: 0.009387 | lr: 0.000563\n",
            "epoch: 5 (step: 4081) | valid_loss: 0.877374\n",
            "epoch: 5 (step: 4091) | train loss: 0.006248 | lr: 0.000562\n",
            "epoch: 5 (step: 4091) | valid_loss: 0.878353\n",
            "epoch: 5 (step: 4101) | train loss: 0.010425 | lr: 0.000561\n",
            "epoch: 5 (step: 4101) | valid_loss: 0.878119\n",
            "epoch: 5 (step: 4111) | train loss: 0.005547 | lr: 0.000560\n",
            "epoch: 5 (step: 4111) | valid_loss: 0.877149\n",
            "epoch: 5 (step: 4121) | train loss: 0.008483 | lr: 0.000559\n",
            "epoch: 5 (step: 4121) | valid_loss: 0.879323\n",
            "epoch: 5 (step: 4131) | train loss: 0.009492 | lr: 0.000558\n",
            "epoch: 5 (step: 4131) | valid_loss: 0.878342\n",
            "epoch: 5 (step: 4141) | train loss: 0.008084 | lr: 0.000557\n",
            "epoch: 5 (step: 4141) | valid_loss: 0.878601\n",
            "epoch: 5 (step: 4151) | train loss: 0.011406 | lr: 0.000556\n",
            "epoch: 5 (step: 4151) | valid_loss: 0.879080\n",
            "epoch: 5 (step: 4161) | train loss: 0.008496 | lr: 0.000554\n",
            "epoch: 5 (step: 4161) | valid_loss: 0.881520\n",
            "epoch: 5 (step: 4171) | train loss: 0.008701 | lr: 0.000553\n",
            "epoch: 5 (step: 4171) | valid_loss: 0.882743\n",
            "epoch: 5 (step: 4181) | train loss: 0.008533 | lr: 0.000552\n",
            "epoch: 5 (step: 4181) | valid_loss: 0.889094\n",
            "epoch: 5 (step: 4191) | train loss: 0.008231 | lr: 0.000551\n",
            "epoch: 5 (step: 4191) | valid_loss: 0.890822\n",
            "epoch: 5 (step: 4201) | train loss: 0.007718 | lr: 0.000550\n",
            "epoch: 5 (step: 4201) | valid_loss: 0.889622\n",
            "epoch: 5 (step: 4211) | train loss: 0.009116 | lr: 0.000549\n",
            "epoch: 5 (step: 4211) | valid_loss: 0.892030\n",
            "epoch: 5 (step: 4221) | train loss: 0.008548 | lr: 0.000548\n",
            "epoch: 5 (step: 4221) | valid_loss: 0.895436\n",
            "epoch: 5 (step: 4231) | train loss: 0.005982 | lr: 0.000547\n",
            "epoch: 5 (step: 4231) | valid_loss: 0.895671\n",
            "epoch: 5 (step: 4241) | train loss: 0.010269 | lr: 0.000546\n",
            "epoch: 5 (step: 4241) | valid_loss: 0.895667\n",
            "epoch: 5 (step: 4251) | train loss: 0.007892 | lr: 0.000545\n",
            "epoch: 5 (step: 4251) | valid_loss: 0.893721\n",
            "epoch: 5 (step: 4261) | train loss: 0.006854 | lr: 0.000544\n",
            "epoch: 5 (step: 4261) | valid_loss: 0.895179\n",
            "epoch: 5 (step: 4271) | train loss: 0.006498 | lr: 0.000543\n",
            "epoch: 5 (step: 4271) | valid_loss: 0.894679\n",
            "epoch: 5 (step: 4281) | train loss: 0.006638 | lr: 0.000542\n",
            "epoch: 5 (step: 4281) | valid_loss: 0.891987\n",
            "epoch: 5 (step: 4291) | train loss: 0.008074 | lr: 0.000541\n",
            "epoch: 5 (step: 4291) | valid_loss: 0.891260\n",
            "epoch: 5 (step: 4301) | train loss: 0.007999 | lr: 0.000540\n",
            "epoch: 5 (step: 4301) | valid_loss: 0.891268\n",
            "epoch: 5 (step: 4311) | train loss: 0.006876 | lr: 0.000538\n",
            "epoch: 5 (step: 4311) | valid_loss: 0.892015\n",
            "epoch: 5 (step: 4321) | train loss: 0.008295 | lr: 0.000537\n",
            "epoch: 5 (step: 4321) | valid_loss: 0.892013\n",
            "epoch: 5 (step: 4331) | train loss: 0.008466 | lr: 0.000536\n",
            "epoch: 5 (step: 4331) | valid_loss: 0.891027\n",
            "epoch: 5 (step: 4341) | train loss: 0.006738 | lr: 0.000535\n",
            "epoch: 5 (step: 4341) | valid_loss: 0.888336\n",
            "epoch: 5 (step: 4351) | train loss: 0.006346 | lr: 0.000534\n",
            "epoch: 5 (step: 4351) | valid_loss: 0.887560\n",
            "epoch: 5 (step: 4361) | train loss: 0.007321 | lr: 0.000533\n",
            "epoch: 5 (step: 4361) | valid_loss: 0.889252\n",
            "epoch: 5 (step: 4371) | train loss: 0.006334 | lr: 0.000532\n",
            "epoch: 5 (step: 4371) | valid_loss: 0.888578\n",
            "epoch: 5 (step: 4381) | train loss: 0.008607 | lr: 0.000531\n",
            "epoch: 5 (step: 4381) | valid_loss: 0.889575\n",
            "epoch: 5 (step: 4391) | train loss: 0.006875 | lr: 0.000530\n",
            "epoch: 5 (step: 4391) | valid_loss: 0.888849\n",
            "epoch: 5 (step: 4401) | train loss: 0.007413 | lr: 0.000529\n",
            "epoch: 5 (step: 4401) | valid_loss: 0.888563\n",
            "epoch: 5 (step: 4411) | train loss: 0.007623 | lr: 0.000528\n",
            "epoch: 5 (step: 4411) | valid_loss: 0.886837\n",
            "epoch: 5 (step: 4421) | train loss: 0.008018 | lr: 0.000527\n",
            "epoch: 5 (step: 4421) | valid_loss: 0.884632\n",
            "epoch: 5 (step: 4431) | train loss: 0.008189 | lr: 0.000526\n",
            "epoch: 5 (step: 4431) | valid_loss: 0.884384\n",
            "epoch: 5 (step: 4441) | train loss: 0.006770 | lr: 0.000525\n",
            "epoch: 5 (step: 4441) | valid_loss: 0.882914\n",
            "epoch: 5 (step: 4451) | train loss: 0.007552 | lr: 0.000523\n",
            "epoch: 5 (step: 4451) | valid_loss: 0.882434\n",
            "epoch: 5 (step: 4461) | train loss: 0.014218 | lr: 0.000522\n",
            "epoch: 5 (step: 4461) | valid_loss: 0.879272\n",
            "epoch: 5 (step: 4471) | train loss: 0.011340 | lr: 0.000521\n",
            "epoch: 5 (step: 4471) | valid_loss: 0.878522\n",
            "epoch: 5 (step: 4481) | train loss: 0.007337 | lr: 0.000520\n",
            "epoch: 5 (step: 4481) | valid_loss: 0.876319\n",
            "epoch: 5 (step: 4491) | train loss: 0.008080 | lr: 0.000519\n",
            "epoch: 5 (step: 4491) | valid_loss: 0.874593\n",
            "epoch: 5 (step: 4501) | train loss: 0.006535 | lr: 0.000518\n",
            "epoch: 5 (step: 4501) | valid_loss: 0.875094\n",
            "epoch: 5 (step: 4511) | train loss: 0.008626 | lr: 0.000517\n",
            "epoch: 5 (step: 4511) | valid_loss: 0.878515\n",
            "epoch: 5 (step: 4521) | train loss: 0.009350 | lr: 0.000516\n",
            "epoch: 5 (step: 4521) | valid_loss: 0.879002\n",
            "epoch: 5 (step: 4531) | train loss: 0.010103 | lr: 0.000515\n",
            "epoch: 5 (step: 4531) | valid_loss: 0.886079\n",
            "epoch: 5 (step: 4541) | train loss: 0.009699 | lr: 0.000514\n",
            "epoch: 5 (step: 4541) | valid_loss: 0.890056\n",
            "epoch: 5 (step: 4551) | train loss: 0.008991 | lr: 0.000513\n",
            "epoch: 5 (step: 4551) | valid_loss: 0.889070\n",
            "epoch: 5 (step: 4561) | train loss: 0.009912 | lr: 0.000512\n",
            "epoch: 5 (step: 4561) | valid_loss: 0.889363\n",
            "epoch: 5 (step: 4571) | train loss: 0.008612 | lr: 0.000511\n",
            "epoch: 5 (step: 4571) | valid_loss: 0.889368\n",
            "epoch: 5 (step: 4581) | train loss: 0.008942 | lr: 0.000510\n",
            "epoch: 5 (step: 4581) | valid_loss: 0.885913\n",
            "epoch: 5 (step: 4591) | train loss: 0.008946 | lr: 0.000508\n",
            "epoch: 5 (step: 4591) | valid_loss: 0.885419\n",
            "epoch: 5 (step: 4601) | train loss: 0.008851 | lr: 0.000507\n",
            "epoch: 5 (step: 4601) | valid_loss: 0.885414\n",
            "epoch: 5 (step: 4611) | train loss: 0.010187 | lr: 0.000506\n",
            "epoch: 5 (step: 4611) | valid_loss: 0.883324\n",
            "epoch: 5 (step: 4621) | train loss: 0.006710 | lr: 0.000505\n",
            "epoch: 5 (step: 4621) | valid_loss: 0.883713\n",
            "epoch: 5 (step: 4631) | train loss: 0.005087 | lr: 0.000504\n",
            "epoch: 5 (step: 4631) | valid_loss: 0.883414\n",
            "epoch: 5 (step: 4641) | train loss: 0.006703 | lr: 0.000503\n",
            "epoch: 5 (step: 4641) | valid_loss: 0.883087\n",
            "epoch: 5 (step: 4651) | train loss: 0.005936 | lr: 0.000502\n",
            "epoch: 5 (step: 4651) | valid_loss: 0.880413\n",
            "epoch: 5 (step: 4661) | train loss: 0.012207 | lr: 0.000501\n",
            "epoch: 5 (step: 4661) | valid_loss: 0.880632\n",
            "epoch: 5 (step: 4671) | train loss: 0.006904 | lr: 0.000500\n",
            "epoch: 5 (step: 4671) | valid_loss: 0.881338\n",
            "epoch: 6 (step: 4681) | train loss: 0.009912 | lr: 0.000499\n",
            "epoch: 6 (step: 4681) | valid_loss: 0.880105\n",
            "epoch: 6 (step: 4691) | train loss: 0.008244 | lr: 0.000498\n",
            "epoch: 6 (step: 4691) | valid_loss: 0.879614\n",
            "epoch: 6 (step: 4701) | train loss: 0.008720 | lr: 0.000497\n",
            "epoch: 6 (step: 4701) | valid_loss: 0.879825\n",
            "epoch: 6 (step: 4711) | train loss: 0.008847 | lr: 0.000496\n",
            "epoch: 6 (step: 4711) | valid_loss: 0.880066\n",
            "epoch: 6 (step: 4721) | train loss: 0.005258 | lr: 0.000495\n",
            "epoch: 6 (step: 4721) | valid_loss: 0.881471\n",
            "epoch: 6 (step: 4731) | train loss: 0.009354 | lr: 0.000493\n",
            "epoch: 6 (step: 4731) | valid_loss: 0.882455\n",
            "epoch: 6 (step: 4741) | train loss: 0.009750 | lr: 0.000492\n",
            "epoch: 6 (step: 4741) | valid_loss: 0.883679\n",
            "epoch: 6 (step: 4751) | train loss: 0.007854 | lr: 0.000491\n",
            "epoch: 6 (step: 4751) | valid_loss: 0.882966\n",
            "epoch: 6 (step: 4761) | train loss: 0.005215 | lr: 0.000490\n",
            "epoch: 6 (step: 4761) | valid_loss: 0.884436\n",
            "epoch: 6 (step: 4771) | train loss: 0.005283 | lr: 0.000489\n",
            "epoch: 6 (step: 4771) | valid_loss: 0.883203\n",
            "epoch: 6 (step: 4781) | train loss: 0.008577 | lr: 0.000488\n",
            "epoch: 6 (step: 4781) | valid_loss: 0.882460\n",
            "epoch: 6 (step: 4791) | train loss: 0.007642 | lr: 0.000487\n",
            "epoch: 6 (step: 4791) | valid_loss: 0.882715\n",
            "epoch: 6 (step: 4801) | train loss: 0.008606 | lr: 0.000486\n",
            "epoch: 6 (step: 4801) | valid_loss: 0.886614\n",
            "epoch: 6 (step: 4811) | train loss: 0.007510 | lr: 0.000485\n",
            "epoch: 6 (step: 4811) | valid_loss: 0.888580\n",
            "epoch: 6 (step: 4821) | train loss: 0.009146 | lr: 0.000484\n",
            "epoch: 6 (step: 4821) | valid_loss: 0.889525\n",
            "epoch: 6 (step: 4831) | train loss: 0.005795 | lr: 0.000483\n",
            "epoch: 6 (step: 4831) | valid_loss: 0.890020\n",
            "epoch: 6 (step: 4841) | train loss: 0.007443 | lr: 0.000482\n",
            "epoch: 6 (step: 4841) | valid_loss: 0.890746\n",
            "epoch: 6 (step: 4851) | train loss: 0.014709 | lr: 0.000481\n",
            "epoch: 6 (step: 4851) | valid_loss: 0.889539\n",
            "epoch: 6 (step: 4861) | train loss: 0.009248 | lr: 0.000480\n",
            "epoch: 6 (step: 4861) | valid_loss: 0.888696\n",
            "epoch: 6 (step: 4871) | train loss: 0.005756 | lr: 0.000478\n",
            "epoch: 6 (step: 4871) | valid_loss: 0.888754\n",
            "epoch: 6 (step: 4881) | train loss: 0.008775 | lr: 0.000477\n",
            "epoch: 6 (step: 4881) | valid_loss: 0.888905\n",
            "epoch: 6 (step: 4891) | train loss: 0.008377 | lr: 0.000476\n",
            "epoch: 6 (step: 4891) | valid_loss: 0.888342\n",
            "epoch: 6 (step: 4901) | train loss: 0.007854 | lr: 0.000475\n",
            "epoch: 6 (step: 4901) | valid_loss: 0.888087\n",
            "epoch: 6 (step: 4911) | train loss: 0.008116 | lr: 0.000474\n",
            "epoch: 6 (step: 4911) | valid_loss: 0.890287\n",
            "epoch: 6 (step: 4921) | train loss: 0.008527 | lr: 0.000473\n",
            "epoch: 6 (step: 4921) | valid_loss: 0.889063\n",
            "epoch: 6 (step: 4931) | train loss: 0.007051 | lr: 0.000472\n",
            "epoch: 6 (step: 4931) | valid_loss: 0.889544\n",
            "epoch: 6 (step: 4941) | train loss: 0.006678 | lr: 0.000471\n",
            "epoch: 6 (step: 4941) | valid_loss: 0.887108\n",
            "epoch: 6 (step: 4951) | train loss: 0.007950 | lr: 0.000470\n",
            "epoch: 6 (step: 4951) | valid_loss: 0.886372\n",
            "epoch: 6 (step: 4961) | train loss: 0.006781 | lr: 0.000469\n",
            "epoch: 6 (step: 4961) | valid_loss: 0.886601\n",
            "epoch: 6 (step: 4971) | train loss: 0.007107 | lr: 0.000468\n",
            "epoch: 6 (step: 4971) | valid_loss: 0.885879\n",
            "epoch: 6 (step: 4981) | train loss: 0.007874 | lr: 0.000467\n",
            "epoch: 6 (step: 4981) | valid_loss: 0.884873\n",
            "epoch: 6 (step: 4991) | train loss: 0.010777 | lr: 0.000466\n",
            "epoch: 6 (step: 4991) | valid_loss: 0.886072\n",
            "epoch: 6 (step: 5001) | train loss: 0.007492 | lr: 0.000465\n",
            "epoch: 6 (step: 5001) | valid_loss: 0.889464\n",
            "epoch: 6 (step: 5011) | train loss: 0.006503 | lr: 0.000463\n",
            "epoch: 6 (step: 5011) | valid_loss: 0.890461\n",
            "epoch: 6 (step: 5021) | train loss: 0.008485 | lr: 0.000462\n",
            "epoch: 6 (step: 5021) | valid_loss: 0.891948\n",
            "epoch: 6 (step: 5031) | train loss: 0.011360 | lr: 0.000461\n",
            "epoch: 6 (step: 5031) | valid_loss: 0.890957\n",
            "epoch: 6 (step: 5041) | train loss: 0.008522 | lr: 0.000460\n",
            "epoch: 6 (step: 5041) | valid_loss: 0.892195\n",
            "epoch: 6 (step: 5051) | train loss: 0.010724 | lr: 0.000459\n",
            "epoch: 6 (step: 5051) | valid_loss: 0.890766\n",
            "epoch: 6 (step: 5061) | train loss: 0.008429 | lr: 0.000458\n",
            "epoch: 6 (step: 5061) | valid_loss: 0.891259\n",
            "epoch: 6 (step: 5071) | train loss: 0.008107 | lr: 0.000457\n",
            "epoch: 6 (step: 5071) | valid_loss: 0.892203\n",
            "epoch: 6 (step: 5081) | train loss: 0.008321 | lr: 0.000456\n",
            "epoch: 6 (step: 5081) | valid_loss: 0.892167\n",
            "epoch: 6 (step: 5091) | train loss: 0.006665 | lr: 0.000455\n",
            "epoch: 6 (step: 5091) | valid_loss: 0.892405\n",
            "epoch: 6 (step: 5101) | train loss: 0.006930 | lr: 0.000454\n",
            "epoch: 6 (step: 5101) | valid_loss: 0.891676\n",
            "epoch: 6 (step: 5111) | train loss: 0.008493 | lr: 0.000453\n",
            "epoch: 6 (step: 5111) | valid_loss: 0.891183\n",
            "epoch: 6 (step: 5121) | train loss: 0.005136 | lr: 0.000452\n",
            "epoch: 6 (step: 5121) | valid_loss: 0.891429\n",
            "epoch: 6 (step: 5131) | train loss: 0.009806 | lr: 0.000451\n",
            "epoch: 6 (step: 5131) | valid_loss: 0.891182\n",
            "epoch: 6 (step: 5141) | train loss: 0.004825 | lr: 0.000450\n",
            "epoch: 6 (step: 5141) | valid_loss: 0.891168\n",
            "epoch: 6 (step: 5151) | train loss: 0.005532 | lr: 0.000449\n",
            "epoch: 6 (step: 5151) | valid_loss: 0.891157\n",
            "epoch: 6 (step: 5161) | train loss: 0.004826 | lr: 0.000447\n",
            "epoch: 6 (step: 5161) | valid_loss: 0.890653\n",
            "epoch: 6 (step: 5171) | train loss: 0.007433 | lr: 0.000446\n",
            "epoch: 6 (step: 5171) | valid_loss: 0.891381\n",
            "epoch: 6 (step: 5181) | train loss: 0.005948 | lr: 0.000445\n",
            "epoch: 6 (step: 5181) | valid_loss: 0.892838\n",
            "epoch: 6 (step: 5191) | train loss: 0.006283 | lr: 0.000444\n",
            "epoch: 6 (step: 5191) | valid_loss: 0.891861\n",
            "epoch: 6 (step: 5201) | train loss: 0.004480 | lr: 0.000443\n",
            "epoch: 6 (step: 5201) | valid_loss: 0.891387\n",
            "epoch: 6 (step: 5211) | train loss: 0.006445 | lr: 0.000442\n",
            "epoch: 6 (step: 5211) | valid_loss: 0.890880\n",
            "epoch: 6 (step: 5221) | train loss: 0.007761 | lr: 0.000441\n",
            "epoch: 6 (step: 5221) | valid_loss: 0.890640\n",
            "epoch: 6 (step: 5231) | train loss: 0.005887 | lr: 0.000440\n",
            "epoch: 6 (step: 5231) | valid_loss: 0.892582\n",
            "epoch: 6 (step: 5241) | train loss: 0.005969 | lr: 0.000439\n",
            "epoch: 6 (step: 5241) | valid_loss: 0.891124\n",
            "epoch: 6 (step: 5251) | train loss: 0.005510 | lr: 0.000438\n",
            "epoch: 6 (step: 5251) | valid_loss: 0.891100\n",
            "epoch: 6 (step: 5261) | train loss: 0.006128 | lr: 0.000437\n",
            "epoch: 6 (step: 5261) | valid_loss: 0.889653\n",
            "epoch: 6 (step: 5271) | train loss: 0.006356 | lr: 0.000436\n",
            "epoch: 6 (step: 5271) | valid_loss: 0.890134\n",
            "epoch: 6 (step: 5281) | train loss: 0.008958 | lr: 0.000435\n",
            "epoch: 6 (step: 5281) | valid_loss: 0.889887\n",
            "epoch: 6 (step: 5291) | train loss: 0.005279 | lr: 0.000434\n",
            "epoch: 6 (step: 5291) | valid_loss: 0.889413\n",
            "epoch: 6 (step: 5301) | train loss: 0.008820 | lr: 0.000432\n",
            "epoch: 6 (step: 5301) | valid_loss: 0.888916\n",
            "epoch: 6 (step: 5311) | train loss: 0.005719 | lr: 0.000431\n",
            "epoch: 6 (step: 5311) | valid_loss: 0.888660\n",
            "epoch: 6 (step: 5321) | train loss: 0.007240 | lr: 0.000430\n",
            "epoch: 6 (step: 5321) | valid_loss: 0.887937\n",
            "epoch: 6 (step: 5331) | train loss: 0.008707 | lr: 0.000429\n",
            "epoch: 6 (step: 5331) | valid_loss: 0.887926\n",
            "epoch: 6 (step: 5341) | train loss: 0.003728 | lr: 0.000428\n",
            "epoch: 6 (step: 5341) | valid_loss: 0.888174\n",
            "epoch: 6 (step: 5351) | train loss: 0.006499 | lr: 0.000427\n",
            "epoch: 6 (step: 5351) | valid_loss: 0.888406\n",
            "epoch: 6 (step: 5361) | train loss: 0.008299 | lr: 0.000426\n",
            "epoch: 6 (step: 5361) | valid_loss: 0.889138\n",
            "epoch: 6 (step: 5371) | train loss: 0.003654 | lr: 0.000425\n",
            "epoch: 6 (step: 5371) | valid_loss: 0.889386\n",
            "epoch: 6 (step: 5381) | train loss: 0.005244 | lr: 0.000424\n",
            "epoch: 6 (step: 5381) | valid_loss: 0.887689\n",
            "epoch: 6 (step: 5391) | train loss: 0.006805 | lr: 0.000423\n",
            "epoch: 6 (step: 5391) | valid_loss: 0.888175\n",
            "epoch: 6 (step: 5401) | train loss: 0.006409 | lr: 0.000422\n",
            "epoch: 6 (step: 5401) | valid_loss: 0.888423\n",
            "epoch: 6 (step: 5411) | train loss: 0.008388 | lr: 0.000421\n",
            "epoch: 6 (step: 5411) | valid_loss: 0.887209\n",
            "epoch: 6 (step: 5421) | train loss: 0.006815 | lr: 0.000420\n",
            "epoch: 6 (step: 5421) | valid_loss: 0.888394\n",
            "epoch: 6 (step: 5431) | train loss: 0.006898 | lr: 0.000419\n",
            "epoch: 6 (step: 5431) | valid_loss: 0.889366\n",
            "epoch: 6 (step: 5441) | train loss: 0.008932 | lr: 0.000417\n",
            "epoch: 6 (step: 5441) | valid_loss: 0.891309\n",
            "epoch: 6 (step: 5451) | train loss: 0.007092 | lr: 0.000416\n",
            "epoch: 6 (step: 5451) | valid_loss: 0.890573\n",
            "epoch: 6 (step: 5461) | train loss: 0.005336 | lr: 0.000415\n",
            "epoch: 6 (step: 5461) | valid_loss: 0.891317\n",
            "epoch: 6 (step: 5471) | train loss: 0.007094 | lr: 0.000414\n",
            "epoch: 6 (step: 5471) | valid_loss: 0.891785\n",
            "epoch: 6 (step: 5481) | train loss: 0.008013 | lr: 0.000413\n",
            "epoch: 6 (step: 5481) | valid_loss: 0.891067\n",
            "epoch: 6 (step: 5491) | train loss: 0.005853 | lr: 0.000412\n",
            "epoch: 6 (step: 5491) | valid_loss: 0.890357\n",
            "epoch: 6 (step: 5501) | train loss: 0.006528 | lr: 0.000411\n",
            "epoch: 6 (step: 5501) | valid_loss: 0.889618\n",
            "epoch: 6 (step: 5511) | train loss: 0.007505 | lr: 0.000410\n",
            "epoch: 6 (step: 5511) | valid_loss: 0.889869\n",
            "epoch: 6 (step: 5521) | train loss: 0.010181 | lr: 0.000409\n",
            "epoch: 6 (step: 5521) | valid_loss: 0.889871\n",
            "epoch: 6 (step: 5531) | train loss: 0.006567 | lr: 0.000408\n",
            "epoch: 6 (step: 5531) | valid_loss: 0.889373\n",
            "epoch: 6 (step: 5541) | train loss: 0.005544 | lr: 0.000407\n",
            "epoch: 6 (step: 5541) | valid_loss: 0.889381\n",
            "epoch: 6 (step: 5551) | train loss: 0.009113 | lr: 0.000406\n",
            "epoch: 6 (step: 5551) | valid_loss: 0.888402\n",
            "epoch: 6 (step: 5561) | train loss: 0.006297 | lr: 0.000405\n",
            "epoch: 6 (step: 5561) | valid_loss: 0.887672\n",
            "epoch: 6 (step: 5571) | train loss: 0.006882 | lr: 0.000404\n",
            "epoch: 6 (step: 5571) | valid_loss: 0.887669\n",
            "epoch: 6 (step: 5581) | train loss: 0.006328 | lr: 0.000402\n",
            "epoch: 6 (step: 5581) | valid_loss: 0.888158\n",
            "epoch: 6 (step: 5591) | train loss: 0.005669 | lr: 0.000401\n",
            "epoch: 6 (step: 5591) | valid_loss: 0.887658\n",
            "epoch: 6 (step: 5601) | train loss: 0.006886 | lr: 0.000400\n",
            "epoch: 6 (step: 5601) | valid_loss: 0.887416\n",
            "epoch: 7 (step: 5611) | train loss: 0.007646 | lr: 0.000399\n",
            "epoch: 7 (step: 5611) | valid_loss: 0.887165\n",
            "epoch: 7 (step: 5621) | train loss: 0.004774 | lr: 0.000398\n",
            "epoch: 7 (step: 5621) | valid_loss: 0.887408\n",
            "epoch: 7 (step: 5631) | train loss: 0.006256 | lr: 0.000397\n",
            "epoch: 7 (step: 5631) | valid_loss: 0.886672\n",
            "epoch: 7 (step: 5641) | train loss: 0.005743 | lr: 0.000396\n",
            "epoch: 7 (step: 5641) | valid_loss: 0.887653\n",
            "epoch: 7 (step: 5651) | train loss: 0.007449 | lr: 0.000395\n",
            "epoch: 7 (step: 5651) | valid_loss: 0.885698\n",
            "epoch: 7 (step: 5661) | train loss: 0.007233 | lr: 0.000394\n",
            "epoch: 7 (step: 5661) | valid_loss: 0.885692\n",
            "epoch: 7 (step: 5671) | train loss: 0.005276 | lr: 0.000393\n",
            "epoch: 7 (step: 5671) | valid_loss: 0.886438\n",
            "epoch: 7 (step: 5681) | train loss: 0.008273 | lr: 0.000392\n",
            "epoch: 7 (step: 5681) | valid_loss: 0.887392\n",
            "epoch: 7 (step: 5691) | train loss: 0.008030 | lr: 0.000391\n",
            "epoch: 7 (step: 5691) | valid_loss: 0.887624\n",
            "epoch: 7 (step: 5701) | train loss: 0.008037 | lr: 0.000390\n",
            "epoch: 7 (step: 5701) | valid_loss: 0.888108\n",
            "epoch: 7 (step: 5711) | train loss: 0.004704 | lr: 0.000389\n",
            "epoch: 7 (step: 5711) | valid_loss: 0.888843\n",
            "epoch: 7 (step: 5721) | train loss: 0.006344 | lr: 0.000387\n",
            "epoch: 7 (step: 5721) | valid_loss: 0.887375\n",
            "epoch: 7 (step: 5731) | train loss: 0.007238 | lr: 0.000386\n",
            "epoch: 7 (step: 5731) | valid_loss: 0.887626\n",
            "epoch: 7 (step: 5741) | train loss: 0.005860 | lr: 0.000385\n",
            "epoch: 7 (step: 5741) | valid_loss: 0.887151\n",
            "epoch: 7 (step: 5751) | train loss: 0.006541 | lr: 0.000384\n",
            "epoch: 7 (step: 5751) | valid_loss: 0.887155\n",
            "epoch: 7 (step: 5761) | train loss: 0.005519 | lr: 0.000383\n",
            "epoch: 7 (step: 5761) | valid_loss: 0.888611\n",
            "epoch: 7 (step: 5771) | train loss: 0.007225 | lr: 0.000382\n",
            "epoch: 7 (step: 5771) | valid_loss: 0.888359\n",
            "epoch: 7 (step: 5781) | train loss: 0.006945 | lr: 0.000381\n",
            "epoch: 7 (step: 5781) | valid_loss: 0.887872\n",
            "epoch: 7 (step: 5791) | train loss: 0.008267 | lr: 0.000380\n",
            "epoch: 7 (step: 5791) | valid_loss: 0.888590\n",
            "epoch: 7 (step: 5801) | train loss: 0.004991 | lr: 0.000379\n",
            "epoch: 7 (step: 5801) | valid_loss: 0.888344\n",
            "epoch: 7 (step: 5811) | train loss: 0.005701 | lr: 0.000378\n",
            "epoch: 7 (step: 5811) | valid_loss: 0.888109\n",
            "epoch: 7 (step: 5821) | train loss: 0.006520 | lr: 0.000377\n",
            "epoch: 7 (step: 5821) | valid_loss: 0.887867\n",
            "epoch: 7 (step: 5831) | train loss: 0.006625 | lr: 0.000376\n",
            "epoch: 7 (step: 5831) | valid_loss: 0.887135\n",
            "epoch: 7 (step: 5841) | train loss: 0.005670 | lr: 0.000375\n",
            "epoch: 7 (step: 5841) | valid_loss: 0.887630\n",
            "epoch: 7 (step: 5851) | train loss: 0.004653 | lr: 0.000374\n",
            "epoch: 7 (step: 5851) | valid_loss: 0.887137\n",
            "epoch: 7 (step: 5861) | train loss: 0.006444 | lr: 0.000372\n",
            "epoch: 7 (step: 5861) | valid_loss: 0.887140\n",
            "epoch: 7 (step: 5871) | train loss: 0.005531 | lr: 0.000371\n",
            "epoch: 7 (step: 5871) | valid_loss: 0.887894\n",
            "epoch: 7 (step: 5881) | train loss: 0.007957 | lr: 0.000370\n",
            "epoch: 7 (step: 5881) | valid_loss: 0.888356\n",
            "epoch: 7 (step: 5891) | train loss: 0.006493 | lr: 0.000369\n",
            "epoch: 7 (step: 5891) | valid_loss: 0.889103\n",
            "epoch: 7 (step: 5901) | train loss: 0.007356 | lr: 0.000368\n",
            "epoch: 7 (step: 5901) | valid_loss: 0.888377\n",
            "epoch: 7 (step: 5911) | train loss: 0.005773 | lr: 0.000367\n",
            "epoch: 7 (step: 5911) | valid_loss: 0.888612\n",
            "epoch: 7 (step: 5921) | train loss: 0.008085 | lr: 0.000366\n",
            "epoch: 7 (step: 5921) | valid_loss: 0.889085\n",
            "epoch: 7 (step: 5931) | train loss: 0.006712 | lr: 0.000365\n",
            "epoch: 7 (step: 5931) | valid_loss: 0.889332\n",
            "epoch: 7 (step: 5941) | train loss: 0.005510 | lr: 0.000364\n",
            "epoch: 7 (step: 5941) | valid_loss: 0.890067\n",
            "epoch: 7 (step: 5951) | train loss: 0.007058 | lr: 0.000363\n",
            "epoch: 7 (step: 5951) | valid_loss: 0.890298\n",
            "epoch: 7 (step: 5961) | train loss: 0.005552 | lr: 0.000362\n",
            "epoch: 7 (step: 5961) | valid_loss: 0.891041\n",
            "epoch: 7 (step: 5971) | train loss: 0.009937 | lr: 0.000361\n",
            "epoch: 7 (step: 5971) | valid_loss: 0.891760\n",
            "epoch: 7 (step: 5981) | train loss: 0.005389 | lr: 0.000360\n",
            "epoch: 7 (step: 5981) | valid_loss: 0.891509\n",
            "epoch: 7 (step: 5991) | train loss: 0.006677 | lr: 0.000359\n",
            "epoch: 7 (step: 5991) | valid_loss: 0.891747\n",
            "epoch: 7 (step: 6001) | train loss: 0.009244 | lr: 0.000357\n",
            "epoch: 7 (step: 6001) | valid_loss: 0.892716\n",
            "epoch: 7 (step: 6011) | train loss: 0.005996 | lr: 0.000356\n",
            "epoch: 7 (step: 6011) | valid_loss: 0.893693\n",
            "epoch: 7 (step: 6021) | train loss: 0.007991 | lr: 0.000355\n",
            "epoch: 7 (step: 6021) | valid_loss: 0.894660\n",
            "epoch: 7 (step: 6031) | train loss: 0.009390 | lr: 0.000354\n",
            "epoch: 7 (step: 6031) | valid_loss: 0.895874\n",
            "epoch: 7 (step: 6041) | train loss: 0.007202 | lr: 0.000353\n",
            "epoch: 7 (step: 6041) | valid_loss: 0.895378\n",
            "epoch: 7 (step: 6051) | train loss: 0.004744 | lr: 0.000352\n",
            "epoch: 7 (step: 6051) | valid_loss: 0.895615\n",
            "epoch: 7 (step: 6061) | train loss: 0.005502 | lr: 0.000351\n",
            "epoch: 7 (step: 6061) | valid_loss: 0.895611\n",
            "epoch: 7 (step: 6071) | train loss: 0.007297 | lr: 0.000350\n",
            "epoch: 7 (step: 6071) | valid_loss: 0.895841\n",
            "epoch: 7 (step: 6081) | train loss: 0.008809 | lr: 0.000349\n",
            "epoch: 7 (step: 6081) | valid_loss: 0.895120\n",
            "epoch: 7 (step: 6091) | train loss: 0.007526 | lr: 0.000348\n",
            "epoch: 7 (step: 6091) | valid_loss: 0.892921\n",
            "epoch: 7 (step: 6101) | train loss: 0.008536 | lr: 0.000347\n",
            "epoch: 7 (step: 6101) | valid_loss: 0.893906\n",
            "epoch: 7 (step: 6111) | train loss: 0.008449 | lr: 0.000346\n",
            "epoch: 7 (step: 6111) | valid_loss: 0.897063\n",
            "epoch: 7 (step: 6121) | train loss: 0.004641 | lr: 0.000345\n",
            "epoch: 7 (step: 6121) | valid_loss: 0.897061\n",
            "epoch: 7 (step: 6131) | train loss: 0.008693 | lr: 0.000344\n",
            "epoch: 7 (step: 6131) | valid_loss: 0.897321\n",
            "epoch: 7 (step: 6141) | train loss: 0.006532 | lr: 0.000343\n",
            "epoch: 7 (step: 6141) | valid_loss: 0.898041\n",
            "epoch: 7 (step: 6151) | train loss: 0.006770 | lr: 0.000341\n",
            "epoch: 7 (step: 6151) | valid_loss: 0.897804\n",
            "epoch: 7 (step: 6161) | train loss: 0.007980 | lr: 0.000340\n",
            "epoch: 7 (step: 6161) | valid_loss: 0.897067\n",
            "epoch: 7 (step: 6171) | train loss: 0.006496 | lr: 0.000339\n",
            "epoch: 7 (step: 6171) | valid_loss: 0.897796\n",
            "epoch: 7 (step: 6181) | train loss: 0.006368 | lr: 0.000338\n",
            "epoch: 7 (step: 6181) | valid_loss: 0.897549\n",
            "epoch: 7 (step: 6191) | train loss: 0.006903 | lr: 0.000337\n",
            "epoch: 7 (step: 6191) | valid_loss: 0.898527\n",
            "epoch: 7 (step: 6201) | train loss: 0.007072 | lr: 0.000336\n",
            "epoch: 7 (step: 6201) | valid_loss: 0.899978\n",
            "epoch: 7 (step: 6211) | train loss: 0.007125 | lr: 0.000335\n",
            "epoch: 7 (step: 6211) | valid_loss: 0.898773\n",
            "epoch: 7 (step: 6221) | train loss: 0.007571 | lr: 0.000334\n",
            "epoch: 7 (step: 6221) | valid_loss: 0.899497\n",
            "epoch: 7 (step: 6231) | train loss: 0.005097 | lr: 0.000333\n",
            "epoch: 7 (step: 6231) | valid_loss: 0.901191\n",
            "epoch: 7 (step: 6241) | train loss: 0.005248 | lr: 0.000332\n",
            "epoch: 7 (step: 6241) | valid_loss: 0.900698\n",
            "epoch: 7 (step: 6251) | train loss: 0.008095 | lr: 0.000331\n",
            "epoch: 7 (step: 6251) | valid_loss: 0.900464\n",
            "epoch: 7 (step: 6261) | train loss: 0.007246 | lr: 0.000330\n",
            "epoch: 7 (step: 6261) | valid_loss: 0.900704\n",
            "epoch: 7 (step: 6271) | train loss: 0.010458 | lr: 0.000329\n",
            "epoch: 7 (step: 6271) | valid_loss: 0.898284\n",
            "epoch: 7 (step: 6281) | train loss: 0.005470 | lr: 0.000328\n",
            "epoch: 7 (step: 6281) | valid_loss: 0.898762\n",
            "epoch: 7 (step: 6291) | train loss: 0.005900 | lr: 0.000326\n",
            "epoch: 7 (step: 6291) | valid_loss: 0.898279\n",
            "epoch: 7 (step: 6301) | train loss: 0.006120 | lr: 0.000325\n",
            "epoch: 7 (step: 6301) | valid_loss: 0.897287\n",
            "epoch: 7 (step: 6311) | train loss: 0.007870 | lr: 0.000324\n",
            "epoch: 7 (step: 6311) | valid_loss: 0.898268\n",
            "epoch: 7 (step: 6321) | train loss: 0.005399 | lr: 0.000323\n",
            "epoch: 7 (step: 6321) | valid_loss: 0.898022\n",
            "epoch: 7 (step: 6331) | train loss: 0.006514 | lr: 0.000322\n",
            "epoch: 7 (step: 6331) | valid_loss: 0.897769\n",
            "epoch: 7 (step: 6341) | train loss: 0.007621 | lr: 0.000321\n",
            "epoch: 7 (step: 6341) | valid_loss: 0.897536\n",
            "epoch: 7 (step: 6351) | train loss: 0.003387 | lr: 0.000320\n",
            "epoch: 7 (step: 6351) | valid_loss: 0.896800\n",
            "epoch: 7 (step: 6361) | train loss: 0.007088 | lr: 0.000319\n",
            "epoch: 7 (step: 6361) | valid_loss: 0.897542\n",
            "epoch: 7 (step: 6371) | train loss: 0.006243 | lr: 0.000318\n",
            "epoch: 7 (step: 6371) | valid_loss: 0.896808\n",
            "epoch: 7 (step: 6381) | train loss: 0.006667 | lr: 0.000317\n",
            "epoch: 7 (step: 6381) | valid_loss: 0.896313\n",
            "epoch: 7 (step: 6391) | train loss: 0.005710 | lr: 0.000316\n",
            "epoch: 7 (step: 6391) | valid_loss: 0.896063\n",
            "epoch: 7 (step: 6401) | train loss: 0.005681 | lr: 0.000315\n",
            "epoch: 7 (step: 6401) | valid_loss: 0.896809\n",
            "epoch: 7 (step: 6411) | train loss: 0.005340 | lr: 0.000314\n",
            "epoch: 7 (step: 6411) | valid_loss: 0.896066\n",
            "epoch: 7 (step: 6421) | train loss: 0.007703 | lr: 0.000313\n",
            "epoch: 7 (step: 6421) | valid_loss: 0.897757\n",
            "epoch: 7 (step: 6431) | train loss: 0.006125 | lr: 0.000311\n",
            "epoch: 7 (step: 6431) | valid_loss: 0.896549\n",
            "epoch: 7 (step: 6441) | train loss: 0.007729 | lr: 0.000310\n",
            "epoch: 7 (step: 6441) | valid_loss: 0.896305\n",
            "epoch: 7 (step: 6451) | train loss: 0.007989 | lr: 0.000309\n",
            "epoch: 7 (step: 6451) | valid_loss: 0.895087\n",
            "epoch: 7 (step: 6461) | train loss: 0.007150 | lr: 0.000308\n",
            "epoch: 7 (step: 6461) | valid_loss: 0.894594\n",
            "epoch: 7 (step: 6471) | train loss: 0.007022 | lr: 0.000307\n",
            "epoch: 7 (step: 6471) | valid_loss: 0.896304\n",
            "epoch: 7 (step: 6481) | train loss: 0.007694 | lr: 0.000306\n",
            "epoch: 7 (step: 6481) | valid_loss: 0.894369\n",
            "epoch: 7 (step: 6491) | train loss: 0.007227 | lr: 0.000305\n",
            "epoch: 7 (step: 6491) | valid_loss: 0.893403\n",
            "epoch: 7 (step: 6501) | train loss: 0.005598 | lr: 0.000304\n",
            "epoch: 7 (step: 6501) | valid_loss: 0.892671\n",
            "epoch: 7 (step: 6511) | train loss: 0.006987 | lr: 0.000303\n",
            "epoch: 7 (step: 6511) | valid_loss: 0.892182\n",
            "epoch: 7 (step: 6521) | train loss: 0.006084 | lr: 0.000302\n",
            "epoch: 7 (step: 6521) | valid_loss: 0.892907\n",
            "epoch: 7 (step: 6531) | train loss: 0.004076 | lr: 0.000301\n",
            "epoch: 7 (step: 6531) | valid_loss: 0.892436\n",
            "epoch: 7 (step: 6541) | train loss: 0.005997 | lr: 0.000300\n",
            "epoch: 7 (step: 6541) | valid_loss: 0.892677\n",
            "epoch: 8 (step: 6551) | train loss: 0.005817 | lr: 0.000299\n",
            "epoch: 8 (step: 6551) | valid_loss: 0.892430\n",
            "epoch: 8 (step: 6561) | train loss: 0.006575 | lr: 0.000298\n",
            "epoch: 8 (step: 6561) | valid_loss: 0.892671\n",
            "epoch: 8 (step: 6571) | train loss: 0.007548 | lr: 0.000296\n",
            "epoch: 8 (step: 6571) | valid_loss: 0.893880\n",
            "epoch: 8 (step: 6581) | train loss: 0.006313 | lr: 0.000295\n",
            "epoch: 8 (step: 6581) | valid_loss: 0.892661\n",
            "epoch: 8 (step: 6591) | train loss: 0.005241 | lr: 0.000294\n",
            "epoch: 8 (step: 6591) | valid_loss: 0.892906\n",
            "epoch: 8 (step: 6601) | train loss: 0.005840 | lr: 0.000293\n",
            "epoch: 8 (step: 6601) | valid_loss: 0.893391\n",
            "epoch: 8 (step: 6611) | train loss: 0.008154 | lr: 0.000292\n",
            "epoch: 8 (step: 6611) | valid_loss: 0.894605\n",
            "epoch: 8 (step: 6621) | train loss: 0.003514 | lr: 0.000291\n",
            "epoch: 8 (step: 6621) | valid_loss: 0.895334\n",
            "epoch: 8 (step: 6631) | train loss: 0.007149 | lr: 0.000290\n",
            "epoch: 8 (step: 6631) | valid_loss: 0.893871\n",
            "epoch: 8 (step: 6641) | train loss: 0.007533 | lr: 0.000289\n",
            "epoch: 8 (step: 6641) | valid_loss: 0.894096\n",
            "epoch: 8 (step: 6651) | train loss: 0.007077 | lr: 0.000288\n",
            "epoch: 8 (step: 6651) | valid_loss: 0.893863\n",
            "epoch: 8 (step: 6661) | train loss: 0.008325 | lr: 0.000287\n",
            "epoch: 8 (step: 6661) | valid_loss: 0.892895\n",
            "epoch: 8 (step: 6671) | train loss: 0.007119 | lr: 0.000286\n",
            "epoch: 8 (step: 6671) | valid_loss: 0.893602\n",
            "epoch: 8 (step: 6681) | train loss: 0.005169 | lr: 0.000285\n",
            "epoch: 8 (step: 6681) | valid_loss: 0.893134\n",
            "epoch: 8 (step: 6691) | train loss: 0.004117 | lr: 0.000284\n",
            "epoch: 8 (step: 6691) | valid_loss: 0.893870\n",
            "epoch: 8 (step: 6701) | train loss: 0.006715 | lr: 0.000283\n",
            "epoch: 8 (step: 6701) | valid_loss: 0.893624\n",
            "epoch: 8 (step: 6711) | train loss: 0.006702 | lr: 0.000281\n",
            "epoch: 8 (step: 6711) | valid_loss: 0.893137\n",
            "epoch: 8 (step: 6721) | train loss: 0.005550 | lr: 0.000280\n",
            "epoch: 8 (step: 6721) | valid_loss: 0.893135\n",
            "epoch: 8 (step: 6731) | train loss: 0.006218 | lr: 0.000279\n",
            "epoch: 8 (step: 6731) | valid_loss: 0.892398\n",
            "epoch: 8 (step: 6741) | train loss: 0.007634 | lr: 0.000278\n",
            "epoch: 8 (step: 6741) | valid_loss: 0.892644\n",
            "epoch: 8 (step: 6751) | train loss: 0.007173 | lr: 0.000277\n",
            "epoch: 8 (step: 6751) | valid_loss: 0.893126\n",
            "epoch: 8 (step: 6761) | train loss: 0.005576 | lr: 0.000276\n",
            "epoch: 8 (step: 6761) | valid_loss: 0.893135\n",
            "epoch: 8 (step: 6771) | train loss: 0.006217 | lr: 0.000275\n",
            "epoch: 8 (step: 6771) | valid_loss: 0.892653\n",
            "epoch: 8 (step: 6781) | train loss: 0.004674 | lr: 0.000274\n",
            "epoch: 8 (step: 6781) | valid_loss: 0.892401\n",
            "epoch: 8 (step: 6791) | train loss: 0.005981 | lr: 0.000273\n",
            "epoch: 8 (step: 6791) | valid_loss: 0.893127\n",
            "epoch: 8 (step: 6801) | train loss: 0.007586 | lr: 0.000272\n",
            "epoch: 8 (step: 6801) | valid_loss: 0.893131\n",
            "epoch: 8 (step: 6811) | train loss: 0.007138 | lr: 0.000271\n",
            "epoch: 8 (step: 6811) | valid_loss: 0.893130\n",
            "epoch: 8 (step: 6821) | train loss: 0.008746 | lr: 0.000270\n",
            "epoch: 8 (step: 6821) | valid_loss: 0.892646\n",
            "epoch: 8 (step: 6831) | train loss: 0.004499 | lr: 0.000269\n",
            "epoch: 8 (step: 6831) | valid_loss: 0.892149\n",
            "epoch: 8 (step: 6841) | train loss: 0.009851 | lr: 0.000268\n",
            "epoch: 8 (step: 6841) | valid_loss: 0.893130\n",
            "epoch: 8 (step: 6851) | train loss: 0.010742 | lr: 0.000266\n",
            "epoch: 8 (step: 6851) | valid_loss: 0.893124\n",
            "epoch: 8 (step: 6861) | train loss: 0.004795 | lr: 0.000265\n",
            "epoch: 8 (step: 6861) | valid_loss: 0.893379\n",
            "epoch: 8 (step: 6871) | train loss: 0.006763 | lr: 0.000264\n",
            "epoch: 8 (step: 6871) | valid_loss: 0.892892\n",
            "epoch: 8 (step: 6881) | train loss: 0.005175 | lr: 0.000263\n",
            "epoch: 8 (step: 6881) | valid_loss: 0.893137\n",
            "epoch: 8 (step: 6891) | train loss: 0.006177 | lr: 0.000262\n",
            "epoch: 8 (step: 6891) | valid_loss: 0.893864\n",
            "epoch: 8 (step: 6901) | train loss: 0.006661 | lr: 0.000261\n",
            "epoch: 8 (step: 6901) | valid_loss: 0.894591\n",
            "epoch: 8 (step: 6911) | train loss: 0.006449 | lr: 0.000260\n",
            "epoch: 8 (step: 6911) | valid_loss: 0.896540\n",
            "epoch: 8 (step: 6921) | train loss: 0.006249 | lr: 0.000259\n",
            "epoch: 8 (step: 6921) | valid_loss: 0.896295\n",
            "epoch: 8 (step: 6931) | train loss: 0.005785 | lr: 0.000258\n",
            "epoch: 8 (step: 6931) | valid_loss: 0.895565\n",
            "epoch: 8 (step: 6941) | train loss: 0.006792 | lr: 0.000257\n",
            "epoch: 8 (step: 6941) | valid_loss: 0.894592\n",
            "epoch: 8 (step: 6951) | train loss: 0.004911 | lr: 0.000256\n",
            "epoch: 8 (step: 6951) | valid_loss: 0.895555\n",
            "epoch: 8 (step: 6961) | train loss: 0.007033 | lr: 0.000255\n",
            "epoch: 8 (step: 6961) | valid_loss: 0.895803\n",
            "epoch: 8 (step: 6971) | train loss: 0.005143 | lr: 0.000254\n",
            "epoch: 8 (step: 6971) | valid_loss: 0.896046\n",
            "epoch: 8 (step: 6981) | train loss: 0.005875 | lr: 0.000253\n",
            "epoch: 8 (step: 6981) | valid_loss: 0.896052\n",
            "epoch: 8 (step: 6991) | train loss: 0.005524 | lr: 0.000251\n",
            "epoch: 8 (step: 6991) | valid_loss: 0.897275\n",
            "epoch: 8 (step: 7001) | train loss: 0.007545 | lr: 0.000250\n",
            "epoch: 8 (step: 7001) | valid_loss: 0.897030\n",
            "epoch: 8 (step: 7011) | train loss: 0.004788 | lr: 0.000249\n",
            "epoch: 8 (step: 7011) | valid_loss: 0.897267\n",
            "epoch: 8 (step: 7021) | train loss: 0.007290 | lr: 0.000248\n",
            "epoch: 8 (step: 7021) | valid_loss: 0.897519\n",
            "epoch: 8 (step: 7031) | train loss: 0.005876 | lr: 0.000247\n",
            "epoch: 8 (step: 7031) | valid_loss: 0.897758\n",
            "epoch: 8 (step: 7041) | train loss: 0.006430 | lr: 0.000246\n",
            "epoch: 8 (step: 7041) | valid_loss: 0.897280\n",
            "epoch: 8 (step: 7051) | train loss: 0.007962 | lr: 0.000245\n",
            "epoch: 8 (step: 7051) | valid_loss: 0.897514\n",
            "epoch: 8 (step: 7061) | train loss: 0.003887 | lr: 0.000244\n",
            "epoch: 8 (step: 7061) | valid_loss: 0.897028\n",
            "epoch: 8 (step: 7071) | train loss: 0.004929 | lr: 0.000243\n",
            "epoch: 8 (step: 7071) | valid_loss: 0.897748\n",
            "epoch: 8 (step: 7081) | train loss: 0.007002 | lr: 0.000242\n",
            "epoch: 8 (step: 7081) | valid_loss: 0.898237\n",
            "epoch: 8 (step: 7091) | train loss: 0.006697 | lr: 0.000241\n",
            "epoch: 8 (step: 7091) | valid_loss: 0.897760\n",
            "epoch: 8 (step: 7101) | train loss: 0.005264 | lr: 0.000240\n",
            "epoch: 8 (step: 7101) | valid_loss: 0.897750\n",
            "epoch: 8 (step: 7111) | train loss: 0.006198 | lr: 0.000239\n",
            "epoch: 8 (step: 7111) | valid_loss: 0.897507\n",
            "epoch: 8 (step: 7121) | train loss: 0.009698 | lr: 0.000238\n",
            "epoch: 8 (step: 7121) | valid_loss: 0.897999\n",
            "epoch: 8 (step: 7131) | train loss: 0.005825 | lr: 0.000237\n",
            "epoch: 8 (step: 7131) | valid_loss: 0.898973\n",
            "epoch: 8 (step: 7141) | train loss: 0.005479 | lr: 0.000235\n",
            "epoch: 8 (step: 7141) | valid_loss: 0.898972\n",
            "epoch: 8 (step: 7151) | train loss: 0.005051 | lr: 0.000234\n",
            "epoch: 8 (step: 7151) | valid_loss: 0.897994\n",
            "epoch: 8 (step: 7161) | train loss: 0.005141 | lr: 0.000233\n",
            "epoch: 8 (step: 7161) | valid_loss: 0.898728\n",
            "epoch: 8 (step: 7171) | train loss: 0.005228 | lr: 0.000232\n",
            "epoch: 8 (step: 7171) | valid_loss: 0.898481\n",
            "epoch: 8 (step: 7181) | train loss: 0.007114 | lr: 0.000231\n",
            "epoch: 8 (step: 7181) | valid_loss: 0.898237\n",
            "epoch: 8 (step: 7191) | train loss: 0.007937 | lr: 0.000230\n",
            "epoch: 8 (step: 7191) | valid_loss: 0.899207\n",
            "epoch: 8 (step: 7201) | train loss: 0.008194 | lr: 0.000229\n",
            "epoch: 8 (step: 7201) | valid_loss: 0.898477\n",
            "epoch: 8 (step: 7211) | train loss: 0.005824 | lr: 0.000228\n",
            "epoch: 8 (step: 7211) | valid_loss: 0.898236\n",
            "epoch: 8 (step: 7221) | train loss: 0.004462 | lr: 0.000227\n",
            "epoch: 8 (step: 7221) | valid_loss: 0.898225\n",
            "epoch: 8 (step: 7231) | train loss: 0.007722 | lr: 0.000226\n",
            "epoch: 8 (step: 7231) | valid_loss: 0.898717\n",
            "epoch: 8 (step: 7241) | train loss: 0.006780 | lr: 0.000225\n",
            "epoch: 8 (step: 7241) | valid_loss: 0.897740\n",
            "epoch: 8 (step: 7251) | train loss: 0.006293 | lr: 0.000224\n",
            "epoch: 8 (step: 7251) | valid_loss: 0.898219\n",
            "epoch: 8 (step: 7261) | train loss: 0.005342 | lr: 0.000223\n",
            "epoch: 8 (step: 7261) | valid_loss: 0.898480\n",
            "epoch: 8 (step: 7271) | train loss: 0.003402 | lr: 0.000222\n",
            "epoch: 8 (step: 7271) | valid_loss: 0.898225\n",
            "epoch: 8 (step: 7281) | train loss: 0.006291 | lr: 0.000220\n",
            "epoch: 8 (step: 7281) | valid_loss: 0.898947\n",
            "epoch: 8 (step: 7291) | train loss: 0.006042 | lr: 0.000219\n",
            "epoch: 8 (step: 7291) | valid_loss: 0.898229\n",
            "epoch: 8 (step: 7301) | train loss: 0.005524 | lr: 0.000218\n",
            "epoch: 8 (step: 7301) | valid_loss: 0.897241\n",
            "epoch: 8 (step: 7311) | train loss: 0.007947 | lr: 0.000217\n",
            "epoch: 8 (step: 7311) | valid_loss: 0.897250\n",
            "epoch: 8 (step: 7321) | train loss: 0.005646 | lr: 0.000216\n",
            "epoch: 8 (step: 7321) | valid_loss: 0.897005\n",
            "epoch: 8 (step: 7331) | train loss: 0.006613 | lr: 0.000215\n",
            "epoch: 8 (step: 7331) | valid_loss: 0.897485\n",
            "epoch: 8 (step: 7341) | train loss: 0.007792 | lr: 0.000214\n",
            "epoch: 8 (step: 7341) | valid_loss: 0.897003\n",
            "epoch: 8 (step: 7351) | train loss: 0.006194 | lr: 0.000213\n",
            "epoch: 8 (step: 7351) | valid_loss: 0.897257\n",
            "epoch: 8 (step: 7361) | train loss: 0.007370 | lr: 0.000212\n",
            "epoch: 8 (step: 7361) | valid_loss: 0.897007\n",
            "epoch: 8 (step: 7371) | train loss: 0.007633 | lr: 0.000211\n",
            "epoch: 8 (step: 7371) | valid_loss: 0.897985\n",
            "epoch: 8 (step: 7381) | train loss: 0.005005 | lr: 0.000210\n",
            "epoch: 8 (step: 7381) | valid_loss: 0.897742\n",
            "epoch: 8 (step: 7391) | train loss: 0.007098 | lr: 0.000209\n",
            "epoch: 8 (step: 7391) | valid_loss: 0.897978\n",
            "epoch: 8 (step: 7401) | train loss: 0.007306 | lr: 0.000208\n",
            "epoch: 8 (step: 7401) | valid_loss: 0.897257\n",
            "epoch: 8 (step: 7411) | train loss: 0.008824 | lr: 0.000207\n",
            "epoch: 8 (step: 7411) | valid_loss: 0.897261\n",
            "epoch: 8 (step: 7421) | train loss: 0.008112 | lr: 0.000205\n",
            "epoch: 8 (step: 7421) | valid_loss: 0.897263\n",
            "epoch: 8 (step: 7431) | train loss: 0.006682 | lr: 0.000204\n",
            "epoch: 8 (step: 7431) | valid_loss: 0.897505\n",
            "epoch: 8 (step: 7441) | train loss: 0.005470 | lr: 0.000203\n",
            "epoch: 8 (step: 7441) | valid_loss: 0.897511\n",
            "epoch: 8 (step: 7451) | train loss: 0.006112 | lr: 0.000202\n",
            "epoch: 8 (step: 7451) | valid_loss: 0.897256\n",
            "epoch: 8 (step: 7461) | train loss: 0.006730 | lr: 0.000201\n",
            "epoch: 8 (step: 7461) | valid_loss: 0.897738\n",
            "epoch: 8 (step: 7471) | train loss: 0.006429 | lr: 0.000200\n",
            "epoch: 8 (step: 7471) | valid_loss: 0.897504\n",
            "epoch: 9 (step: 7481) | train loss: 0.005645 | lr: 0.000199\n",
            "epoch: 9 (step: 7481) | valid_loss: 0.897753\n",
            "epoch: 9 (step: 7491) | train loss: 0.007618 | lr: 0.000198\n",
            "epoch: 9 (step: 7491) | valid_loss: 0.897256\n",
            "epoch: 9 (step: 7501) | train loss: 0.006181 | lr: 0.000197\n",
            "epoch: 9 (step: 7501) | valid_loss: 0.897261\n",
            "epoch: 9 (step: 7511) | train loss: 0.006601 | lr: 0.000196\n",
            "epoch: 9 (step: 7511) | valid_loss: 0.897992\n",
            "epoch: 9 (step: 7521) | train loss: 0.006309 | lr: 0.000195\n",
            "epoch: 9 (step: 7521) | valid_loss: 0.897993\n",
            "epoch: 9 (step: 7531) | train loss: 0.005963 | lr: 0.000194\n",
            "epoch: 9 (step: 7531) | valid_loss: 0.897250\n",
            "epoch: 9 (step: 7541) | train loss: 0.006720 | lr: 0.000193\n",
            "epoch: 9 (step: 7541) | valid_loss: 0.897496\n",
            "epoch: 9 (step: 7551) | train loss: 0.005402 | lr: 0.000192\n",
            "epoch: 9 (step: 7551) | valid_loss: 0.897741\n",
            "epoch: 9 (step: 7561) | train loss: 0.005997 | lr: 0.000190\n",
            "epoch: 9 (step: 7561) | valid_loss: 0.898720\n",
            "epoch: 9 (step: 7571) | train loss: 0.006401 | lr: 0.000189\n",
            "epoch: 9 (step: 7571) | valid_loss: 0.898480\n",
            "epoch: 9 (step: 7581) | train loss: 0.006133 | lr: 0.000188\n",
            "epoch: 9 (step: 7581) | valid_loss: 0.898001\n",
            "epoch: 9 (step: 7591) | train loss: 0.006264 | lr: 0.000187\n",
            "epoch: 9 (step: 7591) | valid_loss: 0.897990\n",
            "epoch: 9 (step: 7601) | train loss: 0.005459 | lr: 0.000186\n",
            "epoch: 9 (step: 7601) | valid_loss: 0.898723\n",
            "epoch: 9 (step: 7611) | train loss: 0.005270 | lr: 0.000185\n",
            "epoch: 9 (step: 7611) | valid_loss: 0.897753\n",
            "epoch: 9 (step: 7621) | train loss: 0.006467 | lr: 0.000184\n",
            "epoch: 9 (step: 7621) | valid_loss: 0.898251\n",
            "epoch: 9 (step: 7631) | train loss: 0.004058 | lr: 0.000183\n",
            "epoch: 9 (step: 7631) | valid_loss: 0.897258\n",
            "epoch: 9 (step: 7641) | train loss: 0.005756 | lr: 0.000182\n",
            "epoch: 9 (step: 7641) | valid_loss: 0.897274\n",
            "epoch: 9 (step: 7651) | train loss: 0.007569 | lr: 0.000181\n",
            "epoch: 9 (step: 7651) | valid_loss: 0.897758\n",
            "epoch: 9 (step: 7661) | train loss: 0.006461 | lr: 0.000180\n",
            "epoch: 9 (step: 7661) | valid_loss: 0.898250\n",
            "epoch: 9 (step: 7671) | train loss: 0.005317 | lr: 0.000179\n",
            "epoch: 9 (step: 7671) | valid_loss: 0.898245\n",
            "epoch: 9 (step: 7681) | train loss: 0.007912 | lr: 0.000178\n",
            "epoch: 9 (step: 7681) | valid_loss: 0.897748\n",
            "epoch: 9 (step: 7691) | train loss: 0.007628 | lr: 0.000177\n",
            "epoch: 9 (step: 7691) | valid_loss: 0.898237\n",
            "epoch: 9 (step: 7701) | train loss: 0.004174 | lr: 0.000175\n",
            "epoch: 9 (step: 7701) | valid_loss: 0.897755\n",
            "epoch: 9 (step: 7711) | train loss: 0.005589 | lr: 0.000174\n",
            "epoch: 9 (step: 7711) | valid_loss: 0.898474\n",
            "epoch: 9 (step: 7721) | train loss: 0.007423 | lr: 0.000173\n",
            "epoch: 9 (step: 7721) | valid_loss: 0.898239\n",
            "epoch: 9 (step: 7731) | train loss: 0.008386 | lr: 0.000172\n",
            "epoch: 9 (step: 7731) | valid_loss: 0.897508\n",
            "epoch: 9 (step: 7741) | train loss: 0.007086 | lr: 0.000171\n",
            "epoch: 9 (step: 7741) | valid_loss: 0.898483\n",
            "epoch: 9 (step: 7751) | train loss: 0.007847 | lr: 0.000170\n",
            "epoch: 9 (step: 7751) | valid_loss: 0.898963\n",
            "epoch: 9 (step: 7761) | train loss: 0.006451 | lr: 0.000169\n",
            "epoch: 9 (step: 7761) | valid_loss: 0.898721\n",
            "epoch: 9 (step: 7771) | train loss: 0.006636 | lr: 0.000168\n",
            "epoch: 9 (step: 7771) | valid_loss: 0.898715\n",
            "epoch: 9 (step: 7781) | train loss: 0.008288 | lr: 0.000167\n",
            "epoch: 9 (step: 7781) | valid_loss: 0.898709\n",
            "epoch: 9 (step: 7791) | train loss: 0.009532 | lr: 0.000166\n",
            "epoch: 9 (step: 7791) | valid_loss: 0.897990\n",
            "epoch: 9 (step: 7801) | train loss: 0.004800 | lr: 0.000165\n",
            "epoch: 9 (step: 7801) | valid_loss: 0.897982\n",
            "epoch: 9 (step: 7811) | train loss: 0.006563 | lr: 0.000164\n",
            "epoch: 9 (step: 7811) | valid_loss: 0.897982\n",
            "epoch: 9 (step: 7821) | train loss: 0.008209 | lr: 0.000163\n",
            "epoch: 9 (step: 7821) | valid_loss: 0.897495\n",
            "epoch: 9 (step: 7831) | train loss: 0.006512 | lr: 0.000162\n",
            "epoch: 9 (step: 7831) | valid_loss: 0.898471\n",
            "epoch: 9 (step: 7841) | train loss: 0.005792 | lr: 0.000160\n",
            "epoch: 9 (step: 7841) | valid_loss: 0.897738\n",
            "epoch: 9 (step: 7851) | train loss: 0.006137 | lr: 0.000159\n",
            "epoch: 9 (step: 7851) | valid_loss: 0.897735\n",
            "epoch: 9 (step: 7861) | train loss: 0.004987 | lr: 0.000158\n",
            "epoch: 9 (step: 7861) | valid_loss: 0.898955\n",
            "epoch: 9 (step: 7871) | train loss: 0.004983 | lr: 0.000157\n",
            "epoch: 9 (step: 7871) | valid_loss: 0.898465\n",
            "epoch: 9 (step: 7881) | train loss: 0.008070 | lr: 0.000156\n",
            "epoch: 9 (step: 7881) | valid_loss: 0.898228\n",
            "epoch: 9 (step: 7891) | train loss: 0.006717 | lr: 0.000155\n",
            "epoch: 9 (step: 7891) | valid_loss: 0.898957\n",
            "epoch: 9 (step: 7901) | train loss: 0.006490 | lr: 0.000154\n",
            "epoch: 9 (step: 7901) | valid_loss: 0.898219\n",
            "epoch: 9 (step: 7911) | train loss: 0.006058 | lr: 0.000153\n",
            "epoch: 9 (step: 7911) | valid_loss: 0.899927\n",
            "epoch: 9 (step: 7921) | train loss: 0.007048 | lr: 0.000152\n",
            "epoch: 9 (step: 7921) | valid_loss: 0.898480\n",
            "epoch: 9 (step: 7931) | train loss: 0.007584 | lr: 0.000151\n",
            "epoch: 9 (step: 7931) | valid_loss: 0.898710\n",
            "epoch: 9 (step: 7941) | train loss: 0.007739 | lr: 0.000150\n",
            "epoch: 9 (step: 7941) | valid_loss: 0.898227\n",
            "epoch: 9 (step: 7951) | train loss: 0.006191 | lr: 0.000149\n",
            "epoch: 9 (step: 7951) | valid_loss: 0.898461\n",
            "epoch: 9 (step: 7961) | train loss: 0.006068 | lr: 0.000148\n",
            "epoch: 9 (step: 7961) | valid_loss: 0.898713\n",
            "epoch: 9 (step: 7971) | train loss: 0.005235 | lr: 0.000147\n",
            "epoch: 9 (step: 7971) | valid_loss: 0.898459\n",
            "epoch: 9 (step: 7981) | train loss: 0.005181 | lr: 0.000146\n",
            "epoch: 9 (step: 7981) | valid_loss: 0.897979\n",
            "epoch: 9 (step: 7991) | train loss: 0.006184 | lr: 0.000144\n",
            "epoch: 9 (step: 7991) | valid_loss: 0.898952\n",
            "epoch: 9 (step: 8001) | train loss: 0.005993 | lr: 0.000143\n",
            "epoch: 9 (step: 8001) | valid_loss: 0.898223\n",
            "epoch: 9 (step: 8011) | train loss: 0.009323 | lr: 0.000142\n",
            "epoch: 9 (step: 8011) | valid_loss: 0.899191\n",
            "epoch: 9 (step: 8021) | train loss: 0.005000 | lr: 0.000141\n",
            "epoch: 9 (step: 8021) | valid_loss: 0.898703\n",
            "epoch: 9 (step: 8031) | train loss: 0.004877 | lr: 0.000140\n",
            "epoch: 9 (step: 8031) | valid_loss: 0.898711\n",
            "epoch: 9 (step: 8041) | train loss: 0.008258 | lr: 0.000139\n",
            "epoch: 9 (step: 8041) | valid_loss: 0.899187\n",
            "epoch: 9 (step: 8051) | train loss: 0.004795 | lr: 0.000138\n",
            "epoch: 9 (step: 8051) | valid_loss: 0.899205\n",
            "epoch: 9 (step: 8061) | train loss: 0.005414 | lr: 0.000137\n",
            "epoch: 9 (step: 8061) | valid_loss: 0.899436\n",
            "epoch: 9 (step: 8071) | train loss: 0.006454 | lr: 0.000136\n",
            "epoch: 9 (step: 8071) | valid_loss: 0.898957\n",
            "epoch: 9 (step: 8081) | train loss: 0.005299 | lr: 0.000135\n",
            "epoch: 9 (step: 8081) | valid_loss: 0.899197\n",
            "epoch: 9 (step: 8091) | train loss: 0.004130 | lr: 0.000134\n",
            "epoch: 9 (step: 8091) | valid_loss: 0.898961\n",
            "epoch: 9 (step: 8101) | train loss: 0.006429 | lr: 0.000133\n",
            "epoch: 9 (step: 8101) | valid_loss: 0.899690\n",
            "epoch: 9 (step: 8111) | train loss: 0.006583 | lr: 0.000132\n",
            "epoch: 9 (step: 8111) | valid_loss: 0.899453\n",
            "epoch: 9 (step: 8121) | train loss: 0.005190 | lr: 0.000131\n",
            "epoch: 9 (step: 8121) | valid_loss: 0.898720\n",
            "epoch: 9 (step: 8131) | train loss: 0.004974 | lr: 0.000129\n",
            "epoch: 9 (step: 8131) | valid_loss: 0.898956\n",
            "epoch: 9 (step: 8141) | train loss: 0.004392 | lr: 0.000128\n",
            "epoch: 9 (step: 8141) | valid_loss: 0.898457\n",
            "epoch: 9 (step: 8151) | train loss: 0.006339 | lr: 0.000127\n",
            "epoch: 9 (step: 8151) | valid_loss: 0.898462\n",
            "epoch: 9 (step: 8161) | train loss: 0.005634 | lr: 0.000126\n",
            "epoch: 9 (step: 8161) | valid_loss: 0.898713\n",
            "epoch: 9 (step: 8171) | train loss: 0.006813 | lr: 0.000125\n",
            "epoch: 9 (step: 8171) | valid_loss: 0.898712\n",
            "epoch: 9 (step: 8181) | train loss: 0.007129 | lr: 0.000124\n",
            "epoch: 9 (step: 8181) | valid_loss: 0.898715\n",
            "epoch: 9 (step: 8191) | train loss: 0.006260 | lr: 0.000123\n",
            "epoch: 9 (step: 8191) | valid_loss: 0.898216\n",
            "epoch: 9 (step: 8201) | train loss: 0.006686 | lr: 0.000122\n",
            "epoch: 9 (step: 8201) | valid_loss: 0.898463\n",
            "epoch: 9 (step: 8211) | train loss: 0.005746 | lr: 0.000121\n",
            "epoch: 9 (step: 8211) | valid_loss: 0.898469\n",
            "epoch: 9 (step: 8221) | train loss: 0.005799 | lr: 0.000120\n",
            "epoch: 9 (step: 8221) | valid_loss: 0.898471\n",
            "epoch: 9 (step: 8231) | train loss: 0.004583 | lr: 0.000119\n",
            "epoch: 9 (step: 8231) | valid_loss: 0.897991\n",
            "epoch: 9 (step: 8241) | train loss: 0.005255 | lr: 0.000118\n",
            "epoch: 9 (step: 8241) | valid_loss: 0.899199\n",
            "epoch: 9 (step: 8251) | train loss: 0.005597 | lr: 0.000117\n",
            "epoch: 9 (step: 8251) | valid_loss: 0.898471\n",
            "epoch: 9 (step: 8261) | train loss: 0.008286 | lr: 0.000116\n",
            "epoch: 9 (step: 8261) | valid_loss: 0.897984\n",
            "epoch: 9 (step: 8271) | train loss: 0.006892 | lr: 0.000114\n",
            "epoch: 9 (step: 8271) | valid_loss: 0.898225\n",
            "epoch: 9 (step: 8281) | train loss: 0.006119 | lr: 0.000113\n",
            "epoch: 9 (step: 8281) | valid_loss: 0.899207\n",
            "epoch: 9 (step: 8291) | train loss: 0.006345 | lr: 0.000112\n",
            "epoch: 9 (step: 8291) | valid_loss: 0.899195\n",
            "epoch: 9 (step: 8301) | train loss: 0.005260 | lr: 0.000111\n",
            "epoch: 9 (step: 8301) | valid_loss: 0.898702\n",
            "epoch: 9 (step: 8311) | train loss: 0.007561 | lr: 0.000110\n",
            "epoch: 9 (step: 8311) | valid_loss: 0.898477\n",
            "epoch: 9 (step: 8321) | train loss: 0.008611 | lr: 0.000109\n",
            "epoch: 9 (step: 8321) | valid_loss: 0.897976\n",
            "epoch: 9 (step: 8331) | train loss: 0.009071 | lr: 0.000108\n",
            "epoch: 9 (step: 8331) | valid_loss: 0.897979\n",
            "epoch: 9 (step: 8341) | train loss: 0.004641 | lr: 0.000107\n",
            "epoch: 9 (step: 8341) | valid_loss: 0.897736\n",
            "epoch: 9 (step: 8351) | train loss: 0.009055 | lr: 0.000106\n",
            "epoch: 9 (step: 8351) | valid_loss: 0.898945\n",
            "epoch: 9 (step: 8361) | train loss: 0.007072 | lr: 0.000105\n",
            "epoch: 9 (step: 8361) | valid_loss: 0.897740\n",
            "epoch: 9 (step: 8371) | train loss: 0.007771 | lr: 0.000104\n",
            "epoch: 9 (step: 8371) | valid_loss: 0.898696\n",
            "epoch: 9 (step: 8381) | train loss: 0.005991 | lr: 0.000103\n",
            "epoch: 9 (step: 8381) | valid_loss: 0.897739\n",
            "epoch: 9 (step: 8391) | train loss: 0.007594 | lr: 0.000102\n",
            "epoch: 9 (step: 8391) | valid_loss: 0.898211\n",
            "epoch: 9 (step: 8401) | train loss: 0.006705 | lr: 0.000101\n",
            "epoch: 9 (step: 8401) | valid_loss: 0.897979\n",
            "epoch: 9 (step: 8411) | train loss: 0.006331 | lr: 0.000099\n",
            "epoch: 9 (step: 8411) | valid_loss: 0.897975\n",
            "epoch: 10 (step: 8421) | train loss: 0.005295 | lr: 0.000098\n",
            "epoch: 10 (step: 8421) | valid_loss: 0.897731\n",
            "epoch: 10 (step: 8431) | train loss: 0.004700 | lr: 0.000097\n",
            "epoch: 10 (step: 8431) | valid_loss: 0.897484\n",
            "epoch: 10 (step: 8441) | train loss: 0.008575 | lr: 0.000096\n",
            "epoch: 10 (step: 8441) | valid_loss: 0.897501\n",
            "epoch: 10 (step: 8451) | train loss: 0.007838 | lr: 0.000095\n",
            "epoch: 10 (step: 8451) | valid_loss: 0.897245\n",
            "epoch: 10 (step: 8461) | train loss: 0.004774 | lr: 0.000094\n",
            "epoch: 10 (step: 8461) | valid_loss: 0.897491\n",
            "epoch: 10 (step: 8471) | train loss: 0.006701 | lr: 0.000093\n",
            "epoch: 10 (step: 8471) | valid_loss: 0.897496\n",
            "epoch: 10 (step: 8481) | train loss: 0.008051 | lr: 0.000092\n",
            "epoch: 10 (step: 8481) | valid_loss: 0.897976\n",
            "epoch: 10 (step: 8491) | train loss: 0.005664 | lr: 0.000091\n",
            "epoch: 10 (step: 8491) | valid_loss: 0.897738\n",
            "epoch: 10 (step: 8501) | train loss: 0.009373 | lr: 0.000090\n",
            "epoch: 10 (step: 8501) | valid_loss: 0.896762\n",
            "epoch: 10 (step: 8511) | train loss: 0.004680 | lr: 0.000089\n",
            "epoch: 10 (step: 8511) | valid_loss: 0.897503\n",
            "epoch: 10 (step: 8521) | train loss: 0.005422 | lr: 0.000088\n",
            "epoch: 10 (step: 8521) | valid_loss: 0.897240\n",
            "epoch: 10 (step: 8531) | train loss: 0.008986 | lr: 0.000087\n",
            "epoch: 10 (step: 8531) | valid_loss: 0.897247\n",
            "epoch: 10 (step: 8541) | train loss: 0.004882 | lr: 0.000086\n",
            "epoch: 10 (step: 8541) | valid_loss: 0.897730\n",
            "epoch: 10 (step: 8551) | train loss: 0.007653 | lr: 0.000084\n",
            "epoch: 10 (step: 8551) | valid_loss: 0.897485\n",
            "epoch: 10 (step: 8561) | train loss: 0.004251 | lr: 0.000083\n",
            "epoch: 10 (step: 8561) | valid_loss: 0.897730\n",
            "epoch: 10 (step: 8571) | train loss: 0.005033 | lr: 0.000082\n",
            "epoch: 10 (step: 8571) | valid_loss: 0.896755\n",
            "epoch: 10 (step: 8581) | train loss: 0.005338 | lr: 0.000081\n",
            "epoch: 10 (step: 8581) | valid_loss: 0.897001\n",
            "epoch: 10 (step: 8591) | train loss: 0.006602 | lr: 0.000080\n",
            "epoch: 10 (step: 8591) | valid_loss: 0.897239\n",
            "epoch: 10 (step: 8601) | train loss: 0.007285 | lr: 0.000079\n",
            "epoch: 10 (step: 8601) | valid_loss: 0.897487\n",
            "epoch: 10 (step: 8611) | train loss: 0.007303 | lr: 0.000078\n",
            "epoch: 10 (step: 8611) | valid_loss: 0.897012\n",
            "epoch: 10 (step: 8621) | train loss: 0.005869 | lr: 0.000077\n",
            "epoch: 10 (step: 8621) | valid_loss: 0.896761\n",
            "epoch: 10 (step: 8631) | train loss: 0.004951 | lr: 0.000076\n",
            "epoch: 10 (step: 8631) | valid_loss: 0.897735\n",
            "epoch: 10 (step: 8641) | train loss: 0.007434 | lr: 0.000075\n",
            "epoch: 10 (step: 8641) | valid_loss: 0.896525\n",
            "epoch: 10 (step: 8651) | train loss: 0.007372 | lr: 0.000074\n",
            "epoch: 10 (step: 8651) | valid_loss: 0.897487\n",
            "epoch: 10 (step: 8661) | train loss: 0.006067 | lr: 0.000073\n",
            "epoch: 10 (step: 8661) | valid_loss: 0.897237\n",
            "epoch: 10 (step: 8671) | train loss: 0.007042 | lr: 0.000072\n",
            "epoch: 10 (step: 8671) | valid_loss: 0.897488\n",
            "epoch: 10 (step: 8681) | train loss: 0.004867 | lr: 0.000071\n",
            "epoch: 10 (step: 8681) | valid_loss: 0.897001\n",
            "epoch: 10 (step: 8691) | train loss: 0.005717 | lr: 0.000069\n",
            "epoch: 10 (step: 8691) | valid_loss: 0.897500\n",
            "epoch: 10 (step: 8701) | train loss: 0.003772 | lr: 0.000068\n",
            "epoch: 10 (step: 8701) | valid_loss: 0.897729\n",
            "epoch: 10 (step: 8711) | train loss: 0.005945 | lr: 0.000067\n",
            "epoch: 10 (step: 8711) | valid_loss: 0.897981\n",
            "epoch: 10 (step: 8721) | train loss: 0.006392 | lr: 0.000066\n",
            "epoch: 10 (step: 8721) | valid_loss: 0.897728\n",
            "epoch: 10 (step: 8731) | train loss: 0.006241 | lr: 0.000065\n",
            "epoch: 10 (step: 8731) | valid_loss: 0.897737\n",
            "epoch: 10 (step: 8741) | train loss: 0.003558 | lr: 0.000064\n",
            "epoch: 10 (step: 8741) | valid_loss: 0.897495\n",
            "epoch: 10 (step: 8751) | train loss: 0.005471 | lr: 0.000063\n",
            "epoch: 10 (step: 8751) | valid_loss: 0.898217\n",
            "epoch: 10 (step: 8761) | train loss: 0.006990 | lr: 0.000062\n",
            "epoch: 10 (step: 8761) | valid_loss: 0.896516\n",
            "epoch: 10 (step: 8771) | train loss: 0.005327 | lr: 0.000061\n",
            "epoch: 10 (step: 8771) | valid_loss: 0.897242\n",
            "epoch: 10 (step: 8781) | train loss: 0.004512 | lr: 0.000060\n",
            "epoch: 10 (step: 8781) | valid_loss: 0.897732\n",
            "epoch: 10 (step: 8791) | train loss: 0.004825 | lr: 0.000059\n",
            "epoch: 10 (step: 8791) | valid_loss: 0.897727\n",
            "epoch: 10 (step: 8801) | train loss: 0.006329 | lr: 0.000058\n",
            "epoch: 10 (step: 8801) | valid_loss: 0.897737\n",
            "epoch: 10 (step: 8811) | train loss: 0.006815 | lr: 0.000057\n",
            "epoch: 10 (step: 8811) | valid_loss: 0.897488\n",
            "epoch: 10 (step: 8821) | train loss: 0.005843 | lr: 0.000056\n",
            "epoch: 10 (step: 8821) | valid_loss: 0.897245\n",
            "epoch: 10 (step: 8831) | train loss: 0.005167 | lr: 0.000054\n",
            "epoch: 10 (step: 8831) | valid_loss: 0.898218\n",
            "epoch: 10 (step: 8841) | train loss: 0.006232 | lr: 0.000053\n",
            "epoch: 10 (step: 8841) | valid_loss: 0.897240\n",
            "epoch: 10 (step: 8851) | train loss: 0.007357 | lr: 0.000052\n",
            "epoch: 10 (step: 8851) | valid_loss: 0.897008\n",
            "epoch: 10 (step: 8861) | train loss: 0.004924 | lr: 0.000051\n",
            "epoch: 10 (step: 8861) | valid_loss: 0.897724\n",
            "epoch: 10 (step: 8871) | train loss: 0.006604 | lr: 0.000050\n",
            "epoch: 10 (step: 8871) | valid_loss: 0.897005\n",
            "epoch: 10 (step: 8881) | train loss: 0.005894 | lr: 0.000049\n",
            "epoch: 10 (step: 8881) | valid_loss: 0.897259\n",
            "epoch: 10 (step: 8891) | train loss: 0.005724 | lr: 0.000048\n",
            "epoch: 10 (step: 8891) | valid_loss: 0.897970\n",
            "epoch: 10 (step: 8901) | train loss: 0.007012 | lr: 0.000047\n",
            "epoch: 10 (step: 8901) | valid_loss: 0.897977\n",
            "epoch: 10 (step: 8911) | train loss: 0.005583 | lr: 0.000046\n",
            "epoch: 10 (step: 8911) | valid_loss: 0.897720\n",
            "epoch: 10 (step: 8921) | train loss: 0.006885 | lr: 0.000045\n",
            "epoch: 10 (step: 8921) | valid_loss: 0.897490\n",
            "epoch: 10 (step: 8931) | train loss: 0.007082 | lr: 0.000044\n",
            "epoch: 10 (step: 8931) | valid_loss: 0.897734\n",
            "epoch: 10 (step: 8941) | train loss: 0.005830 | lr: 0.000043\n",
            "epoch: 10 (step: 8941) | valid_loss: 0.896995\n",
            "epoch: 10 (step: 8951) | train loss: 0.006659 | lr: 0.000042\n",
            "epoch: 10 (step: 8951) | valid_loss: 0.897483\n",
            "epoch: 10 (step: 8961) | train loss: 0.006705 | lr: 0.000041\n",
            "epoch: 10 (step: 8961) | valid_loss: 0.897725\n",
            "epoch: 10 (step: 8971) | train loss: 0.006573 | lr: 0.000040\n",
            "epoch: 10 (step: 8971) | valid_loss: 0.897243\n",
            "epoch: 10 (step: 8981) | train loss: 0.004163 | lr: 0.000038\n",
            "epoch: 10 (step: 8981) | valid_loss: 0.897007\n",
            "epoch: 10 (step: 8991) | train loss: 0.005828 | lr: 0.000037\n",
            "epoch: 10 (step: 8991) | valid_loss: 0.898211\n",
            "epoch: 10 (step: 9001) | train loss: 0.006301 | lr: 0.000036\n",
            "epoch: 10 (step: 9001) | valid_loss: 0.897244\n",
            "epoch: 10 (step: 9011) | train loss: 0.007960 | lr: 0.000035\n",
            "epoch: 10 (step: 9011) | valid_loss: 0.897479\n",
            "epoch: 10 (step: 9021) | train loss: 0.007810 | lr: 0.000034\n",
            "epoch: 10 (step: 9021) | valid_loss: 0.898208\n",
            "epoch: 10 (step: 9031) | train loss: 0.006348 | lr: 0.000033\n",
            "epoch: 10 (step: 9031) | valid_loss: 0.897484\n",
            "epoch: 10 (step: 9041) | train loss: 0.007442 | lr: 0.000032\n",
            "epoch: 10 (step: 9041) | valid_loss: 0.897480\n",
            "epoch: 10 (step: 9051) | train loss: 0.007085 | lr: 0.000031\n",
            "epoch: 10 (step: 9051) | valid_loss: 0.897730\n",
            "epoch: 10 (step: 9061) | train loss: 0.007029 | lr: 0.000030\n",
            "epoch: 10 (step: 9061) | valid_loss: 0.897492\n",
            "epoch: 10 (step: 9071) | train loss: 0.006822 | lr: 0.000029\n",
            "epoch: 10 (step: 9071) | valid_loss: 0.897975\n",
            "epoch: 10 (step: 9081) | train loss: 0.004467 | lr: 0.000028\n",
            "epoch: 10 (step: 9081) | valid_loss: 0.897248\n",
            "epoch: 10 (step: 9091) | train loss: 0.007845 | lr: 0.000027\n",
            "epoch: 10 (step: 9091) | valid_loss: 0.897719\n",
            "epoch: 10 (step: 9101) | train loss: 0.006200 | lr: 0.000026\n",
            "epoch: 10 (step: 9101) | valid_loss: 0.896761\n",
            "epoch: 10 (step: 9111) | train loss: 0.006427 | lr: 0.000025\n",
            "epoch: 10 (step: 9111) | valid_loss: 0.896763\n",
            "epoch: 10 (step: 9121) | train loss: 0.007077 | lr: 0.000023\n",
            "epoch: 10 (step: 9121) | valid_loss: 0.896761\n",
            "epoch: 10 (step: 9131) | train loss: 0.005566 | lr: 0.000022\n",
            "epoch: 10 (step: 9131) | valid_loss: 0.897723\n",
            "epoch: 10 (step: 9141) | train loss: 0.006368 | lr: 0.000021\n",
            "epoch: 10 (step: 9141) | valid_loss: 0.897480\n",
            "epoch: 10 (step: 9151) | train loss: 0.004102 | lr: 0.000020\n",
            "epoch: 10 (step: 9151) | valid_loss: 0.897961\n",
            "epoch: 10 (step: 9161) | train loss: 0.007958 | lr: 0.000019\n",
            "epoch: 10 (step: 9161) | valid_loss: 0.897724\n",
            "epoch: 10 (step: 9171) | train loss: 0.007161 | lr: 0.000018\n",
            "epoch: 10 (step: 9171) | valid_loss: 0.897487\n",
            "epoch: 10 (step: 9181) | train loss: 0.007977 | lr: 0.000017\n",
            "epoch: 10 (step: 9181) | valid_loss: 0.896995\n",
            "epoch: 10 (step: 9191) | train loss: 0.006145 | lr: 0.000016\n",
            "epoch: 10 (step: 9191) | valid_loss: 0.897475\n",
            "epoch: 10 (step: 9201) | train loss: 0.004935 | lr: 0.000015\n",
            "epoch: 10 (step: 9201) | valid_loss: 0.897977\n",
            "epoch: 10 (step: 9211) | train loss: 0.007931 | lr: 0.000014\n",
            "epoch: 10 (step: 9211) | valid_loss: 0.897731\n",
            "epoch: 10 (step: 9221) | train loss: 0.007778 | lr: 0.000013\n",
            "epoch: 10 (step: 9221) | valid_loss: 0.897488\n",
            "epoch: 10 (step: 9231) | train loss: 0.003726 | lr: 0.000012\n",
            "epoch: 10 (step: 9231) | valid_loss: 0.897970\n",
            "epoch: 10 (step: 9241) | train loss: 0.005447 | lr: 0.000011\n",
            "epoch: 10 (step: 9241) | valid_loss: 0.897722\n",
            "epoch: 10 (step: 9251) | train loss: 0.005046 | lr: 0.000010\n",
            "epoch: 10 (step: 9251) | valid_loss: 0.897973\n",
            "epoch: 10 (step: 9261) | train loss: 0.005619 | lr: 0.000008\n",
            "epoch: 10 (step: 9261) | valid_loss: 0.897484\n",
            "epoch: 10 (step: 9271) | train loss: 0.007710 | lr: 0.000007\n",
            "epoch: 10 (step: 9271) | valid_loss: 0.898219\n",
            "epoch: 10 (step: 9281) | train loss: 0.009279 | lr: 0.000006\n",
            "epoch: 10 (step: 9281) | valid_loss: 0.897244\n",
            "epoch: 10 (step: 9291) | train loss: 0.006982 | lr: 0.000005\n",
            "epoch: 10 (step: 9291) | valid_loss: 0.897238\n",
            "epoch: 10 (step: 9301) | train loss: 0.007927 | lr: 0.000004\n",
            "epoch: 10 (step: 9301) | valid_loss: 0.897241\n",
            "epoch: 10 (step: 9311) | train loss: 0.005887 | lr: 0.000003\n",
            "epoch: 10 (step: 9311) | valid_loss: 0.896991\n",
            "epoch: 10 (step: 9321) | train loss: 0.006491 | lr: 0.000002\n",
            "epoch: 10 (step: 9321) | valid_loss: 0.897245\n",
            "epoch: 10 (step: 9331) | train loss: 0.007772 | lr: 0.000001\n",
            "epoch: 10 (step: 9331) | valid_loss: 0.897728\n",
            "epoch: 10 (step: 9341) | train loss: 0.007094 | lr: 0.000000\n",
            "epoch: 10 (step: 9341) | valid_loss: 0.897720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Initial Model Evaluation on All Queries\n",
        "\n",
        "In this step, we will evaluate the model's performance across all queries, using the Reliability Score (RS) as our evaluation metric. This will provide a baseline understanding of the model's reliability scroe without filtering for unanswerable queries."
      ],
      "metadata": {
        "id": "Dqu5fNALDD-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scoring_program.scoring_utils import execute_all, reliability_score, penalize\n",
        "from scoring_program.postprocessing import post_process_sql\n",
        "\n",
        "# Load the best-performing model checkpoint\n",
        "model, optimizer, scheduler, args, step, best_metric = load_model(\n",
        "    model,\n",
        "    os.path.join(args.save_model_path, 'checkpoint_best.pth.tar'),\n",
        "    args,\n",
        ")\n",
        "\n",
        "# Perform inference on the validation set\n",
        "valid_eval = generate_sql(tokenizer, model, valid_loader, args)\n",
        "\n",
        "# Post-process SQL queries for evaluation\n",
        "label = {sample['id']: post_process_sql(sample['real']) for sample in valid_eval}\n",
        "label_y = {sample['id']: post_process_sql(sample['pred']) for sample in valid_eval}\n",
        "id2maxent = {sample['id']: max(sample['entropy']) for sample in valid_eval}  # NOTE: Abstain strategy not used here\n",
        "\n",
        "# Calculate the Reliability Score (RS) across all queries\n",
        "real_dict = {id_: post_process_sql(label[id_]) for id_ in label}\n",
        "pred_dict = {id_: post_process_sql(label_y[id_]) for id_ in label_y}\n",
        "assert set(real_dict) == set(pred_dict), \"IDs do not match\"\n",
        "\n",
        "real_result = execute_all(real_dict, db_path=DB_PATH, tag='real')\n",
        "pred_result = execute_all(pred_dict, db_path=DB_PATH, tag='pred')\n",
        "\n",
        "scores, score_dict = reliability_score(real_result, pred_result, return_dict=True)\n",
        "accuracy0 = penalize(scores, penalty=0)\n",
        "accuracy5 = penalize(scores, penalty=5)\n",
        "accuracy10 = penalize(scores, penalty=10)\n",
        "accuracyN = penalize(scores, penalty=len(scores))\n",
        "\n",
        "print(f\"RS without filtering unanswerable queries: Accuracy0: {accuracy0}, Accuracy5: {accuracy5}, Accuracy10: {accuracy10}, AccuracyN: {accuracyN}\")"
      ],
      "metadata": {
        "id": "jFNoUdhaDHNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ac0859-4152-4f75-cc3b-d3b2447c8150"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 257/257 [24:19<00:00,  5.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RS without filtering unanswerable queries: Accuracy0: 0.8097560975609757, Accuracy5: -0.14146341463414633, Accuracy10: -1.0926829268292684, AccuracyN: -194.19024390243902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Model Evaluation Considering Unanswerable Questions\n",
        "\n",
        "This step refines the evaluation process by considering unanswerable questions ($Q_{una}$). We apply a threshold based on maximum entropy to filter out uncertain predictions. The RS is then recalculated to assess the model's performance more accurately in scenarios where abstaining from answering difficult questions is preferable.\n",
        "\n",
        "Here, compared to the Step 5, aims to provide a clear and concise evaluation process, highlighting the importance of reliability in text-to-SQL modeling, especially when dealing with complex or uncertain queries."
      ],
      "metadata": {
        "id": "aq5sSJnydPDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_threshold(id2maxent, score_dict):\n",
        "    \"\"\"\n",
        "    Determine the optimal threshold for filtering based on maximum entropy and scores.\n",
        "    \"\"\"\n",
        "    values = []\n",
        "    scores = []\n",
        "    for key, val in id2maxent.items():\n",
        "        values.append(val)\n",
        "        scores.append(score_dict[key])\n",
        "\n",
        "    sorted_indices = np.argsort(values)\n",
        "    sorted_values = np.array(values)[sorted_indices]\n",
        "    sorted_scores = np.array(scores)[sorted_indices]\n",
        "\n",
        "    max_score, threshold = 0, -1\n",
        "    for idx in range(len(sorted_scores)):\n",
        "        cum_score = sum(sorted_scores[:idx+1])\n",
        "        if cum_score > max_score:\n",
        "            print('cum_score > max_score')\n",
        "            max_score, threshold = cum_score, sorted_values[idx-1]\n",
        "\n",
        "    return threshold  # We abstain if maxent is greater than this threshold."
      ],
      "metadata": {
        "id": "Ly_sDoWfdVv1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate threshold for filtering unanswerable queries\n",
        "threshold = get_threshold(id2maxent, score_dict)\n",
        "print(f\"Threshold for filtering: {threshold}\")\n",
        "\n",
        "# Apply threshold to filter out uncertain predictions\n",
        "label_y = {sample['id']: 'null' if threshold < max(sample['entropy']) else post_process_sql(sample['pred']) for sample in valid_eval}\n",
        "\n",
        "# Recalculate RS with filtered predictions\n",
        "real_dict = {id_: post_process_sql(label[id_]) for id_ in label}\n",
        "pred_dict = {id_: post_process_sql(label_y[id_]) for id_ in label_y}\n",
        "\n",
        "scores_filtered = reliability_score(real_dict, pred_dict)\n",
        "\n",
        "accuracy0_filtered = penalize(scores_filtered, penalty=0)\n",
        "accuracy5_filtered = penalize(scores_filtered, penalty=5)\n",
        "accuracy10_filtered = penalize(scores_filtered, penalty=10)\n",
        "accuracyN_filtered = penalize(scores_filtered, penalty=len(scores))\n",
        "\n",
        "# Output the refined RS scores with abstention\n",
        "print(f\"RS with filtered unanswerable queries: Accuracy0: {accuracy0_filtered}, Accuracy5: {accuracy5_filtered}, Accuracy10: {accuracy10_filtered}, AccuracyN: {accuracyN_filtered}\")"
      ],
      "metadata": {
        "id": "KLlXZILWDK4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b99a059-62f0-40e5-834b-5cb38445b3d9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "cum_score > max_score\n",
            "Threshold for filtering: 4.273737907409668\n",
            "RS with filtered unanswerable queries: Accuracy0: 0.7248780487804878, Accuracy5: -0.6165853658536585, Accuracy10: -1.9580487804878048, AccuracyN: -274.2751219512195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Test data inference\n",
        "\n",
        "Now, we conduct inference using the original validation set as our test data. Our model generates SQL predictions, applying the previously defined entropy threshold to filter out uncertain responses. Predictions with high uncertainty are marked `null`, indicating the model's strategic abstention from potentially incorrect outputs."
      ],
      "metadata": {
        "id": "so9fFAxxDQFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conduct inference on the test set (For now, we use original validation set as test data)\n",
        "test_eval = generate_sql(tokenizer, model, test_loader, args)\n",
        "\n",
        "# Apply the threshold to uncertain predictions\n",
        "label_y = {sample['id']: 'null' if threshold < max(sample['entropy']) else post_process_sql(sample['pred']) for sample in test_eval}"
      ],
      "metadata": {
        "id": "L40jsDQWDQTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8698573d-7f8b-4b72-8efd-dee5c4932ddf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 291/291 [28:09<00:00,  5.80s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save these predictions to a JSON file in a designated results directory, creating the directory if necessary. A final check confirms the presence of our output file, ensuring our test inference process is complete and successful."
      ],
      "metadata": {
        "id": "QUo3gue75Gmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale; locale.getpreferredencoding = lambda: \"UTF-8\" # if necessary"
      ],
      "metadata": {
        "id": "La1gzUogtXDM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_io import write_json as write_label\n",
        "\n",
        "# Save the filtered predictions to a JSON file\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "SCORING_OUTPUT_DIR = os.path.join(RESULT_DIR, 'prediction.json')\n",
        "write_label(SCORING_OUTPUT_DIR, label_y)\n",
        "\n",
        "# Verify the file creation\n",
        "print(\"Listing files in RESULT_DIR:\")\n",
        "!ls {RESULT_DIR}"
      ],
      "metadata": {
        "id": "KreTDPl5DVK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4add4b-dcb7-43a7-93b8-c13fb5804737"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in RESULT_DIR:\n",
            "prediction.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Submission\n",
        "\n",
        "In this final step, we'll prepare and submit our results to the Codabench competition."
      ],
      "metadata": {
        "id": "FHQZ1_rLDabS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to the directory containing the prediction file\n",
        "%cd {RESULT_DIR}\n",
        "\n",
        "# Compress the prediction.json file into a ZIP archive\n",
        "!zip predictions.zip prediction.json"
      ],
      "metadata": {
        "id": "l8fRbMgqDYTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c70745d-d29e-4f1f-9186-56df5e2438ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024/sample_result_submission\n",
            "  adding: prediction.json (deflated 54%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Submission File: Ensure that the `predictions.zip` file contains only the `prediction.json` file. This ZIP archive is the required format for submission to Codabench.\n",
        "\n",
        "- Submitting on Codabench: Navigate to the Codabench competition page and go to the **My Submissions** tab. Upload the `predictions.zip` file following the provided instructions. Make sure to adhere to any guidelines or submission requirements detailed on the competition page."
      ],
      "metadata": {
        "id": "CXWnb8itDhGC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1-DM8XNUYYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}